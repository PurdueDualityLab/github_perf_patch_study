{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e779bfd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Optional\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec262fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001\n",
      "models/gemini-2.5-flash\n",
      "models/gemini-2.5-pro\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.5-flash-preview-tts\n",
      "models/gemini-2.5-pro-preview-tts\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/gemma-3n-e4b-it\n",
      "models/gemma-3n-e2b-it\n",
      "models/gemini-flash-latest\n",
      "models/gemini-flash-lite-latest\n",
      "models/gemini-pro-latest\n",
      "models/gemini-2.5-flash-lite\n",
      "models/gemini-2.5-flash-image-preview\n",
      "models/gemini-2.5-flash-image\n",
      "models/gemini-2.5-flash-preview-09-2025\n",
      "models/gemini-2.5-flash-lite-preview-09-2025\n",
      "models/gemini-3-pro-preview\n",
      "models/gemini-3-pro-image-preview\n",
      "models/nano-banana-pro-preview\n",
      "models/gemini-robotics-er-1.5-preview\n",
      "models/gemini-2.5-computer-use-preview-10-2025\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/gemini-embedding-001\n",
      "models/aqa\n",
      "models/imagen-4.0-generate-preview-06-06\n",
      "models/imagen-4.0-ultra-generate-preview-06-06\n",
      "models/imagen-4.0-generate-001\n",
      "models/imagen-4.0-ultra-generate-001\n",
      "models/imagen-4.0-fast-generate-001\n",
      "models/veo-2.0-generate-001\n",
      "models/veo-3.0-generate-001\n",
      "models/veo-3.0-fast-generate-001\n",
      "models/veo-3.1-generate-preview\n",
      "models/veo-3.1-fast-generate-preview\n",
      "models/gemini-2.0-flash-live-001\n",
      "models/gemini-live-2.5-flash-preview\n",
      "models/gemini-2.5-flash-live-preview\n",
      "models/gemini-2.5-flash-native-audio-latest\n",
      "models/gemini-2.5-flash-native-audio-preview-09-2025\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=os.environ.get(\"GEMINI_API_KEY\"))\n",
    "pager = client.models.list(config={\"page_size\": 50})\n",
    "\n",
    "for m in pager:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64e600d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_llm(system_pront: str, prompt: str, type: str = \"ollama\", model: str = \"gemma3:27b\") -> str:\n",
    "    \"\"\"Call local OLLAMA.\"\"\"\n",
    "    LLM_BASE_URL = \"http://localhost:11434/v1\"\n",
    "    LLM_API_KEY = \"\"\n",
    "    llm_client = OpenAI(base_url=LLM_BASE_URL, api_key=LLM_API_KEY)\n",
    "    \n",
    "  \n",
    "    \n",
    "    if(type == \"ollama\"):\n",
    "        print(\"Running OLLAMA, model:\", model)\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_pront},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "        \n",
    "        r = llm_client.chat.completions.create(\n",
    "            model= model,\n",
    "            messages=messages,\n",
    "        )\n",
    "        result = r.choices[0].message.content.strip()\n",
    "        print(\"OLLAMA response:\", result)\n",
    "        return result.strip()\n",
    "    elif(type == \"gemini\"):\n",
    "        \n",
    "        model = \"models/gemini-pro-latest\"\n",
    "        print(\"Running GEMINI, model:\", model)\n",
    "        \n",
    "        GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
    "        client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "        schema={\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"validation_present\": {\n",
    "                        \"type\": \"boolean\"\n",
    "                    },\n",
    "                    \"evidence_sources\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"enum\": [\"pipeline\", \"description\", \"comments\"]\n",
    "                        }\n",
    "                    },\n",
    "                    \"validation_type\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\n",
    "                            \"benchmark\",\n",
    "                            \"profiling\",\n",
    "                            \"load/canary\",\n",
    "                            \"unit-only\",\n",
    "                            \"unspecified\",\n",
    "                            \"none\"\n",
    "                        ]\n",
    "                    },\n",
    "                    \"validation_description\": {\n",
    "                        \"type\": \"string\"\n",
    "                    },\n",
    "                    \"pipeline_signal\": {\n",
    "                        \"type\": \"string\"\n",
    "                    },\n",
    "                    \"description_signal\": {\n",
    "                        \"type\": \"string\"\n",
    "                    },\n",
    "                    \"comment_signal\": {\n",
    "                        \"type\": \"string\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"validation_present\",\n",
    "                    \"evidence_sources\",\n",
    "                    \"validation_type\",\n",
    "                    \"validation_description\",\n",
    "                    \"pipeline_signal\",\n",
    "                    \"description_signal\",\n",
    "                    \"comment_signal\"\n",
    "                ]\n",
    "            }\n",
    "        \n",
    "        config = types.GenerateContentConfig(\n",
    "            temperature=0.0,\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_schema=schema,\n",
    "            # thinking_config=types.ThinkingConfig(\n",
    "            #     thinking_level=types.ThinkingLevel.HIGH\n",
    "            # )\n",
    "        )\n",
    "        \n",
    "        messages = [\n",
    "            system_pront,\n",
    "            prompt\n",
    "        ]\n",
    "        \n",
    "        response = client.models.generate_content(\n",
    "            model=model,\n",
    "            contents=messages,\n",
    "            config=config,\n",
    "        )\n",
    "\n",
    "        return response.text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56c2b2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_datasets_dir(start: Optional[Path] = None) -> Path:\n",
    "    start = start or Path.cwd()\n",
    "    for path in (start, *start.parents):\n",
    "        candidate = path / \"datasets\"\n",
    "        if candidate.exists():\n",
    "            return candidate\n",
    "    raise FileNotFoundError(f\"Could not find 'datasets' directory from {start}\")\n",
    "\n",
    "\n",
    "DATASETS_DIR = find_datasets_dir()\n",
    "PROJECT_ROOT = DATASETS_DIR.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10afe7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json(text: str) -> Dict:\n",
    "    \"\"\"Best-effort JSON extraction from model output.\"\"\"\n",
    "    start = text.find(\"{\")\n",
    "    end = text.rfind(\"}\")\n",
    "    if start != -1 and end != -1 and end > start:\n",
    "        snippet = text[start : end + 1]\n",
    "        try:\n",
    "            return json.loads(snippet)\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "    return {}\n",
    "\n",
    "def truncate(text: str, limit: int = 10000) -> str:\n",
    "    return text if len(text) <= limit else text[:limit] + \"...[truncated]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29784b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pr_core(prefix: str) -> pd.DataFrame:\n",
    "    commits = pd.read_parquet(\n",
    "        DATASETS_DIR / f\"{prefix}_pr\" / f\"{prefix}_pr_commits.parquet\"\n",
    "    )\n",
    "    return commits.drop_duplicates(\"pr_id\").set_index(\"pr_id\")\n",
    "\n",
    "\n",
    "def collect_comments(prefix: str, pr_id: int) -> List[str]:\n",
    "    issue = pd.read_parquet(\n",
    "        DATASETS_DIR / f\"{prefix}_pr\" / f\"{prefix}_pr_issue_comments.parquet\"\n",
    "    )\n",
    "    review = pd.read_parquet(\n",
    "        DATASETS_DIR / f\"{prefix}_pr\" / f\"{prefix}_pr_review_comments.parquet\"\n",
    "    )\n",
    "    texts = []\n",
    "    for df in (issue, review):\n",
    "        subset = df[df[\"pr_id\"] == pr_id]\n",
    "        texts.extend(subset[\"body\"].dropna().tolist())\n",
    "    return texts\n",
    "\n",
    "\n",
    "def collect_pipeline_names(prefix: str, pr_id: int) -> List[str]:\n",
    "    workflows = pd.read_parquet(\n",
    "        DATASETS_DIR / f\"{prefix}_pr\" / f\"{prefix}_pr_workflow_runs.parquet\"\n",
    "    )\n",
    "    subset = workflows[workflows[\"pr_id\"] == pr_id]\n",
    "    return sorted(subset[\"workflow_name\"].dropna().unique().tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63d63ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_pr(\n",
    "    prefix: str, pr_id: int, author_type: str, pr_core: pd.DataFrame\n",
    ") -> Dict:\n",
    "    row = pr_core.loc[pr_id]\n",
    "    pipeline_names = collect_pipeline_names(prefix, pr_id)\n",
    "    comments = collect_comments(prefix, pr_id)\n",
    "    description = (row.get(\"pr_description\") or \"\").strip()\n",
    "    \n",
    "    SYSTEM_PROMPT_TEMPLATE = \"\"\"You classify evidence of performance validation for a PR.\n",
    "    Return compact JSON only with keys:\n",
    "    validation_present (bool), evidence_sources (list of \"pipeline\",\"description\",\"comments\"),\n",
    "    validation_type (benchmark,profiling,load/canary,unit-only,unspecified,none),\n",
    "    validation_description (short text),\n",
    "    pipeline_signal (short), description_signal (short), comment_signal (short).\n",
    "\n",
    "    Rules:\n",
    "    - Pipelines count only if workflow names imply perf/benchmark/load/canary; note when they are unit/lint-only.\n",
    "    - Description/comments count if they mention perf benchmarks, profiling, latency/throughput numbers,\n",
    "    load/canary rollout, A/B tests, perf tools, or explicit \"no perf validation\".\n",
    "    - If nothing indicates perf validation, set validation_present=false,\n",
    "    validation_type=\"none\", evidence_sources=[],\n",
    "    validation_description=\"No validation evidence\".\n",
    "    \"\"\"\n",
    "    \n",
    "    PROMPT_TEMPLATE = \"\"\"\n",
    "    You are given information about a GitHub Pull Request (PR).\n",
    "    Using the provided PIPELINES, DESCRIPTION, and COMMENTS, determine if there is evidence of performance validation for the PR.\n",
    "    Input (TOONS format):\n",
    "\n",
    "    PIPELINES:\n",
    "    {pipeline_names}\n",
    "\n",
    "    DESCRIPTION:\n",
    "    {description}\n",
    "\n",
    "    COMMENTS:\n",
    "    {comments}\n",
    "\n",
    "    JSON:\n",
    "    \"\"\"\n",
    "\n",
    "    if not pipeline_names and not description and not comments:\n",
    "        return {\n",
    "            \"pr_id\": pr_id,\n",
    "            \"author_type\": author_type,\n",
    "            \"repo\": f\"{row.get('repo_owner')}/{row.get('repo_name')}\",\n",
    "            \"pr_number\": row.get(\"pr_number\"),\n",
    "            \"pr_title\": row.get(\"pr_title\"),\n",
    "            \"pipeline_names\": pipeline_names,\n",
    "            \"validation_present\": False,\n",
    "            \"evidence_sources\": [],\n",
    "            \"validation_type\": \"none\",\n",
    "            \"validation_description\": \"No validation evidence\",\n",
    "            \"pipeline_signal\": \"\",\n",
    "            \"description_signal\": \"\",\n",
    "            \"comment_signal\": \"\",\n",
    "        }\n",
    "\n",
    "    prompt = PROMPT_TEMPLATE.format(\n",
    "    pipeline_names=\"\\n  - \" + \"\\n  - \".join(pipeline_names) if pipeline_names else \"  None\",\n",
    "    description=\"  \" + truncate(description).replace(\"\\n\", \"\\n  \") if description else \"  None\",\n",
    "    comments=\"  - \" + \"\\n  - \".join(truncate(\" | \".join(comments)).split(\" | \")) if comments else \"  None\",\n",
    "    )\n",
    "    \n",
    "    raw = run_llm(SYSTEM_PROMPT_TEMPLATE, prompt, type=\"gemini\")\n",
    "    parsed = extract_json(raw)\n",
    "    \n",
    "\n",
    "\n",
    "    evidence_sources = parsed.get(\"evidence_sources\") or []\n",
    "    if isinstance(evidence_sources, (tuple, list)):\n",
    "        evidence_sources = list(evidence_sources)\n",
    "\n",
    "    return {\n",
    "        \"pr_id\": pr_id,\n",
    "        \"author_type\": author_type,\n",
    "        \"repo\": f\"{row.get('repo_owner')}/{row.get('repo_name')}\",\n",
    "        \"pr_number\": row.get(\"pr_number\"),\n",
    "        \"pr_title\": row.get(\"pr_title\"),\n",
    "        \"pipeline_names\": pipeline_names,\n",
    "        \"validation_present\": parsed.get(\"validation_present\"),\n",
    "        \"evidence_sources\": evidence_sources,\n",
    "        \"validation_type\": parsed.get(\"validation_type\"),\n",
    "        \"validation_description\": parsed.get(\"validation_description\"),\n",
    "        \"pipeline_signal\": parsed.get(\"pipeline_signal\"),\n",
    "        \"description_signal\": parsed.get(\"description_signal\"),\n",
    "        \"comment_signal\": parsed.get(\"comment_signal\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "178deb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr_ids_from_commits(prefix: str, limit: Optional[int] = None) -> Iterable[int]:\n",
    "    commits = pd.read_parquet(\n",
    "        DATASETS_DIR / f\"{prefix}_pr\" / f\"{prefix}_pr_commits.parquet\"\n",
    "    )\n",
    "    pr_ids = sorted(commits[\"pr_id\"].dropna().astype(int).unique().tolist())\n",
    "    return pr_ids if limit is None else pr_ids[:limit]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e873eead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 220 existing rows from /Users/antoniozhong/Documents/dev/purdue/MSR2026/github_perf_patch_study/RQ3/rq3_validation_evidence.parquet\n",
      "Processing 104 AI PRs (starting from index 221) and 83 human PRs (total).\n",
      "Processing AI PR 1/104: 3213528854\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 2/104: 3213723251\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 3/104: 3213724164\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 4/104: 3213728031\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 5/104: 3213730809\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 6/104: 3213747226\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 7/104: 3213750237\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 8/104: 3213850102\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 9/104: 3213857892\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 10/104: 3213876116\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 11/104: 3213895675\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 12/104: 3214278956\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 13/104: 3214281732\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 14/104: 3214766453\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 15/104: 3215138589\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 16/104: 3215330137\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 17/104: 3216548273\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 18/104: 3216588034\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 19/104: 3216964251\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 20/104: 3217652543\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "[partial save] Saved 240 rows to /Users/antoniozhong/Documents/dev/purdue/MSR2026/github_perf_patch_study/RQ3/rq3_validation_evidence.parquet\n",
      "Processing AI PR 21/104: 3217675934\n",
      "Processing AI PR 22/104: 3217742863\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 23/104: 3217758395\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 24/104: 3217761016\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 25/104: 3217766297\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 26/104: 3218234090\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 27/104: 3218343296\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 28/104: 3218429525\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 29/104: 3219158589\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 30/104: 3219696751\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 31/104: 3219981823\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 32/104: 3220396620\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 33/104: 3220735806\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 34/104: 3220760486\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 35/104: 3222683231\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 36/104: 3223908947\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 37/104: 3224713270\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 38/104: 3224827777\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 39/104: 3225788754\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 40/104: 3226144762\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "[partial save] Saved 260 rows to /Users/antoniozhong/Documents/dev/purdue/MSR2026/github_perf_patch_study/RQ3/rq3_validation_evidence.parquet\n",
      "Processing AI PR 41/104: 3226180108\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 42/104: 3226639011\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 43/104: 3227169343\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 44/104: 3227405736\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 45/104: 3233988388\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 46/104: 3234031765\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 47/104: 3235100943\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 48/104: 3235179464\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 49/104: 3238396793\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 50/104: 3238582253\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 51/104: 3238674493\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 52/104: 3238720815\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 53/104: 3238723742\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 54/104: 3238737226\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 55/104: 3238739331\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 56/104: 3239263606\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 57/104: 3239403987\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 58/104: 3239561220\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 59/104: 3240006620\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 60/104: 3240460340\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "[partial save] Saved 280 rows to /Users/antoniozhong/Documents/dev/purdue/MSR2026/github_perf_patch_study/RQ3/rq3_validation_evidence.parquet\n",
      "Processing AI PR 61/104: 3240593081\n",
      "Processing AI PR 62/104: 3241057566\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 63/104: 3241523087\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 64/104: 3241690700\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 65/104: 3241691177\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 66/104: 3241695471\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 67/104: 3241758610\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 68/104: 3242128024\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 69/104: 3242396116\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 70/104: 3242666013\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 71/104: 3245509530\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 72/104: 3245861239\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 73/104: 3245892725\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 74/104: 3245899488\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 75/104: 3245927515\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 76/104: 3245957050\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 77/104: 3245970844\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 78/104: 3246099511\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 79/104: 3246105987\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 80/104: 3246117305\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "[partial save] Saved 300 rows to /Users/antoniozhong/Documents/dev/purdue/MSR2026/github_perf_patch_study/RQ3/rq3_validation_evidence.parquet\n",
      "Processing AI PR 81/104: 3246122368\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 82/104: 3246158661\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 83/104: 3246365675\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 84/104: 3246418740\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 85/104: 3246432388\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 86/104: 3250089415\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 87/104: 3250286583\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 88/104: 3250477735\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 89/104: 3252596861\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 90/104: 3253657829\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 91/104: 3253809004\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 92/104: 3254647682\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 93/104: 3257571628\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 94/104: 3257665431\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 95/104: 3258539679\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 96/104: 3261822593\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 97/104: 3262412016\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 98/104: 3262845265\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 99/104: 3262865664\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 100/104: 3262887238\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "[partial save] Saved 320 rows to /Users/antoniozhong/Documents/dev/purdue/MSR2026/github_perf_patch_study/RQ3/rq3_validation_evidence.parquet\n",
      "Processing AI PR 101/104: 3263278811\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 102/104: 3264767865\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 103/104: 3265736885\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing AI PR 104/104: 3267289370\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 1/83: 2260441374\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 2/83: 2260678480\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 3/83: 2269202548\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 4/83: 2269709704\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 5/83: 2277950711\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 6/83: 2297969098\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 7/83: 2303501996\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 8/83: 2308221415\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 9/83: 2309904375\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 10/83: 2311607019\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 11/83: 2316356365\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 12/83: 2324987642\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 13/83: 2336649960\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 14/83: 2336988355\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 15/83: 2337334370\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 16/83: 2337335339\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "[partial save] Saved 340 rows to /Users/antoniozhong/Documents/dev/purdue/MSR2026/github_perf_patch_study/RQ3/rq3_validation_evidence.parquet\n",
      "Processing human PR 17/83: 2353668916\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 18/83: 2354104157\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 19/83: 2356811134\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 20/83: 2356985296\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 21/83: 2358030784\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 22/83: 2369238232\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 23/83: 2369253951\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 24/83: 2369320781\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 25/83: 2386158448\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 26/83: 2389511160\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 27/83: 2392888093\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 28/83: 2394225726\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 29/83: 2398828721\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 30/83: 2398994327\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 31/83: 2400016065\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 32/83: 2408616836\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 33/83: 2412640161\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 34/83: 2419106029\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 35/83: 2425248848\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 36/83: 2427616889\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "[partial save] Saved 360 rows to /Users/antoniozhong/Documents/dev/purdue/MSR2026/github_perf_patch_study/RQ3/rq3_validation_evidence.parquet\n",
      "Processing human PR 37/83: 2432868443\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 38/83: 2439339242\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 39/83: 2441809617\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 40/83: 2443864788\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 41/83: 2452623588\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 42/83: 2452691617\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 43/83: 2469218203\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 44/83: 2483117033\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 45/83: 2486573779\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 46/83: 2492416622\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 47/83: 2495944314\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 48/83: 2496617006\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 49/83: 2497503442\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 50/83: 2503287360\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 51/83: 2504407177\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 52/83: 2512247973\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 53/83: 2519312120\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 54/83: 2519831355\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 55/83: 2524180167\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 56/83: 2524300649\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "[partial save] Saved 380 rows to /Users/antoniozhong/Documents/dev/purdue/MSR2026/github_perf_patch_study/RQ3/rq3_validation_evidence.parquet\n",
      "Processing human PR 57/83: 2524313861\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 58/83: 2527565003\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 59/83: 2531991252\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 60/83: 2537690761\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 61/83: 2542615571\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 62/83: 2544691147\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 63/83: 2545078467\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 64/83: 2555753483\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 65/83: 2558083620\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 66/83: 2560305820\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 67/83: 2564432253\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 68/83: 2573225924\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 69/83: 2577421996\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 70/83: 2590261382\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 71/83: 2596620305\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 72/83: 2597070258\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 73/83: 2604024784\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 74/83: 2604162624\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 75/83: 2607579182\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 76/83: 2608906245\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "[partial save] Saved 400 rows to /Users/antoniozhong/Documents/dev/purdue/MSR2026/github_perf_patch_study/RQ3/rq3_validation_evidence.parquet\n",
      "Processing human PR 77/83: 2609611207\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 78/83: 2613893429\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 79/83: 2615702170\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 80/83: 2616290996\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 81/83: 2617294066\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 82/83: 2622581875\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Processing human PR 83/83: 2623769975\n",
      "Running GEMINI, model: models/gemini-pro-latest\n",
      "Saved FINAL 407 rows to /Users/antoniozhong/Documents/dev/purdue/MSR2026/github_perf_patch_study/RQ3/rq3_validation_evidence.parquet\n",
      "No errors to log.\n"
     ]
    }
   ],
   "source": [
    "out_dir = PROJECT_ROOT / \"RQ3\"\n",
    "out_dir.mkdir(exist_ok=True, parents=True)\n",
    "out_path = out_dir / \"rq3_validation_evidence.parquet\"\n",
    "\n",
    "# Cargar progreso previo y continuar desde AI PR 221 en adelante\n",
    "if out_path.exists():\n",
    "    prev_df = pd.read_parquet(out_path)\n",
    "    records = prev_df.to_dict(orient=\"records\")\n",
    "    print(f\"Loaded {len(records)} existing rows from {out_path}\")\n",
    "else:\n",
    "    records = []\n",
    "    print(\"No existing parquet found; starting fresh records list.\")\n",
    "\n",
    "aio_core = load_pr_core(\"ai\")\n",
    "human_core = load_pr_core(\"human\")\n",
    "\n",
    "limit = None\n",
    "ai_start_index = 220  # reanudar despues de los primeros 220 PRs de AI\n",
    "\n",
    "error_log = []\n",
    "error_log_path = out_dir / \"rq3_error_log.csv\"\n",
    "\n",
    "def save_partial(records, out_path):\n",
    "    df_tmp = pd.DataFrame(records)\n",
    "    df_tmp.to_parquet(out_path, index=False)\n",
    "    print(f\"[partial save] Saved {len(df_tmp)} rows to {out_path}\")\n",
    "\n",
    "ai_ids_all = list(pr_ids_from_commits(\"ai\", limit=limit))\n",
    "human_ids = list(pr_ids_from_commits(\"human\", limit=limit))\n",
    "\n",
    "aio_ids = ai_ids_all[ai_start_index:]\n",
    "print(f\"Processing {len(aio_ids)} AI PRs (starting from index {ai_start_index + 1}) and {len(human_ids)} human PRs (total).\")\n",
    "\n",
    "# ============================\n",
    "# Process AI PRs\n",
    "# ============================\n",
    "for idx, pr_id in enumerate(aio_ids, 1):\n",
    "    print(f\"Processing AI PR {idx}/{len(aio_ids)}: {pr_id}\")\n",
    "    try:\n",
    "        result = analyze_pr(\"ai\", pr_id, \"ai_agent\", aio_core)\n",
    "        records.append(result)\n",
    "    except Exception as exc:\n",
    "        err_msg = f\"error: {exc}\"\n",
    "        print(f\"[ERROR][AI][{pr_id}] {err_msg}\")\n",
    "        error_log.append({\"pr_id\": pr_id, \"author_type\": \"ai_agent\", \"error\": err_msg})\n",
    "        records.append({\n",
    "            \"pr_id\": pr_id,\n",
    "            \"author_type\": \"ai_agent\",\n",
    "            \"repo\": \"\",\n",
    "            \"pr_number\": None,\n",
    "            \"pr_title\": \"\",\n",
    "            \"pipeline_names\": [],\n",
    "            \"validation_present\": None,\n",
    "            \"evidence_sources\": [],\n",
    "            \"validation_type\": \"error\",\n",
    "            \"validation_description\": err_msg,\n",
    "            \"pipeline_signal\": \"\",\n",
    "            \"description_signal\": \"\",\n",
    "            \"comment_signal\": \"\",\n",
    "        })\n",
    "\n",
    "    # ---- SAVE EVERY 20 ----\n",
    "    if len(records) % 20 == 0:\n",
    "        save_partial(records, out_path)\n",
    "\n",
    "# ============================\n",
    "# Process Human PRs\n",
    "# ============================\n",
    "for idx, pr_id in enumerate(human_ids, 1):\n",
    "    print(f\"Processing human PR {idx}/{len(human_ids)}: {pr_id}\")\n",
    "    try:\n",
    "        result = analyze_pr(\"human\", pr_id, \"human\", human_core)\n",
    "        records.append(result)\n",
    "    except Exception as exc:\n",
    "        err_msg = f\"error: {exc}\"\n",
    "        print(f\"[ERROR][HUMAN][{pr_id}] {err_msg}\")\n",
    "        error_log.append({\"pr_id\": pr_id, \"author_type\": \"human\", \"error\": err_msg})\n",
    "        records.append({\n",
    "            \"pr_id\": pr_id,\n",
    "            \"author_type\": \"human\",\n",
    "            \"repo\": \"\",\n",
    "            \"pr_number\": None,\n",
    "            \"pr_title\": \"\",\n",
    "            \"pipeline_names\": [],\n",
    "            \"validation_present\": None,\n",
    "            \"evidence_sources\": [],\n",
    "            \"validation_type\": \"error\",\n",
    "            \"validation_description\": err_msg,\n",
    "            \"pipeline_signal\": \"\",\n",
    "            \"description_signal\": \"\",\n",
    "            \"comment_signal\": \"\",\n",
    "        })\n",
    "\n",
    "    # ---- SAVE EVERY 20 ----\n",
    "    if len(records) % 20 == 0:\n",
    "        save_partial(records, out_path)\n",
    "\n",
    "# ============================\n",
    "# Final save\n",
    "# ============================\n",
    "df = pd.DataFrame(records)\n",
    "df.to_parquet(out_path, index=False)\n",
    "print(f\"Saved FINAL {len(df)} rows to {out_path}\")\n",
    "\n",
    "if error_log:\n",
    "    pd.DataFrame(error_log).to_csv(error_log_path, index=False)\n",
    "    print(f\"Saved {len(error_log)} error IDs to {error_log_path}\")\n",
    "else:\n",
    "    print(\"No errors to log.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e12e20c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pr_id</th>\n",
       "      <th>author_type</th>\n",
       "      <th>repo</th>\n",
       "      <th>pr_number</th>\n",
       "      <th>pr_title</th>\n",
       "      <th>pipeline_names</th>\n",
       "      <th>validation_present</th>\n",
       "      <th>evidence_sources</th>\n",
       "      <th>validation_type</th>\n",
       "      <th>validation_description</th>\n",
       "      <th>pipeline_signal</th>\n",
       "      <th>description_signal</th>\n",
       "      <th>comment_signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>2555753483</td>\n",
       "      <td>human</td>\n",
       "      <td>dotnet/msbuild</td>\n",
       "      <td>11934.0</td>\n",
       "      <td>update to stop closures from lazy functions and linq</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>[description]</td>\n",
       "      <td>profiling</td>\n",
       "      <td>The author used ILSpy to verify that closures, which were causing allocations, were removed after the changes.</td>\n",
       "      <td>No pipelines.</td>\n",
       "      <td>Fixes an allocation issue and provides before/after ILSpy screenshots to verify closures were removed.</td>\n",
       "      <td>Code review comments, no validation evidence.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>2558083620</td>\n",
       "      <td>human</td>\n",
       "      <td>bionic-gpt/bionic-gpt</td>\n",
       "      <td>776.0</td>\n",
       "      <td>Cache busting</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>none</td>\n",
       "      <td>No validation evidence</td>\n",
       "      <td>No pipelines</td>\n",
       "      <td>No description</td>\n",
       "      <td>A Cloudflare Pages deployment bot comment is present, but it contains no performance validation information.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>2560305820</td>\n",
       "      <td>human</td>\n",
       "      <td>antiwork/gumroad</td>\n",
       "      <td>289.0</td>\n",
       "      <td>Added Typhoeus client for HTTP connection pooling + re-use</td>\n",
       "      <td>[autofix.ci]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>none</td>\n",
       "      <td>No validation evidence. The PR description claims a performance improvement but provides no data, benchmarks, or profiling results to support it.</td>\n",
       "      <td>The 'autofix.ci' pipeline does not suggest performance testing.</td>\n",
       "      <td>Claims performance improvement by reusing HTTP connections but provides no data or benchmarks.</td>\n",
       "      <td>Auto-generated comments with no performance content.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>2564432253</td>\n",
       "      <td>human</td>\n",
       "      <td>tokens-studio/figma-plugin</td>\n",
       "      <td>3402.0</td>\n",
       "      <td>Github Sync Optimization</td>\n",
       "      <td>[ESLint, Node.js CI]</td>\n",
       "      <td>True</td>\n",
       "      <td>[description]</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>The PR description states the goal is to reduce 'longer sync times' and suggests a manual, qualitative test to observe the performance improvement.</td>\n",
       "      <td>Pipelines 'ESLint' and 'Node.js CI' are for linting and general continuous integration, not performance validation.</td>\n",
       "      <td>The PR description identifies 'longer sync times' as a performance issue and suggests a manual test to verify the improvement.</td>\n",
       "      <td>Comments are from bots (changeset, artifacts, code coverage) and code review feedback, with no mention of performance.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>2573225924</td>\n",
       "      <td>human</td>\n",
       "      <td>microsoft/TypeScript</td>\n",
       "      <td>61822.0</td>\n",
       "      <td>optimization, reduce memory usage</td>\n",
       "      <td>[CI, Code Scanning - Action]</td>\n",
       "      <td>True</td>\n",
       "      <td>[description, comments]</td>\n",
       "      <td>benchmark</td>\n",
       "      <td>The PR description claims an 11% speedup in project initialization time. A comment asks for the methodology used to obtain these stats.</td>\n",
       "      <td>CI and Code Scanning pipelines are not performance-related.</td>\n",
       "      <td>Claims an 11% speedup in project initialization time for tsserver in large repositories.</td>\n",
       "      <td>A comment asks how the performance statistics were determined.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>2577421996</td>\n",
       "      <td>human</td>\n",
       "      <td>antiwork/gumroad</td>\n",
       "      <td>307.0</td>\n",
       "      <td>Fixed duplicate context lookups across app</td>\n",
       "      <td>[autofix.ci]</td>\n",
       "      <td>True</td>\n",
       "      <td>[description]</td>\n",
       "      <td>benchmark</td>\n",
       "      <td>The PR description states the change saves ~4 DB queries per page load, resulting in a ~2% performance win.</td>\n",
       "      <td>The 'autofix.ci' pipeline does not appear to be for performance validation.</td>\n",
       "      <td>The description quantifies a performance improvement: 'saves ~4 DB queries per page load when logged in, resulting in a ~2% win'.</td>\n",
       "      <td>Comments are auto-generated and do not contain performance validation information.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>2590261382</td>\n",
       "      <td>human</td>\n",
       "      <td>microsoft/vscode</td>\n",
       "      <td>251382.0</td>\n",
       "      <td>Optimized concat with reduce</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>none</td>\n",
       "      <td>No validation evidence. The description claims a performance improvement ('saves resources') but provides no data to support it.</td>\n",
       "      <td>No pipelines.</td>\n",
       "      <td>The description claims resource savings by using `push` instead of `concat`.</td>\n",
       "      <td>No comments.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>2596620305</td>\n",
       "      <td>human</td>\n",
       "      <td>microsoft/qsharp</td>\n",
       "      <td>2530.0</td>\n",
       "      <td>Improve JupyterLab extension build time</td>\n",
       "      <td>[Benchmark Reports, CI Build and Test, DevSkim]</td>\n",
       "      <td>True</td>\n",
       "      <td>[pipeline, description]</td>\n",
       "      <td>benchmark</td>\n",
       "      <td>The PR description provides specific build time improvements (from ~70s to ~15s) and a 'Benchmark Reports' pipeline was executed.</td>\n",
       "      <td>A 'Benchmark Reports' pipeline was run.</td>\n",
       "      <td>The description provides specific build time improvements with before/after numbers (~70s to ~15s).</td>\n",
       "      <td>No comments provided.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>2597070258</td>\n",
       "      <td>human</td>\n",
       "      <td>calcom/cal.com</td>\n",
       "      <td>21855.0</td>\n",
       "      <td>perf: use repository for me query &amp; caching in /settings/my-account/general/ RSC</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>[description]</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>The PR description claims performance improvements from caching and faster queries, supported by before and after screencasts demonstrating the change.</td>\n",
       "      <td>No pipelines found.</td>\n",
       "      <td>Description includes a summary claiming improved performance through caching and faster queries, and provides before/after screencasts.</td>\n",
       "      <td>No performance validation mentioned.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>2604024784</td>\n",
       "      <td>human</td>\n",
       "      <td>calcom/cal.com</td>\n",
       "      <td>21923.0</td>\n",
       "      <td>fix: Improve performance of settings/admin/organizations page</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>[description, comments]</td>\n",
       "      <td>load/canary</td>\n",
       "      <td>Manual validation was performed by testing UI responsiveness with a large number of organizations (5000). The author provided before/after videos, and a reviewer tested the branch locally, though the improvement was disputed.</td>\n",
       "      <td>No pipelines.</td>\n",
       "      <td>PR description claims performance improvement by memoizing and reducing re-renders for large organization lists.</td>\n",
       "      <td>Reviewers requested before/after videos and manually tested the branch with 5000 organizations to check for performance improvements, concluding there was little difference.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>2604162624</td>\n",
       "      <td>human</td>\n",
       "      <td>antiwork/gumroad</td>\n",
       "      <td>361.0</td>\n",
       "      <td>Improved Sidekiq scheduling efficiency for `LargeSellersUpdateUserBal</td>\n",
       "      <td>[autofix.ci]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>none</td>\n",
       "      <td>The PR implements a performance optimization by using bulk job enqueuing. However, there is no evidence of validation; the claims of improved efficiency in the description and comments are not supported by any metrics, benchmarks, or profiling results.</td>\n",
       "      <td>The 'autofix.ci' pipeline does not indicate performance testing.</td>\n",
       "      <td>Description claims improved efficiency ('much more efficiently') but lacks metrics or benchmark results.</td>\n",
       "      <td>Comments praise the change as a 'performance optimization' but provide no quantitative validation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>2607579182</td>\n",
       "      <td>human</td>\n",
       "      <td>gofiber/fiber</td>\n",
       "      <td>3532.0</td>\n",
       "      <td>Improve performance #3476</td>\n",
       "      <td>[Benchmark, CodeQL, Run govulncheck, Test, golangci-lint, markdownlint]</td>\n",
       "      <td>True</td>\n",
       "      <td>[pipeline, description]</td>\n",
       "      <td>benchmark</td>\n",
       "      <td>A 'Benchmark' pipeline is present, and the PR description states the goal is to improve performance. However, the checklist item for providing benchmarks in the description is unchecked.</td>\n",
       "      <td>A 'Benchmark' pipeline is present.</td>\n",
       "      <td>The PR description aims to 'Improve the performance' but a checklist item '[ ] Provided benchmarks for the new code' is unchecked.</td>\n",
       "      <td>No performance validation signals found in comments.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>2608906245</td>\n",
       "      <td>human</td>\n",
       "      <td>antiwork/gumroad</td>\n",
       "      <td>397.0</td>\n",
       "      <td>Cached repetitive data lookups for creator analytics</td>\n",
       "      <td>[autofix.ci]</td>\n",
       "      <td>True</td>\n",
       "      <td>[description, comments]</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>The PR is a performance optimization that introduces caching. Validation is implied through the description and code review comments confirming the fix, but no quantitative benchmarks or profiling data are provided.</td>\n",
       "      <td>The 'autofix.ci' pipeline does not appear to be related to performance testing.</td>\n",
       "      <td>The description explicitly mentions 'Performance Improvements' and explains how caching will enhance analytics performance and reduce redundant queries.</td>\n",
       "      <td>Automated comments confirm the change is a 'performance optimization' by preventing redundant database queries, but lack quantitative data.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>2609611207</td>\n",
       "      <td>human</td>\n",
       "      <td>TracecatHQ/tracecat</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>perf(engine): Disable worker eager execution to try distribute load</td>\n",
       "      <td>[Lint python, pytest]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>none</td>\n",
       "      <td>No validation evidence. The PR description mentions a change to improve load distribution but provides no data or benchmark results. The pipelines are for linting and unit tests.</td>\n",
       "      <td>Pipelines are for linting and unit tests (pytest), not performance.</td>\n",
       "      <td>Describes a change intended to improve load distribution but provides no validation data.</td>\n",
       "      <td>No comments.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>2613893429</td>\n",
       "      <td>human</td>\n",
       "      <td>oven-sh/bun</td>\n",
       "      <td>20612.0</td>\n",
       "      <td>Optimize  `napi_get_value_string_utf8` `napi_get_value_string_latin1`  `napi_get_value_string_utf16`</td>\n",
       "      <td>[Codex Test Sync, Glob Sources, Lint, Typos, format]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>none</td>\n",
       "      <td>No validation evidence found. The PR description only states 'It compiled' for verification, and pipelines are for linting and testing, not performance.</td>\n",
       "      <td>Pipelines are for linting, formatting, and testing, not performance.</td>\n",
       "      <td>Description mentions a potential optimization but verification is only 'It compiled'.</td>\n",
       "      <td>Comments show a build failure and instructions for local testing, no performance data.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>2615702170</td>\n",
       "      <td>human</td>\n",
       "      <td>bruin-data/ingestr</td>\n",
       "      <td>264.0</td>\n",
       "      <td>patch/propagate extract parallelism</td>\n",
       "      <td>[.github/workflows/tests.yml, secrets_scan]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>none</td>\n",
       "      <td>No validation evidence</td>\n",
       "      <td>Pipeline names (tests.yml, secrets_scan) do not suggest performance testing.</td>\n",
       "      <td>The description mentions changes related to performance (parallelism) but provides no data or results.</td>\n",
       "      <td>No comments.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>2616290996</td>\n",
       "      <td>human</td>\n",
       "      <td>roboflow/inference</td>\n",
       "      <td>1385.0</td>\n",
       "      <td> Speed up method `WithFixedSizeCache.add_model` by 50% in PR #1373 (`feat/pass-countinference-to-serverless-getweights`)</td>\n",
       "      <td>[Codeflash Optimization]</td>\n",
       "      <td>True</td>\n",
       "      <td>[description]</td>\n",
       "      <td>benchmark</td>\n",
       "      <td>The PR description provides specific benchmark results, showing a 50% speedup for a function, with runtime decreasing from 1.08 seconds to 722 milliseconds. It also details the profiling-driven optimizations made.</td>\n",
       "      <td>The pipeline name 'Codeflash Optimization' is ambiguous and does not explicitly indicate performance testing.</td>\n",
       "      <td>Description explicitly states a '50% (0.50x) speedup' with before and after runtimes (1.08s -&gt; 722ms) and details profiling-driven optimizations.</td>\n",
       "      <td>No comments.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>2617294066</td>\n",
       "      <td>human</td>\n",
       "      <td>appsmithorg/appsmith</td>\n",
       "      <td>41033.0</td>\n",
       "      <td>chore: ce changes related to decoupling webworker</td>\n",
       "      <td>[Close Labeler, Copy labels from a connected issue to the PR, Label PRs based on title, PR Automation test suite, Quality checks]</td>\n",
       "      <td>True</td>\n",
       "      <td>[description]</td>\n",
       "      <td>benchmark</td>\n",
       "      <td>The PR description explicitly states a performance improvement goal of reducing LCP by 1.8-2.2 seconds and details the technical changes made to achieve this, such as code splitting and deferred rendering.</td>\n",
       "      <td>Pipelines are for general automation, quality checks, and functional tests (Cypress), not performance validation.</td>\n",
       "      <td>The description states a goal of improving LCP by 1.8-2.2 seconds and details several performance-enhancing changes like code splitting and deferred rendering.</td>\n",
       "      <td>Comments are auto-generated summaries of the code changes, which are performance-related, but provide no new validation evidence.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>2622581875</td>\n",
       "      <td>human</td>\n",
       "      <td>dotnet/runtime</td>\n",
       "      <td>117071.0</td>\n",
       "      <td>Reduce HTTP headers validation overhead</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>[description]</td>\n",
       "      <td>benchmark</td>\n",
       "      <td>The PR description includes a detailed benchmark table showing significant improvements in latency and memory allocation for header operations, along with the complete benchmark code.</td>\n",
       "      <td>No pipelines.</td>\n",
       "      <td>Detailed benchmark results table and benchmark code provided, showing improvements in latency and memory allocation.</td>\n",
       "      <td>Technical discussion about implementation details and correctness.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>2623769975</td>\n",
       "      <td>human</td>\n",
       "      <td>antiwork/gumroad</td>\n",
       "      <td>471.0</td>\n",
       "      <td>Preloaded thumbnail variants to avoid n+1 SQL queries</td>\n",
       "      <td>[autofix.ci]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>none</td>\n",
       "      <td>The PR description and comments state the change is a performance optimization to fix N+1 queries, but no benchmarks, profiling, or other quantitative data is provided to validate the improvement.</td>\n",
       "      <td>The 'autofix.ci' pipeline does not suggest performance testing.</td>\n",
       "      <td>Description claims performance improvement by reducing DB queries but provides no validation data.</td>\n",
       "      <td>Comments identify the change as a performance optimization but lack quantitative validation.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pr_id author_type                        repo  pr_number  \\\n",
       "387  2555753483       human              dotnet/msbuild    11934.0   \n",
       "388  2558083620       human       bionic-gpt/bionic-gpt      776.0   \n",
       "389  2560305820       human            antiwork/gumroad      289.0   \n",
       "390  2564432253       human  tokens-studio/figma-plugin     3402.0   \n",
       "391  2573225924       human        microsoft/TypeScript    61822.0   \n",
       "392  2577421996       human            antiwork/gumroad      307.0   \n",
       "393  2590261382       human            microsoft/vscode   251382.0   \n",
       "394  2596620305       human            microsoft/qsharp     2530.0   \n",
       "395  2597070258       human              calcom/cal.com    21855.0   \n",
       "396  2604024784       human              calcom/cal.com    21923.0   \n",
       "397  2604162624       human            antiwork/gumroad      361.0   \n",
       "398  2607579182       human               gofiber/fiber     3532.0   \n",
       "399  2608906245       human            antiwork/gumroad      397.0   \n",
       "400  2609611207       human         TracecatHQ/tracecat     1213.0   \n",
       "401  2613893429       human                 oven-sh/bun    20612.0   \n",
       "402  2615702170       human          bruin-data/ingestr      264.0   \n",
       "403  2616290996       human          roboflow/inference     1385.0   \n",
       "404  2617294066       human        appsmithorg/appsmith    41033.0   \n",
       "405  2622581875       human              dotnet/runtime   117071.0   \n",
       "406  2623769975       human            antiwork/gumroad      471.0   \n",
       "\n",
       "                                                                                                                       pr_title  \\\n",
       "387                                                                        update to stop closures from lazy functions and linq   \n",
       "388                                                                                                               Cache busting   \n",
       "389                                                                  Added Typhoeus client for HTTP connection pooling + re-use   \n",
       "390                                                                                                    Github Sync Optimization   \n",
       "391                                                                                           optimization, reduce memory usage   \n",
       "392                                                                                  Fixed duplicate context lookups across app   \n",
       "393                                                                                                Optimized concat with reduce   \n",
       "394                                                                                     Improve JupyterLab extension build time   \n",
       "395                                            perf: use repository for me query & caching in /settings/my-account/general/ RSC   \n",
       "396                                                               fix: Improve performance of settings/admin/organizations page   \n",
       "397                                                      Improved Sidekiq scheduling efficiency for `LargeSellersUpdateUserBal   \n",
       "398                                                                                                   Improve performance #3476   \n",
       "399                                                                        Cached repetitive data lookups for creator analytics   \n",
       "400                                                         perf(engine): Disable worker eager execution to try distribute load   \n",
       "401                        Optimize  `napi_get_value_string_utf8` `napi_get_value_string_latin1`  `napi_get_value_string_utf16`   \n",
       "402                                                                                         patch/propagate extract parallelism   \n",
       "403   Speed up method `WithFixedSizeCache.add_model` by 50% in PR #1373 (`feat/pass-countinference-to-serverless-getweights`)   \n",
       "404                                                                           chore: ce changes related to decoupling webworker   \n",
       "405                                                                                     Reduce HTTP headers validation overhead   \n",
       "406                                                                       Preloaded thumbnail variants to avoid n+1 SQL queries   \n",
       "\n",
       "                                                                                                                        pipeline_names  \\\n",
       "387                                                                                                                                 []   \n",
       "388                                                                                                                                 []   \n",
       "389                                                                                                                       [autofix.ci]   \n",
       "390                                                                                                               [ESLint, Node.js CI]   \n",
       "391                                                                                                       [CI, Code Scanning - Action]   \n",
       "392                                                                                                                       [autofix.ci]   \n",
       "393                                                                                                                                 []   \n",
       "394                                                                                    [Benchmark Reports, CI Build and Test, DevSkim]   \n",
       "395                                                                                                                                 []   \n",
       "396                                                                                                                                 []   \n",
       "397                                                                                                                       [autofix.ci]   \n",
       "398                                                            [Benchmark, CodeQL, Run govulncheck, Test, golangci-lint, markdownlint]   \n",
       "399                                                                                                                       [autofix.ci]   \n",
       "400                                                                                                              [Lint python, pytest]   \n",
       "401                                                                               [Codex Test Sync, Glob Sources, Lint, Typos, format]   \n",
       "402                                                                                        [.github/workflows/tests.yml, secrets_scan]   \n",
       "403                                                                                                           [Codeflash Optimization]   \n",
       "404  [Close Labeler, Copy labels from a connected issue to the PR, Label PRs based on title, PR Automation test suite, Quality checks]   \n",
       "405                                                                                                                                 []   \n",
       "406                                                                                                                       [autofix.ci]   \n",
       "\n",
       "    validation_present         evidence_sources validation_type  \\\n",
       "387               True            [description]       profiling   \n",
       "388              False                       []            none   \n",
       "389              False                       []            none   \n",
       "390               True            [description]     unspecified   \n",
       "391               True  [description, comments]       benchmark   \n",
       "392               True            [description]       benchmark   \n",
       "393              False                       []            none   \n",
       "394               True  [pipeline, description]       benchmark   \n",
       "395               True            [description]     unspecified   \n",
       "396               True  [description, comments]     load/canary   \n",
       "397              False                       []            none   \n",
       "398               True  [pipeline, description]       benchmark   \n",
       "399               True  [description, comments]     unspecified   \n",
       "400              False                       []            none   \n",
       "401              False                       []            none   \n",
       "402              False                       []            none   \n",
       "403               True            [description]       benchmark   \n",
       "404               True            [description]       benchmark   \n",
       "405               True            [description]       benchmark   \n",
       "406              False                       []            none   \n",
       "\n",
       "                                                                                                                                                                                                                                           validation_description  \\\n",
       "387                                                                                                                                                The author used ILSpy to verify that closures, which were causing allocations, were removed after the changes.   \n",
       "388                                                                                                                                                                                                                                        No validation evidence   \n",
       "389                                                                                                             No validation evidence. The PR description claims a performance improvement but provides no data, benchmarks, or profiling results to support it.   \n",
       "390                                                                                                           The PR description states the goal is to reduce 'longer sync times' and suggests a manual, qualitative test to observe the performance improvement.   \n",
       "391                                                                                                                       The PR description claims an 11% speedup in project initialization time. A comment asks for the methodology used to obtain these stats.   \n",
       "392                                                                                                                                                   The PR description states the change saves ~4 DB queries per page load, resulting in a ~2% performance win.   \n",
       "393                                                                                                                              No validation evidence. The description claims a performance improvement ('saves resources') but provides no data to support it.   \n",
       "394                                                                                                                             The PR description provides specific build time improvements (from ~70s to ~15s) and a 'Benchmark Reports' pipeline was executed.   \n",
       "395                                                                                                       The PR description claims performance improvements from caching and faster queries, supported by before and after screencasts demonstrating the change.   \n",
       "396                             Manual validation was performed by testing UI responsiveness with a large number of organizations (5000). The author provided before/after videos, and a reviewer tested the branch locally, though the improvement was disputed.   \n",
       "397  The PR implements a performance optimization by using bulk job enqueuing. However, there is no evidence of validation; the claims of improved efficiency in the description and comments are not supported by any metrics, benchmarks, or profiling results.   \n",
       "398                                                                    A 'Benchmark' pipeline is present, and the PR description states the goal is to improve performance. However, the checklist item for providing benchmarks in the description is unchecked.   \n",
       "399                                       The PR is a performance optimization that introduces caching. Validation is implied through the description and code review comments confirming the fix, but no quantitative benchmarks or profiling data are provided.   \n",
       "400                                                                            No validation evidence. The PR description mentions a change to improve load distribution but provides no data or benchmark results. The pipelines are for linting and unit tests.   \n",
       "401                                                                                                      No validation evidence found. The PR description only states 'It compiled' for verification, and pipelines are for linting and testing, not performance.   \n",
       "402                                                                                                                                                                                                                                        No validation evidence   \n",
       "403                                         The PR description provides specific benchmark results, showing a 50% speedup for a function, with runtime decreasing from 1.08 seconds to 722 milliseconds. It also details the profiling-driven optimizations made.   \n",
       "404                                                 The PR description explicitly states a performance improvement goal of reducing LCP by 1.8-2.2 seconds and details the technical changes made to achieve this, such as code splitting and deferred rendering.   \n",
       "405                                                                       The PR description includes a detailed benchmark table showing significant improvements in latency and memory allocation for header operations, along with the complete benchmark code.   \n",
       "406                                                          The PR description and comments state the change is a performance optimization to fix N+1 queries, but no benchmarks, profiling, or other quantitative data is provided to validate the improvement.   \n",
       "\n",
       "                                                                                                         pipeline_signal  \\\n",
       "387                                                                                                        No pipelines.   \n",
       "388                                                                                                         No pipelines   \n",
       "389                                                      The 'autofix.ci' pipeline does not suggest performance testing.   \n",
       "390  Pipelines 'ESLint' and 'Node.js CI' are for linting and general continuous integration, not performance validation.   \n",
       "391                                                          CI and Code Scanning pipelines are not performance-related.   \n",
       "392                                          The 'autofix.ci' pipeline does not appear to be for performance validation.   \n",
       "393                                                                                                        No pipelines.   \n",
       "394                                                                              A 'Benchmark Reports' pipeline was run.   \n",
       "395                                                                                                  No pipelines found.   \n",
       "396                                                                                                        No pipelines.   \n",
       "397                                                     The 'autofix.ci' pipeline does not indicate performance testing.   \n",
       "398                                                                                   A 'Benchmark' pipeline is present.   \n",
       "399                                      The 'autofix.ci' pipeline does not appear to be related to performance testing.   \n",
       "400                                                  Pipelines are for linting and unit tests (pytest), not performance.   \n",
       "401                                                 Pipelines are for linting, formatting, and testing, not performance.   \n",
       "402                                         Pipeline names (tests.yml, secrets_scan) do not suggest performance testing.   \n",
       "403        The pipeline name 'Codeflash Optimization' is ambiguous and does not explicitly indicate performance testing.   \n",
       "404    Pipelines are for general automation, quality checks, and functional tests (Cypress), not performance validation.   \n",
       "405                                                                                                        No pipelines.   \n",
       "406                                                      The 'autofix.ci' pipeline does not suggest performance testing.   \n",
       "\n",
       "                                                                                                                                                  description_signal  \\\n",
       "387                                                           Fixes an allocation issue and provides before/after ILSpy screenshots to verify closures were removed.   \n",
       "388                                                                                                                                                   No description   \n",
       "389                                                                   Claims performance improvement by reusing HTTP connections but provides no data or benchmarks.   \n",
       "390                                   The PR description identifies 'longer sync times' as a performance issue and suggests a manual test to verify the improvement.   \n",
       "391                                                                         Claims an 11% speedup in project initialization time for tsserver in large repositories.   \n",
       "392                                The description quantifies a performance improvement: 'saves ~4 DB queries per page load when logged in, resulting in a ~2% win'.   \n",
       "393                                                                                     The description claims resource savings by using `push` instead of `concat`.   \n",
       "394                                                              The description provides specific build time improvements with before/after numbers (~70s to ~15s).   \n",
       "395                          Description includes a summary claiming improved performance through caching and faster queries, and provides before/after screencasts.   \n",
       "396                                                 PR description claims performance improvement by memoizing and reducing re-renders for large organization lists.   \n",
       "397                                                         Description claims improved efficiency ('much more efficiently') but lacks metrics or benchmark results.   \n",
       "398                               The PR description aims to 'Improve the performance' but a checklist item '[ ] Provided benchmarks for the new code' is unchecked.   \n",
       "399         The description explicitly mentions 'Performance Improvements' and explains how caching will enhance analytics performance and reduce redundant queries.   \n",
       "400                                                                        Describes a change intended to improve load distribution but provides no validation data.   \n",
       "401                                                                            Description mentions a potential optimization but verification is only 'It compiled'.   \n",
       "402                                                           The description mentions changes related to performance (parallelism) but provides no data or results.   \n",
       "403                Description explicitly states a '50% (0.50x) speedup' with before and after runtimes (1.08s -> 722ms) and details profiling-driven optimizations.   \n",
       "404  The description states a goal of improving LCP by 1.8-2.2 seconds and details several performance-enhancing changes like code splitting and deferred rendering.   \n",
       "405                                             Detailed benchmark results table and benchmark code provided, showing improvements in latency and memory allocation.   \n",
       "406                                                               Description claims performance improvement by reducing DB queries but provides no validation data.   \n",
       "\n",
       "                                                                                                                                                                    comment_signal  \n",
       "387                                                                                                                                  Code review comments, no validation evidence.  \n",
       "388                                                                   A Cloudflare Pages deployment bot comment is present, but it contains no performance validation information.  \n",
       "389                                                                                                                           Auto-generated comments with no performance content.  \n",
       "390                                                         Comments are from bots (changeset, artifacts, code coverage) and code review feedback, with no mention of performance.  \n",
       "391                                                                                                                 A comment asks how the performance statistics were determined.  \n",
       "392                                                                                             Comments are auto-generated and do not contain performance validation information.  \n",
       "393                                                                                                                                                                   No comments.  \n",
       "394                                                                                                                                                          No comments provided.  \n",
       "395                                                                                                                                           No performance validation mentioned.  \n",
       "396  Reviewers requested before/after videos and manually tested the branch with 5000 organizations to check for performance improvements, concluding there was little difference.  \n",
       "397                                                                             Comments praise the change as a 'performance optimization' but provide no quantitative validation.  \n",
       "398                                                                                                                           No performance validation signals found in comments.  \n",
       "399                                    Automated comments confirm the change is a 'performance optimization' by preventing redundant database queries, but lack quantitative data.  \n",
       "400                                                                                                                                                                   No comments.  \n",
       "401                                                                                         Comments show a build failure and instructions for local testing, no performance data.  \n",
       "402                                                                                                                                                                   No comments.  \n",
       "403                                                                                                                                                                   No comments.  \n",
       "404                                              Comments are auto-generated summaries of the code changes, which are performance-related, but provide no new validation evidence.  \n",
       "405                                                                                                             Technical discussion about implementation details and correctness.  \n",
       "406                                                                                   Comments identify the change as a performance optimization but lack quantitative validation.  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.expand_frame_repr\", True)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "data_temp = pd.read_parquet(out_path)\n",
    "data_temp.tail(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
