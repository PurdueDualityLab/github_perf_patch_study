{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e02c32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.11/site-packages (2.6.1)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (0.11.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (2.12.3)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install openai pandas python-dotenv\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Optional, Tuple\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3675577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List, Literal\n",
    "\n",
    "\n",
    "class ValidationSchema(BaseModel):\n",
    "    validation_present: bool\n",
    "\n",
    "    evidence_sources: List[\n",
    "        Literal[\"pipeline\", \"description\", \"comments\", \"code_diff\"]\n",
    "    ]\n",
    "\n",
    "    validation_type: Literal[\n",
    "        \"benchmark\",\n",
    "        \"profiling\",\n",
    "        \"static-analysis\",\n",
    "        \"anecdotal\",\n",
    "        \"none\"\n",
    "    ]\n",
    "\n",
    "    validation_description: str\n",
    "    pipeline_signal: str\n",
    "    description_signal: str\n",
    "    comment_signal: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b648581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_llm(prompt: str, user_prompt: str) -> ValidationSchema:\n",
    "    LLM_BASE_URL = None\n",
    "    LLM_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    llm_client = OpenAI(base_url=LLM_BASE_URL, api_key=LLM_API_KEY)\n",
    "    \n",
    "    model = \"gpt-5.1-2025-11-13\"\n",
    "    print(\"Running OPENAI, model:\", model)\n",
    "\n",
    "    r = llm_client.responses.parse(\n",
    "        model=model,\n",
    "        reasoning={\"effort\": \"high\"},\n",
    "        instructions=prompt,\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt\n",
    "            }\n",
    "        ],\n",
    "        text_format=ValidationSchema,\n",
    "    )\n",
    "\n",
    "    result: ValidationSchema = r.output_parsed\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf5fc590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_datasets_dir(start: Optional[Path] = None) -> Path:\n",
    "    start = start or Path.cwd()\n",
    "    for path in (start, *start.parents):\n",
    "        candidate = path / \"datasets\"\n",
    "        if candidate.exists():\n",
    "            return candidate\n",
    "    raise FileNotFoundError(f\"Could not find 'datasets' directory from {start}\")\n",
    "\n",
    "\n",
    "DATASETS_DIR = find_datasets_dir()\n",
    "PROJECT_ROOT = DATASETS_DIR.parent\n",
    "\n",
    "def truncate(text: str, limit: int = 15000) -> str:\n",
    "    return text if len(text) <= limit else text[:limit] + \"...[truncated]\"\n",
    "\n",
    "def load_pr_core(prefix: str) -> pd.DataFrame:\n",
    "    commits = pd.read_parquet(\n",
    "        DATASETS_DIR / f\"{prefix}_pr\" / f\"{prefix}_pr_commits.parquet\"\n",
    "    )\n",
    "    return commits.drop_duplicates(\"pr_id\").set_index(\"pr_id\")\n",
    "\n",
    "\n",
    "def collect_comments(prefix: str, pr_id: int) -> List[str]:\n",
    "    issue = pd.read_parquet(\n",
    "        DATASETS_DIR / f\"{prefix}_pr\" / f\"{prefix}_pr_issue_comments.parquet\"\n",
    "    )\n",
    "    review = pd.read_parquet(\n",
    "        DATASETS_DIR / f\"{prefix}_pr\" / f\"{prefix}_pr_review_comments.parquet\"\n",
    "    )\n",
    "    texts = []\n",
    "    for df in (issue, review):\n",
    "        subset = df[df[\"pr_id\"] == pr_id]\n",
    "        texts.extend(subset[\"body\"].dropna().tolist())\n",
    "    return texts\n",
    "\n",
    "\n",
    "def collect_pipeline_names(prefix: str, pr_id: int) -> List[str]:\n",
    "    workflows = pd.read_parquet(\n",
    "        DATASETS_DIR / f\"{prefix}_pr\" / f\"{prefix}_pr_workflow_runs.parquet\"\n",
    "    )\n",
    "    subset = workflows[workflows[\"pr_id\"] == pr_id]\n",
    "    return sorted(subset[\"workflow_name\"].dropna().unique().tolist())\n",
    "\n",
    "def pr_ids_from_commits(prefix: str, limit: Optional[int] = None) -> Iterable[int]:\n",
    "    commits = pd.read_parquet(\n",
    "        DATASETS_DIR / f\"{prefix}_pr\" / f\"{prefix}_pr_commits.parquet\"\n",
    "    )\n",
    "    pr_ids = sorted(commits[\"pr_id\"].dropna().astype(int).unique().tolist())\n",
    "    return pr_ids if limit is None else pr_ids[:limit]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdf370ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_pr(\n",
    "    prefix: str,\n",
    "    pr_id: int,\n",
    "    author_type: str,\n",
    "    pr_core: pd.DataFrame,\n",
    ") -> Tuple[Dict, Dict]:\n",
    "    row = pr_core.loc[pr_id]\n",
    "    pipeline_names = collect_pipeline_names(prefix, pr_id)\n",
    "    comments = collect_comments(prefix, pr_id)\n",
    "    description = (row.get(\"pr_description\") or \"\").strip()\n",
    "    code_diff = (row.get(\"patch\") or \"\").strip()\n",
    "\n",
    "    DEVELOPER_PROMPT_TEMPLATE = \"\"\"\n",
    "    You are a classifier for performance validation evidence in GitHub Pull Requests (PRs).\n",
    "\n",
    "    Your job is to decide whether there is explicit performance validation, and if so,\n",
    "    to classify it into EXACTLY ONE validation_type category based on the definitions below.\n",
    "\n",
    "    First, carefully read and internalize these validation_type categories:\n",
    "\n",
    "    1. Benchmark-Based Validation (Unit Tests or Microbenchmarks)\n",
    "    Definition:\n",
    "    The PR validates performance by running benchmark tests—either existing unit tests or newly added benchmark/microbenchmark tests. It includes explicit before-and-after comparisons such as runtime, throughput, memory, CPU usage, or any quantitative metric collected from tests.\n",
    "\n",
    "    2. Profiling-Based Validation (Application- or Function-Level Profiling)\n",
    "    Definition:\n",
    "    The PR uses profiling tools to validate performance, typically capturing stack samples, CPU hotspots, flamegraphs, or function-level timings. Evidence includes profiling outputs before and after the change.\n",
    "\n",
    "    3. Static-Analysis-Based Validation (Reasoning Without Runtime Evidence)\n",
    "    Definition:\n",
    "    The PR argues for performance improvement through static reasoning about the code—algorithmic complexity, data-structure changes, loop bounds, allocation count reduction, etc., without providing runtime/profiling data.\n",
    "\n",
    "    4. Anecdotal or Informal Local Testing (No Evidence Provided)\n",
    "    Definition:\n",
    "    The PR claims that performance is improved based on local testing, intuition, or manual observation, but provides no quantitative metrics, no profiling output, and no static-analysis justification.\n",
    "\n",
    "    Decision Rules:\n",
    "\n",
    "    1) First decide if performance validation is explicitly present (validation_present).\n",
    "    - Set validation_present = TRUE only when the PR explicitly shows some form of validation evidence: benchmarks/microbenchmarks, profiling traces, static performance reasoning, or explicit local testing statements.\n",
    "    - Do NOT infer validation from performance intent alone.\n",
    "\n",
    "    2) If validation_present is \"FALSE\", please set validation_type = \"none\", also set evidence_sources = [] also set validation_description to explain the absence of validation. Never assign any other validation_type.\n",
    "    \n",
    "    3) If validation_present is \"TRUE\", please choose exactly ONE non-\"none\" validation_type from the following: Benchmark-Based Validation; Profiling-Based Validation; Static-Analysis-Based Validation; Anecdotal or Informal Local Testing\n",
    "\n",
    "    4) evidence_sources must list where the validation is explicitly mentioned: \"pipeline\", \"description\", \"comments\", \"code_diff\"\n",
    "\n",
    "    5) When validation_type is \"benchmark\", \"profiling\": mention the metrics used (latency, throughput, memory, CPU, etc.).\n",
    "\n",
    "    You must ALWAYS return STRICT JSON with exactly these keys: validation_present, evidence_sources, validation_type, metrics, validation_description, pipeline_signal, description_signal, comment_signal.\n",
    "\n",
    "    No extra commentary. No markdown. No explanations.\n",
    "    \"\"\"\n",
    "\n",
    "    USER_PROMPT_TEMPLATE = \"\"\"\n",
    "    Classify the following PR strictly using the rules and definitions from the system.\n",
    "\n",
    "    PIPELINES:\n",
    "    {pipeline_names}\n",
    "\n",
    "    DESCRIPTION:\n",
    "    {description}\n",
    "\n",
    "    COMMENTS:\n",
    "    {comments}\n",
    "    \n",
    "    CODE DIFF:\n",
    "    {code_diff}\n",
    "    \"\"\"\n",
    "\n",
    "    if not pipeline_names and not description and not comments and not code_diff:\n",
    "        print(f\"Short-circuiting PR {pr_id} with no signals\")\n",
    "        print(f\"pipeline_names: {pipeline_names}\")\n",
    "        print(f\"description: {description}\")\n",
    "        print(f\"comments: {comments}\")\n",
    "        print(f\"code_diff: {code_diff}\")\n",
    "        raise Exception(\"No signals present\")\n",
    "\n",
    "    prompt = USER_PROMPT_TEMPLATE.format(\n",
    "        pipeline_names=\"- \" + \"- \".join(pipeline_names) if pipeline_names else \"None\",\n",
    "        description=truncate(description) if description else \"None\",\n",
    "        comments=\"- \" + \"- \".join(truncate(\" | \".join(comments)).split(\" | \")) if comments else \"None\",\n",
    "        code_diff=truncate(code_diff) if code_diff else \"None\",\n",
    "    )\n",
    "\n",
    "    developer_prompt = DEVELOPER_PROMPT_TEMPLATE\n",
    "\n",
    "    raw_openai = \"\"\n",
    "    try:\n",
    "        raw_openai = run_llm(\n",
    "            prompt=developer_prompt,\n",
    "            user_prompt=prompt,\n",
    "        ).model_dump()\n",
    "    except Exception as exc:\n",
    "        raise exc\n",
    "\n",
    "    parsed_openai = raw_openai\n",
    "\n",
    "    evidence_sources = parsed_openai.get(\"evidence_sources\") or []\n",
    "    if isinstance(evidence_sources, (tuple, list)):\n",
    "        evidence_sources = list(evidence_sources)\n",
    "    else:\n",
    "        evidence_sources = []\n",
    "\n",
    "    result_openai = {\n",
    "        \"pr_id\": pr_id,\n",
    "        \"author_type\": author_type,\n",
    "        \"repo\": f\"{row.get('repo_owner')}/{row.get('repo_name')}\",\n",
    "        \"pr_number\": row.get(\"pr_number\"),\n",
    "        \"pr_title\": row.get(\"pr_title\"),\n",
    "        \"pipeline_names\": pipeline_names,\n",
    "        \"validation_present\": parsed_openai.get(\"validation_present\", False),\n",
    "        \"evidence_sources\": evidence_sources,\n",
    "        \"validation_type\": parsed_openai.get(\"validation_type\", \"none\"),\n",
    "        \"validation_description\": parsed_openai.get(\"validation_description\", \"No validation evidence\"),\n",
    "        \"pipeline_signal\": parsed_openai.get(\"pipeline_signal\", \"\"),\n",
    "        \"description_signal\": parsed_openai.get(\"description_signal\", \"\"),\n",
    "        \"comment_signal\": parsed_openai.get(\"comment_signal\", \"\"),\n",
    "    }\n",
    "\n",
    "    return result_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "382d25bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resume] Loaded 405 existing records\n",
      "Processing 324 AI PRs and 83 human PRs (first None each).\n",
      "[skip] AI PR 1/324 already processed: 2766896431\n",
      "[skip] AI PR 2/324 already processed: 2843312341\n",
      "[skip] AI PR 3/324 already processed: 2843334531\n",
      "[skip] AI PR 4/324 already processed: 2855302194\n",
      "[skip] AI PR 5/324 already processed: 2859989652\n",
      "[skip] AI PR 6/324 already processed: 2887787232\n",
      "[skip] AI PR 7/324 already processed: 2920983723\n",
      "[skip] AI PR 8/324 already processed: 2926188053\n",
      "[skip] AI PR 9/324 already processed: 2927184629\n",
      "[skip] AI PR 10/324 already processed: 2973653748\n",
      "[skip] AI PR 11/324 already processed: 2991070962\n",
      "[skip] AI PR 12/324 already processed: 3006445782\n",
      "[skip] AI PR 13/324 already processed: 3006507938\n",
      "[skip] AI PR 14/324 already processed: 3006534682\n",
      "[skip] AI PR 15/324 already processed: 3006544045\n",
      "[skip] AI PR 16/324 already processed: 3006562482\n",
      "[skip] AI PR 17/324 already processed: 3033566586\n",
      "[skip] AI PR 18/324 already processed: 3033886992\n",
      "[skip] AI PR 19/324 already processed: 3034903835\n",
      "[skip] AI PR 20/324 already processed: 3034997303\n",
      "[skip] AI PR 21/324 already processed: 3039380315\n",
      "[skip] AI PR 22/324 already processed: 3042979666\n",
      "[skip] AI PR 23/324 already processed: 3046430027\n",
      "[skip] AI PR 24/324 already processed: 3046771940\n",
      "[skip] AI PR 25/324 already processed: 3049300237\n",
      "[skip] AI PR 26/324 already processed: 3049320746\n",
      "[skip] AI PR 27/324 already processed: 3052357500\n",
      "[skip] AI PR 28/324 already processed: 3053325093\n",
      "[skip] AI PR 29/324 already processed: 3053649404\n",
      "[skip] AI PR 30/324 already processed: 3061069405\n",
      "[skip] AI PR 31/324 already processed: 3070150168\n",
      "[skip] AI PR 32/324 already processed: 3070165463\n",
      "[skip] AI PR 33/324 already processed: 3070227634\n",
      "[skip] AI PR 34/324 already processed: 3070233885\n",
      "[skip] AI PR 35/324 already processed: 3070310257\n",
      "[skip] AI PR 36/324 already processed: 3070322024\n",
      "[skip] AI PR 37/324 already processed: 3071077630\n",
      "[skip] AI PR 38/324 already processed: 3071083444\n",
      "[skip] AI PR 39/324 already processed: 3071827885\n",
      "[skip] AI PR 40/324 already processed: 3073532077\n",
      "[skip] AI PR 41/324 already processed: 3073998720\n",
      "[skip] AI PR 42/324 already processed: 3074606452\n",
      "[skip] AI PR 43/324 already processed: 3074924091\n",
      "[skip] AI PR 44/324 already processed: 3075207290\n",
      "[skip] AI PR 45/324 already processed: 3075349977\n",
      "[skip] AI PR 46/324 already processed: 3076655992\n",
      "[skip] AI PR 47/324 already processed: 3077061912\n",
      "[skip] AI PR 48/324 already processed: 3077187183\n",
      "[skip] AI PR 49/324 already processed: 3077200502\n",
      "[skip] AI PR 50/324 already processed: 3078172167\n",
      "[skip] AI PR 51/324 already processed: 3078500498\n",
      "[skip] AI PR 52/324 already processed: 3081150843\n",
      "[skip] AI PR 53/324 already processed: 3081695764\n",
      "[skip] AI PR 54/324 already processed: 3084608702\n",
      "[skip] AI PR 55/324 already processed: 3084684604\n",
      "[skip] AI PR 56/324 already processed: 3084701052\n",
      "[skip] AI PR 57/324 already processed: 3084770989\n",
      "[skip] AI PR 58/324 already processed: 3087062778\n",
      "[skip] AI PR 59/324 already processed: 3087231593\n",
      "[skip] AI PR 60/324 already processed: 3087295315\n",
      "[skip] AI PR 61/324 already processed: 3087728875\n",
      "[skip] AI PR 62/324 already processed: 3089613637\n",
      "[skip] AI PR 63/324 already processed: 3093949496\n",
      "[skip] AI PR 64/324 already processed: 3093995006\n",
      "[skip] AI PR 65/324 already processed: 3095454351\n",
      "[skip] AI PR 66/324 already processed: 3096236895\n",
      "[skip] AI PR 67/324 already processed: 3096249565\n",
      "[skip] AI PR 68/324 already processed: 3096300821\n",
      "[skip] AI PR 69/324 already processed: 3099945080\n",
      "[skip] AI PR 70/324 already processed: 3101459806\n",
      "[skip] AI PR 71/324 already processed: 3104378127\n",
      "[skip] AI PR 72/324 already processed: 3104406142\n",
      "[skip] AI PR 73/324 already processed: 3104463145\n",
      "[skip] AI PR 74/324 already processed: 3104683212\n",
      "[skip] AI PR 75/324 already processed: 3106031006\n",
      "[skip] AI PR 76/324 already processed: 3106780046\n",
      "[skip] AI PR 77/324 already processed: 3106804055\n",
      "[skip] AI PR 78/324 already processed: 3107237879\n",
      "[skip] AI PR 79/324 already processed: 3107735616\n",
      "[skip] AI PR 80/324 already processed: 3108570703\n",
      "[skip] AI PR 81/324 already processed: 3113006799\n",
      "[skip] AI PR 82/324 already processed: 3113051088\n",
      "[skip] AI PR 83/324 already processed: 3115186500\n",
      "[skip] AI PR 84/324 already processed: 3116414631\n",
      "[skip] AI PR 85/324 already processed: 3116534114\n",
      "[skip] AI PR 86/324 already processed: 3117019425\n",
      "[skip] AI PR 87/324 already processed: 3117777345\n",
      "[skip] AI PR 88/324 already processed: 3117839444\n",
      "[skip] AI PR 89/324 already processed: 3118377413\n",
      "[skip] AI PR 90/324 already processed: 3118392412\n",
      "[skip] AI PR 91/324 already processed: 3119099358\n",
      "[skip] AI PR 92/324 already processed: 3120514991\n",
      "[skip] AI PR 93/324 already processed: 3120627194\n",
      "[skip] AI PR 94/324 already processed: 3122455352\n",
      "[skip] AI PR 95/324 already processed: 3128593850\n",
      "[skip] AI PR 96/324 already processed: 3128644658\n",
      "[skip] AI PR 97/324 already processed: 3128738345\n",
      "[skip] AI PR 98/324 already processed: 3128867544\n",
      "[skip] AI PR 99/324 already processed: 3128873567\n",
      "[skip] AI PR 100/324 already processed: 3128898273\n",
      "[skip] AI PR 101/324 already processed: 3130957636\n",
      "[skip] AI PR 102/324 already processed: 3131512724\n",
      "[skip] AI PR 103/324 already processed: 3133585449\n",
      "[skip] AI PR 104/324 already processed: 3134374490\n",
      "[skip] AI PR 105/324 already processed: 3134947414\n",
      "[skip] AI PR 106/324 already processed: 3135397128\n",
      "[skip] AI PR 107/324 already processed: 3136694740\n",
      "[skip] AI PR 108/324 already processed: 3137138306\n",
      "[skip] AI PR 109/324 already processed: 3137786825\n",
      "[skip] AI PR 110/324 already processed: 3137892942\n",
      "[skip] AI PR 111/324 already processed: 3138324206\n",
      "[skip] AI PR 112/324 already processed: 3138341820\n",
      "[skip] AI PR 113/324 already processed: 3141942061\n",
      "[skip] AI PR 114/324 already processed: 3142207549\n",
      "[skip] AI PR 115/324 already processed: 3142406085\n",
      "[skip] AI PR 116/324 already processed: 3142771614\n",
      "[skip] AI PR 117/324 already processed: 3142986664\n",
      "[skip] AI PR 118/324 already processed: 3146327522\n",
      "[skip] AI PR 119/324 already processed: 3146329050\n",
      "[skip] AI PR 120/324 already processed: 3146354845\n",
      "[skip] AI PR 121/324 already processed: 3146857680\n",
      "[skip] AI PR 122/324 already processed: 3146870376\n",
      "[skip] AI PR 123/324 already processed: 3147149820\n",
      "[skip] AI PR 124/324 already processed: 3147340923\n",
      "[skip] AI PR 125/324 already processed: 3148090723\n",
      "[skip] AI PR 126/324 already processed: 3148127134\n",
      "[skip] AI PR 127/324 already processed: 3148602658\n",
      "[skip] AI PR 128/324 already processed: 3150133933\n",
      "[skip] AI PR 129/324 already processed: 3150434121\n",
      "[skip] AI PR 130/324 already processed: 3151002300\n",
      "[skip] AI PR 131/324 already processed: 3151370964\n",
      "[skip] AI PR 132/324 already processed: 3151604419\n",
      "[skip] AI PR 133/324 already processed: 3152003781\n",
      "[skip] AI PR 134/324 already processed: 3152227912\n",
      "[skip] AI PR 135/324 already processed: 3153634298\n",
      "[skip] AI PR 136/324 already processed: 3154548302\n",
      "[skip] AI PR 137/324 already processed: 3154652967\n",
      "[skip] AI PR 138/324 already processed: 3155001680\n",
      "[skip] AI PR 139/324 already processed: 3155697260\n",
      "[skip] AI PR 140/324 already processed: 3158684496\n",
      "[skip] AI PR 141/324 already processed: 3158727370\n",
      "[skip] AI PR 142/324 already processed: 3160620876\n",
      "[skip] AI PR 143/324 already processed: 3161909204\n",
      "[skip] AI PR 144/324 already processed: 3164430964\n",
      "[skip] AI PR 145/324 already processed: 3164482877\n",
      "[skip] AI PR 146/324 already processed: 3164722645\n",
      "[skip] AI PR 147/324 already processed: 3164738704\n",
      "[skip] AI PR 148/324 already processed: 3164813640\n",
      "[skip] AI PR 149/324 already processed: 3166859797\n",
      "[skip] AI PR 150/324 already processed: 3167979829\n",
      "[skip] AI PR 151/324 already processed: 3168164252\n",
      "[skip] AI PR 152/324 already processed: 3168509434\n",
      "[skip] AI PR 153/324 already processed: 3168819278\n",
      "[skip] AI PR 154/324 already processed: 3168842951\n",
      "[skip] AI PR 155/324 already processed: 3173779555\n",
      "[skip] AI PR 156/324 already processed: 3175127708\n",
      "[skip] AI PR 157/324 already processed: 3176300978\n",
      "[skip] AI PR 158/324 already processed: 3181363640\n",
      "[skip] AI PR 159/324 already processed: 3181712853\n",
      "[skip] AI PR 160/324 already processed: 3184544966\n",
      "[skip] AI PR 161/324 already processed: 3185679015\n",
      "[skip] AI PR 162/324 already processed: 3185733825\n",
      "[skip] AI PR 163/324 already processed: 3185988908\n",
      "[skip] AI PR 164/324 already processed: 3186031697\n",
      "[skip] AI PR 165/324 already processed: 3186033939\n",
      "[skip] AI PR 166/324 already processed: 3186037018\n",
      "[skip] AI PR 167/324 already processed: 3186037439\n",
      "[skip] AI PR 168/324 already processed: 3186235764\n",
      "[skip] AI PR 169/324 already processed: 3186305413\n",
      "[skip] AI PR 170/324 already processed: 3186318107\n",
      "[skip] AI PR 171/324 already processed: 3186329921\n",
      "[skip] AI PR 172/324 already processed: 3186331079\n",
      "[skip] AI PR 173/324 already processed: 3186332246\n",
      "[skip] AI PR 174/324 already processed: 3186346363\n",
      "[skip] AI PR 175/324 already processed: 3186370979\n",
      "[skip] AI PR 176/324 already processed: 3186409173\n",
      "[skip] AI PR 177/324 already processed: 3186433660\n",
      "[skip] AI PR 178/324 already processed: 3186657928\n",
      "[skip] AI PR 179/324 already processed: 3187015246\n",
      "[skip] AI PR 180/324 already processed: 3187229759\n",
      "[skip] AI PR 181/324 already processed: 3187736538\n",
      "[skip] AI PR 182/324 already processed: 3188612213\n",
      "[skip] AI PR 183/324 already processed: 3188613267\n",
      "[skip] AI PR 184/324 already processed: 3188613776\n",
      "[skip] AI PR 185/324 already processed: 3188614083\n",
      "[skip] AI PR 186/324 already processed: 3188614216\n",
      "[skip] AI PR 187/324 already processed: 3188714494\n",
      "[skip] AI PR 188/324 already processed: 3188718282\n",
      "[skip] AI PR 189/324 already processed: 3188781479\n",
      "[skip] AI PR 190/324 already processed: 3188892969\n",
      "[skip] AI PR 191/324 already processed: 3189195714\n",
      "[skip] AI PR 192/324 already processed: 3189294728\n",
      "[skip] AI PR 193/324 already processed: 3190011828\n",
      "[skip] AI PR 194/324 already processed: 3190098735\n",
      "[skip] AI PR 195/324 already processed: 3190247421\n",
      "[skip] AI PR 196/324 already processed: 3190320694\n",
      "[skip] AI PR 197/324 already processed: 3193183157\n",
      "[skip] AI PR 198/324 already processed: 3194284966\n",
      "[skip] AI PR 199/324 already processed: 3196281528\n",
      "[skip] AI PR 200/324 already processed: 3197078069\n",
      "[skip] AI PR 201/324 already processed: 3198134004\n",
      "[skip] AI PR 202/324 already processed: 3198941408\n",
      "[skip] AI PR 203/324 already processed: 3200679276\n",
      "[skip] AI PR 204/324 already processed: 3200979351\n",
      "[skip] AI PR 205/324 already processed: 3202402474\n",
      "[skip] AI PR 206/324 already processed: 3202406874\n",
      "[skip] AI PR 207/324 already processed: 3202673408\n",
      "[skip] AI PR 208/324 already processed: 3202700175\n",
      "[skip] AI PR 209/324 already processed: 3202763859\n",
      "[skip] AI PR 210/324 already processed: 3204565892\n",
      "[skip] AI PR 211/324 already processed: 3204638990\n",
      "[skip] AI PR 212/324 already processed: 3206323613\n",
      "[skip] AI PR 213/324 already processed: 3206379276\n",
      "[skip] AI PR 214/324 already processed: 3206422165\n",
      "[skip] AI PR 215/324 already processed: 3206743230\n",
      "[skip] AI PR 216/324 already processed: 3206861578\n",
      "[skip] AI PR 217/324 already processed: 3209964949\n",
      "[skip] AI PR 218/324 already processed: 3210728631\n",
      "[skip] AI PR 219/324 already processed: 3210894862\n",
      "[skip] AI PR 220/324 already processed: 3213281518\n",
      "[skip] AI PR 221/324 already processed: 3213528854\n",
      "[skip] AI PR 222/324 already processed: 3213723251\n",
      "[skip] AI PR 223/324 already processed: 3213724164\n",
      "[skip] AI PR 224/324 already processed: 3213728031\n",
      "[skip] AI PR 225/324 already processed: 3213730809\n",
      "[skip] AI PR 226/324 already processed: 3213747226\n",
      "[skip] AI PR 227/324 already processed: 3213750237\n",
      "[skip] AI PR 228/324 already processed: 3213850102\n",
      "[skip] AI PR 229/324 already processed: 3213857892\n",
      "[skip] AI PR 230/324 already processed: 3213876116\n",
      "[skip] AI PR 231/324 already processed: 3213895675\n",
      "[skip] AI PR 232/324 already processed: 3214278956\n",
      "[skip] AI PR 233/324 already processed: 3214281732\n",
      "[skip] AI PR 234/324 already processed: 3214766453\n",
      "[skip] AI PR 235/324 already processed: 3215138589\n",
      "[skip] AI PR 236/324 already processed: 3215330137\n",
      "[skip] AI PR 237/324 already processed: 3216548273\n",
      "[skip] AI PR 238/324 already processed: 3216588034\n",
      "[skip] AI PR 239/324 already processed: 3216964251\n",
      "[skip] AI PR 240/324 already processed: 3217652543\n",
      "Processing AI PR 241/324: 3217675934\n",
      "Short-circuiting PR 3217675934 with no signals\n",
      "pipeline_names: []\n",
      "description: \n",
      "comments: []\n",
      "code_diff: \n",
      "[error] Logged PR 3217675934 (ai/ai_agent) to /Users/antoniozhong/Documents/dev/purdue/MSR2026/github_perf_patch_study/RQ3/rq3_validation_errors.csv: No signals present\n",
      "[skip] AI PR 242/324 already processed: 3217742863\n",
      "[skip] AI PR 243/324 already processed: 3217758395\n",
      "[skip] AI PR 244/324 already processed: 3217761016\n",
      "[skip] AI PR 245/324 already processed: 3217766297\n",
      "[skip] AI PR 246/324 already processed: 3218234090\n",
      "[skip] AI PR 247/324 already processed: 3218343296\n",
      "[skip] AI PR 248/324 already processed: 3218429525\n",
      "[skip] AI PR 249/324 already processed: 3219158589\n",
      "[skip] AI PR 250/324 already processed: 3219696751\n",
      "[skip] AI PR 251/324 already processed: 3219981823\n",
      "[skip] AI PR 252/324 already processed: 3220396620\n",
      "[skip] AI PR 253/324 already processed: 3220735806\n",
      "[skip] AI PR 254/324 already processed: 3220760486\n",
      "[skip] AI PR 255/324 already processed: 3222683231\n",
      "[skip] AI PR 256/324 already processed: 3223908947\n",
      "[skip] AI PR 257/324 already processed: 3224713270\n",
      "[skip] AI PR 258/324 already processed: 3224827777\n",
      "[skip] AI PR 259/324 already processed: 3225788754\n",
      "[skip] AI PR 260/324 already processed: 3226144762\n",
      "[skip] AI PR 261/324 already processed: 3226180108\n",
      "[skip] AI PR 262/324 already processed: 3226639011\n",
      "[skip] AI PR 263/324 already processed: 3227169343\n",
      "[skip] AI PR 264/324 already processed: 3227405736\n",
      "[skip] AI PR 265/324 already processed: 3233988388\n",
      "[skip] AI PR 266/324 already processed: 3234031765\n",
      "[skip] AI PR 267/324 already processed: 3235100943\n",
      "[skip] AI PR 268/324 already processed: 3235179464\n",
      "[skip] AI PR 269/324 already processed: 3238396793\n",
      "[skip] AI PR 270/324 already processed: 3238582253\n",
      "[skip] AI PR 271/324 already processed: 3238674493\n",
      "[skip] AI PR 272/324 already processed: 3238720815\n",
      "[skip] AI PR 273/324 already processed: 3238723742\n",
      "[skip] AI PR 274/324 already processed: 3238737226\n",
      "[skip] AI PR 275/324 already processed: 3238739331\n",
      "[skip] AI PR 276/324 already processed: 3239263606\n",
      "[skip] AI PR 277/324 already processed: 3239403987\n",
      "[skip] AI PR 278/324 already processed: 3239561220\n",
      "[skip] AI PR 279/324 already processed: 3240006620\n",
      "[skip] AI PR 280/324 already processed: 3240460340\n",
      "Processing AI PR 281/324: 3240593081\n",
      "Short-circuiting PR 3240593081 with no signals\n",
      "pipeline_names: []\n",
      "description: \n",
      "comments: []\n",
      "code_diff: \n",
      "[error] Logged PR 3240593081 (ai/ai_agent) to /Users/antoniozhong/Documents/dev/purdue/MSR2026/github_perf_patch_study/RQ3/rq3_validation_errors.csv: No signals present\n",
      "[skip] AI PR 282/324 already processed: 3241057566\n",
      "[skip] AI PR 283/324 already processed: 3241523087\n",
      "[skip] AI PR 284/324 already processed: 3241690700\n",
      "[skip] AI PR 285/324 already processed: 3241691177\n",
      "[skip] AI PR 286/324 already processed: 3241695471\n",
      "[skip] AI PR 287/324 already processed: 3241758610\n",
      "[skip] AI PR 288/324 already processed: 3242128024\n",
      "[skip] AI PR 289/324 already processed: 3242396116\n",
      "[skip] AI PR 290/324 already processed: 3242666013\n",
      "[skip] AI PR 291/324 already processed: 3245509530\n",
      "[skip] AI PR 292/324 already processed: 3245861239\n",
      "[skip] AI PR 293/324 already processed: 3245892725\n",
      "[skip] AI PR 294/324 already processed: 3245899488\n",
      "[skip] AI PR 295/324 already processed: 3245927515\n",
      "[skip] AI PR 296/324 already processed: 3245957050\n",
      "[skip] AI PR 297/324 already processed: 3245970844\n",
      "[skip] AI PR 298/324 already processed: 3246099511\n",
      "[skip] AI PR 299/324 already processed: 3246105987\n",
      "[skip] AI PR 300/324 already processed: 3246117305\n",
      "[skip] AI PR 301/324 already processed: 3246122368\n",
      "[skip] AI PR 302/324 already processed: 3246158661\n",
      "[skip] AI PR 303/324 already processed: 3246365675\n",
      "[skip] AI PR 304/324 already processed: 3246418740\n",
      "[skip] AI PR 305/324 already processed: 3246432388\n",
      "[skip] AI PR 306/324 already processed: 3250089415\n",
      "[skip] AI PR 307/324 already processed: 3250286583\n",
      "[skip] AI PR 308/324 already processed: 3250477735\n",
      "[skip] AI PR 309/324 already processed: 3252596861\n",
      "[skip] AI PR 310/324 already processed: 3253657829\n",
      "[skip] AI PR 311/324 already processed: 3253809004\n",
      "[skip] AI PR 312/324 already processed: 3254647682\n",
      "[skip] AI PR 313/324 already processed: 3257571628\n",
      "[skip] AI PR 314/324 already processed: 3257665431\n",
      "[skip] AI PR 315/324 already processed: 3258539679\n",
      "[skip] AI PR 316/324 already processed: 3261822593\n",
      "[skip] AI PR 317/324 already processed: 3262412016\n",
      "[skip] AI PR 318/324 already processed: 3262845265\n",
      "[skip] AI PR 319/324 already processed: 3262865664\n",
      "[skip] AI PR 320/324 already processed: 3262887238\n",
      "[skip] AI PR 321/324 already processed: 3263278811\n",
      "[skip] AI PR 322/324 already processed: 3264767865\n",
      "[skip] AI PR 323/324 already processed: 3265736885\n",
      "[skip] AI PR 324/324 already processed: 3267289370\n",
      "[skip] human PR 1/83 already processed: 2260441374\n",
      "[skip] human PR 2/83 already processed: 2260678480\n",
      "[skip] human PR 3/83 already processed: 2269202548\n",
      "[skip] human PR 4/83 already processed: 2269709704\n",
      "[skip] human PR 5/83 already processed: 2277950711\n",
      "[skip] human PR 6/83 already processed: 2297969098\n",
      "[skip] human PR 7/83 already processed: 2303501996\n",
      "[skip] human PR 8/83 already processed: 2308221415\n",
      "[skip] human PR 9/83 already processed: 2309904375\n",
      "[skip] human PR 10/83 already processed: 2311607019\n",
      "[skip] human PR 11/83 already processed: 2316356365\n",
      "[skip] human PR 12/83 already processed: 2324987642\n",
      "[skip] human PR 13/83 already processed: 2336649960\n",
      "[skip] human PR 14/83 already processed: 2336988355\n",
      "[skip] human PR 15/83 already processed: 2337334370\n",
      "[skip] human PR 16/83 already processed: 2337335339\n",
      "[skip] human PR 17/83 already processed: 2353668916\n",
      "[skip] human PR 18/83 already processed: 2354104157\n",
      "[skip] human PR 19/83 already processed: 2356811134\n",
      "[skip] human PR 20/83 already processed: 2356985296\n",
      "[skip] human PR 21/83 already processed: 2358030784\n",
      "[skip] human PR 22/83 already processed: 2369238232\n",
      "[skip] human PR 23/83 already processed: 2369253951\n",
      "[skip] human PR 24/83 already processed: 2369320781\n",
      "[skip] human PR 25/83 already processed: 2386158448\n",
      "[skip] human PR 26/83 already processed: 2389511160\n",
      "[skip] human PR 27/83 already processed: 2392888093\n",
      "[skip] human PR 28/83 already processed: 2394225726\n",
      "[skip] human PR 29/83 already processed: 2398828721\n",
      "[skip] human PR 30/83 already processed: 2398994327\n",
      "[skip] human PR 31/83 already processed: 2400016065\n",
      "[skip] human PR 32/83 already processed: 2408616836\n",
      "[skip] human PR 33/83 already processed: 2412640161\n",
      "[skip] human PR 34/83 already processed: 2419106029\n",
      "[skip] human PR 35/83 already processed: 2425248848\n",
      "[skip] human PR 36/83 already processed: 2427616889\n",
      "[skip] human PR 37/83 already processed: 2432868443\n",
      "[skip] human PR 38/83 already processed: 2439339242\n",
      "[skip] human PR 39/83 already processed: 2441809617\n",
      "[skip] human PR 40/83 already processed: 2443864788\n",
      "[skip] human PR 41/83 already processed: 2452623588\n",
      "[skip] human PR 42/83 already processed: 2452691617\n",
      "[skip] human PR 43/83 already processed: 2469218203\n",
      "[skip] human PR 44/83 already processed: 2483117033\n",
      "[skip] human PR 45/83 already processed: 2486573779\n",
      "[skip] human PR 46/83 already processed: 2492416622\n",
      "[skip] human PR 47/83 already processed: 2495944314\n",
      "[skip] human PR 48/83 already processed: 2496617006\n",
      "[skip] human PR 49/83 already processed: 2497503442\n",
      "[skip] human PR 50/83 already processed: 2503287360\n",
      "[skip] human PR 51/83 already processed: 2504407177\n",
      "[skip] human PR 52/83 already processed: 2512247973\n",
      "[skip] human PR 53/83 already processed: 2519312120\n",
      "[skip] human PR 54/83 already processed: 2519831355\n",
      "[skip] human PR 55/83 already processed: 2524180167\n",
      "[skip] human PR 56/83 already processed: 2524300649\n",
      "[skip] human PR 57/83 already processed: 2524313861\n",
      "[skip] human PR 58/83 already processed: 2527565003\n",
      "[skip] human PR 59/83 already processed: 2531991252\n",
      "[skip] human PR 60/83 already processed: 2537690761\n",
      "[skip] human PR 61/83 already processed: 2542615571\n",
      "[skip] human PR 62/83 already processed: 2544691147\n",
      "[skip] human PR 63/83 already processed: 2545078467\n",
      "[skip] human PR 64/83 already processed: 2555753483\n",
      "[skip] human PR 65/83 already processed: 2558083620\n",
      "[skip] human PR 66/83 already processed: 2560305820\n",
      "[skip] human PR 67/83 already processed: 2564432253\n",
      "[skip] human PR 68/83 already processed: 2573225924\n",
      "[skip] human PR 69/83 already processed: 2577421996\n",
      "[skip] human PR 70/83 already processed: 2590261382\n",
      "[skip] human PR 71/83 already processed: 2596620305\n",
      "[skip] human PR 72/83 already processed: 2597070258\n",
      "[skip] human PR 73/83 already processed: 2604024784\n",
      "[skip] human PR 74/83 already processed: 2604162624\n",
      "[skip] human PR 75/83 already processed: 2607579182\n",
      "[skip] human PR 76/83 already processed: 2608906245\n",
      "[skip] human PR 77/83 already processed: 2609611207\n",
      "[skip] human PR 78/83 already processed: 2613893429\n",
      "[skip] human PR 79/83 already processed: 2615702170\n",
      "[skip] human PR 80/83 already processed: 2616290996\n",
      "[skip] human PR 81/83 already processed: 2617294066\n",
      "[skip] human PR 82/83 already processed: 2622581875\n",
      "[skip] human PR 83/83 already processed: 2623769975\n",
      "Saved FINAL OPENAI 405 rows to /Users/antoniozhong/Documents/dev/purdue/MSR2026/github_perf_patch_study/RQ3/rq3_validation_evidence_openai.parquet\n",
      "Errored PRs (if any) logged to /Users/antoniozhong/Documents/dev/purdue/MSR2026/github_perf_patch_study/RQ3/rq3_validation_errors.csv\n"
     ]
    }
   ],
   "source": [
    "out_dir = PROJECT_ROOT / \"RQ3\"\n",
    "out_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "out_path_openai = out_dir / \"rq3_validation_evidence_openai.parquet\"\n",
    "error_csv_path = out_dir / \"rq3_validation_errors.csv\"\n",
    "\n",
    "ai_core = load_pr_core(\"ai\")\n",
    "human_core = load_pr_core(\"human\")\n",
    "\n",
    "limit = None\n",
    "\n",
    "if out_path_openai.exists():\n",
    "    df_existing = pd.read_parquet(out_path_openai)\n",
    "    records_openai = df_existing.to_dict(\"records\")\n",
    "    processed_ids = set(df_existing[\"pr_id\"].astype(int).tolist())\n",
    "    print(f\"[resume] Loaded {len(records_openai)} existing records\")\n",
    "else:\n",
    "    records_openai = []\n",
    "    processed_ids = set()\n",
    "    print(\"[resume] No previous file found, starting fresh\")\n",
    "\n",
    "\n",
    "def save_partial(records, out_path):\n",
    "    if not records:\n",
    "        return\n",
    "    df_tmp = pd.DataFrame(records)\n",
    "    df_tmp.to_parquet(out_path, index=False)\n",
    "    #print(f\"[partial save] Saved {len(df_tmp)} rows to {out_path}\")\n",
    "\n",
    "\n",
    "def log_error(pr_id, prefix, author_type, exc):\n",
    "    row = {\n",
    "        \"prefix\": prefix,\n",
    "        \"pr_id\": pr_id,\n",
    "        \"author_type\": author_type,\n",
    "        \"error\": str(exc),\n",
    "    }\n",
    "    df_err = pd.DataFrame([row])\n",
    "    header = not error_csv_path.exists()\n",
    "    df_err.to_csv(error_csv_path, mode=\"a\", header=header, index=False)\n",
    "    print(f\"[error] Logged PR {pr_id} ({prefix}/{author_type}) to {error_csv_path}: {exc}\")\n",
    "\n",
    "\n",
    "ai_ids = list(pr_ids_from_commits(\"ai\", limit=limit))\n",
    "human_ids = list(pr_ids_from_commits(\"human\", limit=limit))\n",
    "print(f\"Processing {len(ai_ids)} AI PRs and {len(human_ids)} human PRs (first {limit} each).\")\n",
    "\n",
    "\n",
    "\n",
    "for idx, pr_id in enumerate(ai_ids, 1):\n",
    "\n",
    "    if pr_id in processed_ids:\n",
    "        print(f\"[skip] AI PR {idx}/{len(ai_ids)} already processed: {pr_id}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing AI PR {idx}/{len(ai_ids)}: {pr_id}\")\n",
    "\n",
    "    try:\n",
    "        openai_res = analyze_pr(\"ai\", pr_id, \"ai_agent\", ai_core)\n",
    "        records_openai.append(openai_res)\n",
    "\n",
    "    except Exception as exc:\n",
    "        log_error(pr_id, prefix=\"ai\", author_type=\"ai_agent\", exc=exc)\n",
    "\n",
    "    # ---- SAVE EVERY 1 ----\n",
    "    if len(records_openai) % 1 == 0:\n",
    "        save_partial(records_openai, out_path_openai)\n",
    "\n",
    "\n",
    "\n",
    "for idx, pr_id in enumerate(human_ids, 1):\n",
    "\n",
    "    if pr_id in processed_ids:\n",
    "        print(f\"[skip] human PR {idx}/{len(human_ids)} already processed: {pr_id}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing human PR {idx}/{len(human_ids)}: {pr_id}\")\n",
    "\n",
    "    try:\n",
    "        openai_res = analyze_pr(\"human\", pr_id, \"human\", human_core)\n",
    "        records_openai.append(openai_res)\n",
    "\n",
    "    except Exception as exc:\n",
    "        log_error(pr_id, prefix=\"human\", author_type=\"human\", exc=exc)\n",
    "\n",
    "    # ---- SAVE EVERY 1 ----\n",
    "    if len(records_openai) % 1 == 0:\n",
    "        save_partial(records_openai, out_path_openai)\n",
    "\n",
    "\n",
    "# ============================\n",
    "# Final save ✅\n",
    "# ============================\n",
    "df_open_ai = pd.DataFrame(records_openai)\n",
    "df_open_ai.to_parquet(out_path_openai, index=False)\n",
    "print(f\"Saved FINAL OPENAI {len(df_open_ai)} rows to {out_path_openai}\")\n",
    "print(f\"Errored PRs (if any) logged to {error_csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
