{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e779bfd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Optional\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64e600d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_llm(system_pront: str, prompt: str, type: str = \"ollama\", model: str = \"gemma3:27b\") -> str:\n",
    "    \"\"\"Call local OLLAMA.\"\"\"\n",
    "    LLM_BASE_URL = \"http://localhost:11434/v1\"\n",
    "    LLM_API_KEY = \"\"\n",
    "    llm_client = OpenAI(base_url=LLM_BASE_URL, api_key=LLM_API_KEY)\n",
    "    \n",
    "  \n",
    "    \n",
    "    if(type == \"ollama\"):\n",
    "        print(\"Running OLLAMA, model:\", model)\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_pront},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "        \n",
    "        r = llm_client.chat.completions.create(\n",
    "            model= model,\n",
    "            messages=messages,\n",
    "        )\n",
    "        result = r.choices[0].message.content.strip()\n",
    "        print(\"OLLAMA response:\", result)\n",
    "        return result.strip()\n",
    "    elif(type == \"gemini\"):\n",
    "        \n",
    "        model = \"gemini-3-pro-preview\"\n",
    "        print(\"Running GEMINI, model:\", model)\n",
    "        \n",
    "        GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
    "        client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "        schema={\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"validation_present\": {\n",
    "                        \"type\": \"boolean\"\n",
    "                    },\n",
    "                    \"evidence_sources\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"enum\": [\"pipeline\", \"description\", \"comments\"]\n",
    "                        }\n",
    "                    },\n",
    "                    \"validation_type\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\n",
    "                            \"benchmark\",\n",
    "                            \"profiling\",\n",
    "                            \"load/canary\",\n",
    "                            \"unit-only\",\n",
    "                            \"unspecified\",\n",
    "                            \"none\"\n",
    "                        ]\n",
    "                    },\n",
    "                    \"validation_description\": {\n",
    "                        \"type\": \"string\"\n",
    "                    },\n",
    "                    \"pipeline_signal\": {\n",
    "                        \"type\": \"string\"\n",
    "                    },\n",
    "                    \"description_signal\": {\n",
    "                        \"type\": \"string\"\n",
    "                    },\n",
    "                    \"comment_signal\": {\n",
    "                        \"type\": \"string\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"validation_present\",\n",
    "                    \"evidence_sources\",\n",
    "                    \"validation_type\",\n",
    "                    \"validation_description\",\n",
    "                    \"pipeline_signal\",\n",
    "                    \"description_signal\",\n",
    "                    \"comment_signal\"\n",
    "                ]\n",
    "            }\n",
    "        \n",
    "        config = types.GenerateContentConfig(\n",
    "            temperature=0.0,\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_schema=schema,\n",
    "            thinking_config=types.ThinkingConfig(\n",
    "                thinking_level=types.ThinkingLevel.HIGH\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        messages = [\n",
    "            system_pront,\n",
    "            prompt\n",
    "        ]\n",
    "        \n",
    "        response = client.models.generate_content(\n",
    "            model=model,\n",
    "            contents=messages,\n",
    "            config=config,\n",
    "        )\n",
    "        return response.text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56c2b2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_datasets_dir(start: Optional[Path] = None) -> Path:\n",
    "    start = start or Path.cwd()\n",
    "    for path in (start, *start.parents):\n",
    "        candidate = path / \"datasets\"\n",
    "        if candidate.exists():\n",
    "            return candidate\n",
    "    raise FileNotFoundError(f\"Could not find 'datasets' directory from {start}\")\n",
    "\n",
    "\n",
    "DATASETS_DIR = find_datasets_dir()\n",
    "PROJECT_ROOT = DATASETS_DIR.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10afe7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json(text: str) -> Dict:\n",
    "    \"\"\"Best-effort JSON extraction from model output.\"\"\"\n",
    "    start = text.find(\"{\")\n",
    "    end = text.rfind(\"}\")\n",
    "    if start != -1 and end != -1 and end > start:\n",
    "        snippet = text[start : end + 1]\n",
    "        try:\n",
    "            return json.loads(snippet)\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "    return {}\n",
    "\n",
    "def truncate(text: str, limit: int = 10000) -> str:\n",
    "    return text if len(text) <= limit else text[:limit] + \"...[truncated]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29784b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pr_core(prefix: str) -> pd.DataFrame:\n",
    "    commits = pd.read_parquet(\n",
    "        DATASETS_DIR / f\"{prefix}_pr\" / f\"{prefix}_pr_commits.parquet\"\n",
    "    )\n",
    "    return commits.drop_duplicates(\"pr_id\").set_index(\"pr_id\")\n",
    "\n",
    "\n",
    "def collect_comments(prefix: str, pr_id: int) -> List[str]:\n",
    "    issue = pd.read_parquet(\n",
    "        DATASETS_DIR / f\"{prefix}_pr\" / f\"{prefix}_pr_issue_comments.parquet\"\n",
    "    )\n",
    "    review = pd.read_parquet(\n",
    "        DATASETS_DIR / f\"{prefix}_pr\" / f\"{prefix}_pr_review_comments.parquet\"\n",
    "    )\n",
    "    texts = []\n",
    "    for df in (issue, review):\n",
    "        subset = df[df[\"pr_id\"] == pr_id]\n",
    "        texts.extend(subset[\"body\"].dropna().tolist())\n",
    "    return texts\n",
    "\n",
    "\n",
    "def collect_pipeline_names(prefix: str, pr_id: int) -> List[str]:\n",
    "    workflows = pd.read_parquet(\n",
    "        DATASETS_DIR / f\"{prefix}_pr\" / f\"{prefix}_pr_workflow_runs.parquet\"\n",
    "    )\n",
    "    subset = workflows[workflows[\"pr_id\"] == pr_id]\n",
    "    return sorted(subset[\"workflow_name\"].dropna().unique().tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63d63ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_pr(\n",
    "    prefix: str, pr_id: int, author_type: str, pr_core: pd.DataFrame\n",
    ") -> Dict:\n",
    "    row = pr_core.loc[pr_id]\n",
    "    pipeline_names = collect_pipeline_names(prefix, pr_id)\n",
    "    comments = collect_comments(prefix, pr_id)\n",
    "    description = (row.get(\"pr_description\") or \"\").strip()\n",
    "    \n",
    "    SYSTEM_PROMPT_TEMPLATE = \"\"\"You classify evidence of performance validation for a PR.\n",
    "    Return compact JSON only with keys:\n",
    "    validation_present (bool), evidence_sources (list of \"pipeline\",\"description\",\"comments\"),\n",
    "    validation_type (benchmark,profiling,load/canary,unit-only,unspecified,none),\n",
    "    validation_description (short text),\n",
    "    pipeline_signal (short), description_signal (short), comment_signal (short).\n",
    "\n",
    "    Rules:\n",
    "    - Pipelines count only if workflow names imply perf/benchmark/load/canary; note when they are unit/lint-only.\n",
    "    - Description/comments count if they mention perf benchmarks, profiling, latency/throughput numbers,\n",
    "    load/canary rollout, A/B tests, perf tools, or explicit \"no perf validation\".\n",
    "    - If nothing indicates perf validation, set validation_present=false,\n",
    "    validation_type=\"none\", evidence_sources=[],\n",
    "    validation_description=\"No validation evidence\".\n",
    "    \"\"\"\n",
    "    \n",
    "    PROMPT_TEMPLATE = \"\"\"\n",
    "    You are given information about a GitHub Pull Request (PR).\n",
    "    Using the provided PIPELINES, DESCRIPTION, and COMMENTS, determine if there is evidence of performance validation for the PR.\n",
    "    Input (TOONS format):\n",
    "\n",
    "    PIPELINES:\n",
    "    {pipeline_names}\n",
    "\n",
    "    DESCRIPTION:\n",
    "    {description}\n",
    "\n",
    "    COMMENTS:\n",
    "    {comments}\n",
    "\n",
    "    JSON:\n",
    "    \"\"\"\n",
    "\n",
    "    if not pipeline_names and not description and not comments:\n",
    "        return {\n",
    "            \"pr_id\": pr_id,\n",
    "            \"author_type\": author_type,\n",
    "            \"repo\": f\"{row.get('repo_owner')}/{row.get('repo_name')}\",\n",
    "            \"pr_number\": row.get(\"pr_number\"),\n",
    "            \"pr_title\": row.get(\"pr_title\"),\n",
    "            \"pipeline_names\": pipeline_names,\n",
    "            \"validation_present\": False,\n",
    "            \"evidence_sources\": [],\n",
    "            \"validation_type\": \"none\",\n",
    "            \"validation_description\": \"No validation evidence\",\n",
    "            \"pipeline_signal\": \"\",\n",
    "            \"description_signal\": \"\",\n",
    "            \"comment_signal\": \"\",\n",
    "        }\n",
    "\n",
    "    prompt = PROMPT_TEMPLATE.format(\n",
    "    pipeline_names=\"\\n  - \" + \"\\n  - \".join(pipeline_names) if pipeline_names else \"  None\",\n",
    "    description=\"  \" + truncate(description).replace(\"\\n\", \"\\n  \") if description else \"  None\",\n",
    "    comments=\"  - \" + \"\\n  - \".join(truncate(\" | \".join(comments)).split(\" | \")) if comments else \"  None\",\n",
    "    )\n",
    "    \n",
    "    raw = run_llm(SYSTEM_PROMPT_TEMPLATE, prompt, type=\"gemini\")\n",
    "    parsed = extract_json(raw)\n",
    "\n",
    "    evidence_sources = parsed.get(\"evidence_sources\") or []\n",
    "    if isinstance(evidence_sources, (tuple, list)):\n",
    "        evidence_sources = list(evidence_sources)\n",
    "\n",
    "    return {\n",
    "        \"pr_id\": pr_id,\n",
    "        \"author_type\": author_type,\n",
    "        \"repo\": f\"{row.get('repo_owner')}/{row.get('repo_name')}\",\n",
    "        \"pr_number\": row.get(\"pr_number\"),\n",
    "        \"pr_title\": row.get(\"pr_title\"),\n",
    "        \"pipeline_names\": pipeline_names,\n",
    "        \"validation_present\": parsed.get(\"validation_present\"),\n",
    "        \"evidence_sources\": evidence_sources,\n",
    "        \"validation_type\": parsed.get(\"validation_type\"),\n",
    "        \"validation_description\": parsed.get(\"validation_description\"),\n",
    "        \"pipeline_signal\": parsed.get(\"pipeline_signal\"),\n",
    "        \"description_signal\": parsed.get(\"description_signal\"),\n",
    "        \"comment_signal\": parsed.get(\"comment_signal\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "178deb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr_ids_from_commits(prefix: str, limit: Optional[int] = None) -> Iterable[int]:\n",
    "    commits = pd.read_parquet(\n",
    "        DATASETS_DIR / f\"{prefix}_pr\" / f\"{prefix}_pr_commits.parquet\"\n",
    "    )\n",
    "    pr_ids = sorted(commits[\"pr_id\"].dropna().astype(int).unique().tolist())\n",
    "    return pr_ids if limit is None else pr_ids[:limit]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e873eead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 324 AI PRs and 83 human PRs (first None each).\n",
      "Running GEMINI, model: gemini-3-pro-preview\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "403 PERMISSION_DENIED. {'error': {'code': 403, 'message': 'The caller does not have permission', 'status': 'PERMISSION_DENIED'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m human_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(pr_ids_from_commits(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m, limit\u001b[38;5;241m=\u001b[39mlimit))\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ai_ids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m AI PRs and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(human_ids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m human PRs (first \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlimit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m each).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m re \u001b[38;5;241m=\u001b[39m analyze_pr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mai\u001b[39m\u001b[38;5;124m\"\u001b[39m, ai_ids[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mai_agent\u001b[39m\u001b[38;5;124m\"\u001b[39m, ai_core)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResult for first AI PR to process:\u001b[39m\u001b[38;5;124m\"\u001b[39m, re)\n",
      "Cell \u001b[0;32mIn[27], line 65\u001b[0m, in \u001b[0;36manalyze_pr\u001b[0;34m(prefix, pr_id, author_type, pr_core)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpr_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: pr_id,\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: author_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomment_signal\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     57\u001b[0m     }\n\u001b[1;32m     59\u001b[0m prompt \u001b[38;5;241m=\u001b[39m PROMPT_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     60\u001b[0m pipeline_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  - \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  - \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(pipeline_names) \u001b[38;5;28;01mif\u001b[39;00m pipeline_names \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  None\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     61\u001b[0m description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m truncate(description)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m description \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  None\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     62\u001b[0m comments\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  - \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(truncate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(comments))\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mif\u001b[39;00m comments \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  None\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     63\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m raw \u001b[38;5;241m=\u001b[39m run_llm(SYSTEM_PROMPT_TEMPLATE, prompt, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     66\u001b[0m parsed \u001b[38;5;241m=\u001b[39m extract_json(raw)\n\u001b[1;32m     68\u001b[0m evidence_sources \u001b[38;5;241m=\u001b[39m parsed\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevidence_sources\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m []\n",
      "Cell \u001b[0;32mIn[23], line 94\u001b[0m, in \u001b[0;36mrun_llm\u001b[0;34m(system_pront, prompt, type, model)\u001b[0m\n\u001b[1;32m     80\u001b[0m config \u001b[38;5;241m=\u001b[39m types\u001b[38;5;241m.\u001b[39mGenerateContentConfig(\n\u001b[1;32m     81\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m     82\u001b[0m     response_mime_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m     )\n\u001b[1;32m     87\u001b[0m )\n\u001b[1;32m     89\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     90\u001b[0m     system_pront,\n\u001b[1;32m     91\u001b[0m     prompt\n\u001b[1;32m     92\u001b[0m ]\n\u001b[0;32m---> 94\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[1;32m     95\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     96\u001b[0m     contents\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m     97\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m     98\u001b[0m )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/google/genai/models.py:5218\u001b[0m, in \u001b[0;36mModels.generate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   5216\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_remote_calls_afc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   5217\u001b[0m   i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 5218\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_content(\n\u001b[1;32m   5219\u001b[0m       model\u001b[38;5;241m=\u001b[39mmodel, contents\u001b[38;5;241m=\u001b[39mcontents, config\u001b[38;5;241m=\u001b[39mparsed_config\n\u001b[1;32m   5220\u001b[0m   )\n\u001b[1;32m   5222\u001b[0m   function_map \u001b[38;5;241m=\u001b[39m _extra_utils\u001b[38;5;241m.\u001b[39mget_function_map(parsed_config)\n\u001b[1;32m   5223\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m function_map:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/google/genai/models.py:4000\u001b[0m, in \u001b[0;36mModels._generate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   3997\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mconvert_to_dict(request_dict)\n\u001b[1;32m   3998\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mencode_unserializable_types(request_dict)\n\u001b[0;32m-> 4000\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_client\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m   4001\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m, path, request_dict, http_options\n\u001b[1;32m   4002\u001b[0m )\n\u001b[1;32m   4004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[1;32m   4005\u001b[0m     config, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshould_return_http_response\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4006\u001b[0m ):\n\u001b[1;32m   4007\u001b[0m   return_value \u001b[38;5;241m=\u001b[39m types\u001b[38;5;241m.\u001b[39mGenerateContentResponse(sdk_http_response\u001b[38;5;241m=\u001b[39mresponse)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/google/genai/_api_client.py:1388\u001b[0m, in \u001b[0;36mBaseApiClient.request\u001b[0;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m   1379\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1380\u001b[0m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1383\u001b[0m     http_options: Optional[HttpOptionsOrDict] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1384\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SdkHttpResponse:\n\u001b[1;32m   1385\u001b[0m   http_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request(\n\u001b[1;32m   1386\u001b[0m       http_method, path, request_dict, http_options\n\u001b[1;32m   1387\u001b[0m   )\n\u001b[0;32m-> 1388\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(http_request, http_options, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1389\u001b[0m   response_body \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1390\u001b[0m       response\u001b[38;5;241m.\u001b[39mresponse_stream[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mresponse_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1391\u001b[0m   )\n\u001b[1;32m   1392\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m SdkHttpResponse(headers\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders, body\u001b[38;5;241m=\u001b[39mresponse_body)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/google/genai/_api_client.py:1224\u001b[0m, in \u001b[0;36mBaseApiClient._request\u001b[0;34m(self, http_request, http_options, stream)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     retry \u001b[38;5;241m=\u001b[39m tenacity\u001b[38;5;241m.\u001b[39mRetrying(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mretry_kwargs)\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[0;32m-> 1224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_once, http_request, stream)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tenacity/__init__.py:477\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 477\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(retry_state\u001b[38;5;241m=\u001b[39mretry_state)\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tenacity/__init__.py:378\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    376\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 378\u001b[0m     result \u001b[38;5;241m=\u001b[39m action(retry_state)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tenacity/__init__.py:420\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    418\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tenacity/__init__.py:187\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[0;32m--> 187\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tenacity/__init__.py:480\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 480\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    482\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/google/genai/_api_client.py:1201\u001b[0m, in \u001b[0;36mBaseApiClient._request_once\u001b[0;34m(self, http_request, stream)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_httpx_client\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m   1195\u001b[0m       method\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m   1196\u001b[0m       url\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1199\u001b[0m       timeout\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[1;32m   1200\u001b[0m   )\n\u001b[0;32m-> 1201\u001b[0m   errors\u001b[38;5;241m.\u001b[39mAPIError\u001b[38;5;241m.\u001b[39mraise_for_response(response)\n\u001b[1;32m   1202\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[1;32m   1203\u001b[0m       response\u001b[38;5;241m.\u001b[39mheaders, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext]\n\u001b[1;32m   1204\u001b[0m   )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/google/genai/errors.py:106\u001b[0m, in \u001b[0;36mAPIError.raise_for_response\u001b[0;34m(cls, response)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m   response_json \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mbody_segments[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\n\u001b[0;32m--> 106\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mraise_error(response\u001b[38;5;241m.\u001b[39mstatus_code, response_json, response)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/google/genai/errors.py:131\u001b[0m, in \u001b[0;36mAPIError.raise_error\u001b[0;34m(cls, status_code, response_json, response)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Raises an appropriate APIError subclass based on the status code.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m  APIError: For other error status codes.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m400\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m status_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m500\u001b[39m:\n\u001b[0;32m--> 131\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m status_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m600\u001b[39m:\n\u001b[1;32m    133\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n",
      "\u001b[0;31mClientError\u001b[0m: 403 PERMISSION_DENIED. {'error': {'code': 403, 'message': 'The caller does not have permission', 'status': 'PERMISSION_DENIED'}}"
     ]
    }
   ],
   "source": [
    "\n",
    "out_dir = PROJECT_ROOT / \"RQ3\"\n",
    "out_dir.mkdir(exist_ok=True, parents=True)\n",
    "out_path = out_dir / \"rq3_validation_evidence.parquet\"\n",
    "\n",
    "records = []\n",
    "ai_core = load_pr_core(\"ai\")\n",
    "human_core = load_pr_core(\"human\")\n",
    "\n",
    "limit = None\n",
    "\n",
    "def save_partial(records, out_path):\n",
    "    df_tmp = pd.DataFrame(records)\n",
    "    df_tmp.to_parquet(out_path, index=False)\n",
    "    print(f\"[partial save] Saved {len(df_tmp)} rows to {out_path}\")\n",
    "\n",
    "ai_ids = list(pr_ids_from_commits(\"ai\", limit=limit))\n",
    "human_ids = list(pr_ids_from_commits(\"human\", limit=limit))\n",
    "print(f\"Processing {len(ai_ids)} AI PRs and {len(human_ids)} human PRs (first {limit} each).\")\n",
    "\n",
    "# ============================\n",
    "# Process AI PRs\n",
    "# ============================\n",
    "for idx, pr_id in enumerate(ai_ids, 1):\n",
    "    print(f\"Processing AI PR {idx}/{len(ai_ids)}: {pr_id}\")\n",
    "    try:\n",
    "        records.append(analyze_pr(\"ai\", pr_id, \"ai_agent\", ai_core))\n",
    "    except Exception as exc:\n",
    "        records.append({\n",
    "            \"pr_id\": pr_id,\n",
    "            \"author_type\": \"ai_agent\",\n",
    "            \"repo\": \"\",\n",
    "            \"pr_number\": None,\n",
    "            \"pr_title\": \"\",\n",
    "            \"pipeline_names\": [],\n",
    "            \"validation_present\": None,\n",
    "            \"evidence_sources\": [],\n",
    "            \"validation_type\": \"error\",\n",
    "            \"validation_description\": f\"error: {exc}\",\n",
    "            \"pipeline_signal\": \"\",\n",
    "            \"description_signal\": \"\",\n",
    "            \"comment_signal\": \"\",\n",
    "        })\n",
    "\n",
    "    # ---- SAVE EVERY 20 ----\n",
    "    if len(records) % 20 == 0:\n",
    "        save_partial(records, out_path)\n",
    "\n",
    "# ============================\n",
    "# Process Human PRs\n",
    "# ============================\n",
    "for idx, pr_id in enumerate(human_ids, 1):\n",
    "    print(f\"Processing human PR {idx}/{len(human_ids)}: {pr_id}\")\n",
    "    try:\n",
    "        records.append(analyze_pr(\"human\", pr_id, \"human\", human_core))\n",
    "    except Exception as exc:\n",
    "        records.append({\n",
    "            \"pr_id\": pr_id,\n",
    "            \"author_type\": \"human\",\n",
    "            \"repo\": \"\",\n",
    "            \"pr_number\": None,\n",
    "            \"pr_title\": \"\",\n",
    "            \"pipeline_names\": [],\n",
    "            \"validation_present\": None,\n",
    "            \"evidence_sources\": [],\n",
    "            \"validation_type\": \"error\",\n",
    "            \"validation_description\": f\"error: {exc}\",\n",
    "            \"pipeline_signal\": \"\",\n",
    "            \"description_signal\": \"\",\n",
    "            \"comment_signal\": \"\",\n",
    "        })\n",
    "\n",
    "    # ---- SAVE EVERY 20 ----\n",
    "    if len(records) % 20 == 0:\n",
    "        save_partial(records, out_path)\n",
    "\n",
    "# ============================\n",
    "# Final save\n",
    "# ============================\n",
    "df = pd.DataFrame(records)\n",
    "df.to_parquet(out_path, index=False)\n",
    "print(f\"Saved FINAL {len(df)} rows to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e12e20c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pr_id</th>\n",
       "      <th>author_type</th>\n",
       "      <th>repo</th>\n",
       "      <th>pr_number</th>\n",
       "      <th>pr_title</th>\n",
       "      <th>pipeline_names</th>\n",
       "      <th>validation_present</th>\n",
       "      <th>evidence_sources</th>\n",
       "      <th>validation_type</th>\n",
       "      <th>validation_description</th>\n",
       "      <th>pipeline_signal</th>\n",
       "      <th>description_signal</th>\n",
       "      <th>comment_signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>3240593081</td>\n",
       "      <td>ai_agent</td>\n",
       "      <td>Doriandarko/make-it-heavy</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Codex/integrate tygent module for performance</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>none</td>\n",
       "      <td>No validation evidence</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>3241057566</td>\n",
       "      <td>ai_agent</td>\n",
       "      <td>vllm-project/vllm</td>\n",
       "      <td>21146.0</td>\n",
       "      <td>[Core] Freeze gc during cuda graph capture to speed up init</td>\n",
       "      <td>[Lint and Deploy Charts, pre-commit]</td>\n",
       "      <td>True</td>\n",
       "      <td>[description, comments]</td>\n",
       "      <td>benchmark</td>\n",
       "      <td>The PR description and comments provide detailed before/after benchmarks and comparisons of different configurations, showing a significant speedup in CUDA graph capture time (e.g., from 35s to 2s).</td>\n",
       "      <td>Pipelines are for linting and deployment, not performance.</td>\n",
       "      <td>Description provides before/after benchmark results showing a speedup from 35s to 2s for cudagraph capture.</td>\n",
       "      <td>Comments contain extensive benchmark results comparing different approaches and configurations, showing significant performance improvements.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>3241523087</td>\n",
       "      <td>ai_agent</td>\n",
       "      <td>doodlum/skyrim-community-shaders</td>\n",
       "      <td>1281.0</td>\n",
       "      <td>perf: cache GetRuntimeData usage for improved performance</td>\n",
       "      <td>[WIP]</td>\n",
       "      <td>True</td>\n",
       "      <td>[description, comments]</td>\n",
       "      <td>profiling</td>\n",
       "      <td>The PR description claims performance improvements by caching function calls. However, a detailed analysis in the comments refutes the initial claims, showing the actual performance impact is minimal after profiling the underlying library calls.</td>\n",
       "      <td>No perf-related pipelines.</td>\n",
       "      <td>Claims performance improvement by eliminating 'expensive' function calls.</td>\n",
       "      <td>Detailed analysis in comments refutes initial claims, showing minimal performance gain after profiling the underlying code.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>3241690700</td>\n",
       "      <td>ai_agent</td>\n",
       "      <td>mochilang/mochi</td>\n",
       "      <td>9435.0</td>\n",
       "      <td>Update Clojure compiler</td>\n",
       "      <td>[Test]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>none</td>\n",
       "      <td>The PR description mentions an optimization but provides no performance data or benchmark results to validate it. The pipeline is a generic test run.</td>\n",
       "      <td>The 'Test' pipeline does not suggest performance validation.</td>\n",
       "      <td>Describes an optimization but provides no performance data to validate it.</td>\n",
       "      <td>No comments.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>3241691177</td>\n",
       "      <td>ai_agent</td>\n",
       "      <td>mochilang/mochi</td>\n",
       "      <td>9436.0</td>\n",
       "      <td>Improve Dart aggregate inference</td>\n",
       "      <td>[Test]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>none</td>\n",
       "      <td>No validation evidence. The description mentions compiler refinements which could impact performance, but no benchmarks or metrics are provided. The pipeline is a generic test run.</td>\n",
       "      <td>The 'Test' pipeline does not suggest performance validation.</td>\n",
       "      <td>Description mentions compiler refinements but lacks any performance metrics, benchmarks, or profiling data.</td>\n",
       "      <td>No comments.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>3241695471</td>\n",
       "      <td>ai_agent</td>\n",
       "      <td>mochilang/mochi</td>\n",
       "      <td>9440.0</td>\n",
       "      <td>Improve Lua compiler membership optimization</td>\n",
       "      <td>[Test]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>none</td>\n",
       "      <td>No validation evidence found. The description mentions an optimization but provides no performance data, benchmarks, or profiling results to support the claim.</td>\n",
       "      <td>The 'Test' pipeline does not indicate performance validation.</td>\n",
       "      <td>Mentions 'optimize' but provides no performance data or benchmark results.</td>\n",
       "      <td>No comments.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>3241758610</td>\n",
       "      <td>ai_agent</td>\n",
       "      <td>mochilang/mochi</td>\n",
       "      <td>9484.0</td>\n",
       "      <td>Improve Clojure join compilation</td>\n",
       "      <td>[Test]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>none</td>\n",
       "      <td>The PR description mentions 'optimize' but provides no performance validation data like benchmarks or profiling results. The testing described is functional.</td>\n",
       "      <td>The 'Test' pipeline does not suggest performance validation.</td>\n",
       "      <td>The description mentions 'optimize' but the testing section only shows a standard 'go test' command, not a benchmark.</td>\n",
       "      <td>No comments.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>3242128024</td>\n",
       "      <td>ai_agent</td>\n",
       "      <td>mochilang/mochi</td>\n",
       "      <td>9492.0</td>\n",
       "      <td>Improve Python compiler list set ops</td>\n",
       "      <td>[Test]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>none</td>\n",
       "      <td>The PR description mentions an 'optimize' goal, but no performance validation evidence like benchmarks or profiling is provided. The pipeline is a standard test run.</td>\n",
       "      <td>Pipeline 'Test' does not imply performance validation.</td>\n",
       "      <td>Mentions 'optimize' but provides no performance data, only a standard 'go test' command.</td>\n",
       "      <td>No comments.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>3242396116</td>\n",
       "      <td>ai_agent</td>\n",
       "      <td>mochilang/mochi</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>Improve Prolog compiler map indexing</td>\n",
       "      <td>[Test]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>none</td>\n",
       "      <td>No validation evidence. The PR description mentions optimizations but the testing section only shows unit test commands, not performance benchmarks or results.</td>\n",
       "      <td>The 'Test' pipeline is generic and does not suggest performance testing.</td>\n",
       "      <td>Mentions optimizations but only provides unit test commands, no benchmark results or performance metrics.</td>\n",
       "      <td>No comments.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>3242666013</td>\n",
       "      <td>ai_agent</td>\n",
       "      <td>ohcnetwork/care_fe</td>\n",
       "      <td>12979.0</td>\n",
       "      <td>Optimize encounter page API calls</td>\n",
       "      <td>[Auto Label Conflicts, Code scanning - action, Cypress Tests, Deploy Care Fe, Lint Code Base, OSSAR]</td>\n",
       "      <td>True</td>\n",
       "      <td>[description, comments]</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>The PR description and comments detail optimizations to reduce redundant API calls and improve data fetching strategies for performance.</td>\n",
       "      <td>Pipelines are for linting, E2E tests, and deployment, with no indication of performance testing.</td>\n",
       "      <td>The description explicitly states the goal is to optimize queries and remove duplicate API calls to improve performance by reducing the number of initial API calls.</td>\n",
       "      <td>An auto-generated comment summarizes the refactoring of data fetching logic for performance improvement.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>3245509530</td>\n",
       "      <td>ai_agent</td>\n",
       "      <td>mochilang/mochi</td>\n",
       "      <td>10318.0</td>\n",
       "      <td>Improve TS transpiler loops</td>\n",
       "      <td>[Test]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>none</td>\n",
       "      <td>No validation evidence. The pipeline is a generic 'Test' and the description only mentions running 'go test', which is for functional testing.</td>\n",
       "      <td>Pipeline 'Test' does not imply performance validation.</td>\n",
       "      <td>Description mentions 'go test', which is standard functional testing, not performance validation.</td>\n",
       "      <td>No comments provided.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>3245861239</td>\n",
       "      <td>ai_agent</td>\n",
       "      <td>mochilang/mochi</td>\n",
       "      <td>10448.0</td>\n",
       "      <td>Improve Ruby transpiler output</td>\n",
       "      <td>[Test]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>none</td>\n",
       "      <td>No validation evidence. The description mentions running 'go test', which typically refers to unit or integration tests, not performance validation. The pipeline name 'Test' is also generic.</td>\n",
       "      <td>The 'Test' pipeline name is generic and does not imply performance testing.</td>\n",
       "      <td>The description mentions 'go test', which indicates unit testing, not performance validation.</td>\n",
       "      <td>No comments provided.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>3245892725</td>\n",
       "      <td>ai_agent</td>\n",
       "      <td>mochilang/mochi</td>\n",
       "      <td>10497.0</td>\n",
       "      <td>Improve Dart transpiler progress</td>\n",
       "      <td>[Test]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>none</td>\n",
       "      <td>No validation evidence. The 'Test' pipeline and 'go test' command in the description suggest functional testing, not performance validation.</td>\n",
       "      <td>The 'Test' pipeline name does not suggest performance validation.</td>\n",
       "      <td>The description mentions a 'go test' command, which is insufficient to confirm performance validation.</td>\n",
       "      <td>No comments.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>3245899488</td>\n",
       "      <td>ai_agent</td>\n",
       "      <td>mochilang/mochi</td>\n",
       "      <td>10505.0</td>\n",
       "      <td>Improve Lua transpiler</td>\n",
       "      <td>[Test]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>none</td>\n",
       "      <td>No validation evidence. The PR description mentions running 'go test' with golden files, which is for correctness, not performance.</td>\n",
       "      <td>The 'Test' pipeline name does not imply performance testing.</td>\n",
       "      <td>The description details running 'go test' with golden files, indicating correctness testing, not performance validation.</td>\n",
       "      <td>No comments were provided.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>3245927515</td>\n",
       "      <td>ai_agent</td>\n",
       "      <td>mochilang/mochi</td>\n",
       "      <td>10515.0</td>\n",
       "      <td>Improve C transpiler output</td>\n",
       "      <td>[Test]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>none</td>\n",
       "      <td>No validation evidence found. The description mentions running 'go test', which typically refers to unit or integration tests, not performance tests. The pipeline name 'Test' is generic.</td>\n",
       "      <td>Pipeline 'Test' does not imply performance testing.</td>\n",
       "      <td>Description mentions 'go test', which is for unit/integration tests, not performance.</td>\n",
       "      <td>No comments.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>3245957050</td>\n",
       "      <td>ai_agent</td>\n",
       "      <td>mochilang/mochi</td>\n",
       "      <td>10525.0</td>\n",
       "      <td>Improve TS transpiler output</td>\n",
       "      <td>[Test]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>none</td>\n",
       "      <td>No validation evidence found. The pipeline name 'Test' is generic, and the description only refers to standard 'go test' commands, not performance tests.</td>\n",
       "      <td>Pipeline 'Test' does not imply performance validation.</td>\n",
       "      <td>Description mentions 'go test', which is for unit/integration tests, not performance validation.</td>\n",
       "      <td>No comments provided.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>3245970844</td>\n",
       "      <td>ai_agent</td>\n",
       "      <td>mochilang/mochi</td>\n",
       "      <td>10557.0</td>\n",
       "      <td>Improve rkt transpiler header and tasks</td>\n",
       "      <td>[Test]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>none</td>\n",
       "      <td>No validation evidence found. The PR description mentions a standard `go test` command, which indicates unit testing, not performance validation.</td>\n",
       "      <td>The 'Test' pipeline name does not imply performance testing.</td>\n",
       "      <td>The description provides a `go test` command, indicating unit testing, not performance validation.</td>\n",
       "      <td>No comments provided.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>3246099511</td>\n",
       "      <td>ai_agent</td>\n",
       "      <td>Rello/audioplayer</td>\n",
       "      <td>634.0</td>\n",
       "      <td>Optimize album art lookup</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>[description]</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>The PR description states the goal is to reduce filesystem lookups and mentions documenting a 'performance change' in the changelog, but provides no specific data or methodology.</td>\n",
       "      <td>No pipelines.</td>\n",
       "      <td>Mentions reducing filesystem lookups and documenting a performance change, but lacks specific data.</td>\n",
       "      <td>No comments.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>3246105987</td>\n",
       "      <td>ai_agent</td>\n",
       "      <td>Rello/analytics</td>\n",
       "      <td>522.0</td>\n",
       "      <td>Improve indexing and sharing performance</td>\n",
       "      <td>[REUSE Compliance Check]</td>\n",
       "      <td>True</td>\n",
       "      <td>[description]</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>The PR description claims performance improvements by reducing O(n^2) scans and adding caching, but provides no metrics or benchmark results. The only testing mentioned is unit tests.</td>\n",
       "      <td>The 'REUSE Compliance Check' pipeline is not a performance test.</td>\n",
       "      <td>The summary describes performance optimizations (reducing O(n^2) scans, batching updates, caching), but the testing section only mentions unit tests and provides no performance metrics.</td>\n",
       "      <td>No comments.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>3246117305</td>\n",
       "      <td>ai_agent</td>\n",
       "      <td>mochilang/mochi</td>\n",
       "      <td>10727.0</td>\n",
       "      <td>Improve ts transpiler</td>\n",
       "      <td>[Test]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>none</td>\n",
       "      <td>The PR only mentions standard unit tests (`go test ./...`) and a generic 'Test' pipeline, with no evidence of performance validation.</td>\n",
       "      <td>The 'Test' pipeline suggests unit/lint checks, not performance validation.</td>\n",
       "      <td>The description mentions running `go test ./...`, which indicates unit testing, not performance validation.</td>\n",
       "      <td>No comments provided.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pr_id author_type                              repo  pr_number  \\\n",
       "280  3240593081    ai_agent         Doriandarko/make-it-heavy        9.0   \n",
       "281  3241057566    ai_agent                 vllm-project/vllm    21146.0   \n",
       "282  3241523087    ai_agent  doodlum/skyrim-community-shaders     1281.0   \n",
       "283  3241690700    ai_agent                   mochilang/mochi     9435.0   \n",
       "284  3241691177    ai_agent                   mochilang/mochi     9436.0   \n",
       "285  3241695471    ai_agent                   mochilang/mochi     9440.0   \n",
       "286  3241758610    ai_agent                   mochilang/mochi     9484.0   \n",
       "287  3242128024    ai_agent                   mochilang/mochi     9492.0   \n",
       "288  3242396116    ai_agent                   mochilang/mochi     9550.0   \n",
       "289  3242666013    ai_agent                ohcnetwork/care_fe    12979.0   \n",
       "290  3245509530    ai_agent                   mochilang/mochi    10318.0   \n",
       "291  3245861239    ai_agent                   mochilang/mochi    10448.0   \n",
       "292  3245892725    ai_agent                   mochilang/mochi    10497.0   \n",
       "293  3245899488    ai_agent                   mochilang/mochi    10505.0   \n",
       "294  3245927515    ai_agent                   mochilang/mochi    10515.0   \n",
       "295  3245957050    ai_agent                   mochilang/mochi    10525.0   \n",
       "296  3245970844    ai_agent                   mochilang/mochi    10557.0   \n",
       "297  3246099511    ai_agent                 Rello/audioplayer      634.0   \n",
       "298  3246105987    ai_agent                   Rello/analytics      522.0   \n",
       "299  3246117305    ai_agent                   mochilang/mochi    10727.0   \n",
       "\n",
       "                                                        pr_title  \\\n",
       "280                Codex/integrate tygent module for performance   \n",
       "281  [Core] Freeze gc during cuda graph capture to speed up init   \n",
       "282    perf: cache GetRuntimeData usage for improved performance   \n",
       "283                                      Update Clojure compiler   \n",
       "284                             Improve Dart aggregate inference   \n",
       "285                 Improve Lua compiler membership optimization   \n",
       "286                             Improve Clojure join compilation   \n",
       "287                         Improve Python compiler list set ops   \n",
       "288                         Improve Prolog compiler map indexing   \n",
       "289                            Optimize encounter page API calls   \n",
       "290                                  Improve TS transpiler loops   \n",
       "291                               Improve Ruby transpiler output   \n",
       "292                             Improve Dart transpiler progress   \n",
       "293                                       Improve Lua transpiler   \n",
       "294                                  Improve C transpiler output   \n",
       "295                                 Improve TS transpiler output   \n",
       "296                      Improve rkt transpiler header and tasks   \n",
       "297                                    Optimize album art lookup   \n",
       "298                     Improve indexing and sharing performance   \n",
       "299                                        Improve ts transpiler   \n",
       "\n",
       "                                                                                           pipeline_names  \\\n",
       "280                                                                                                    []   \n",
       "281                                                                  [Lint and Deploy Charts, pre-commit]   \n",
       "282                                                                                                 [WIP]   \n",
       "283                                                                                                [Test]   \n",
       "284                                                                                                [Test]   \n",
       "285                                                                                                [Test]   \n",
       "286                                                                                                [Test]   \n",
       "287                                                                                                [Test]   \n",
       "288                                                                                                [Test]   \n",
       "289  [Auto Label Conflicts, Code scanning - action, Cypress Tests, Deploy Care Fe, Lint Code Base, OSSAR]   \n",
       "290                                                                                                [Test]   \n",
       "291                                                                                                [Test]   \n",
       "292                                                                                                [Test]   \n",
       "293                                                                                                [Test]   \n",
       "294                                                                                                [Test]   \n",
       "295                                                                                                [Test]   \n",
       "296                                                                                                [Test]   \n",
       "297                                                                                                    []   \n",
       "298                                                                              [REUSE Compliance Check]   \n",
       "299                                                                                                [Test]   \n",
       "\n",
       "    validation_present         evidence_sources validation_type  \\\n",
       "280              False                       []            none   \n",
       "281               True  [description, comments]       benchmark   \n",
       "282               True  [description, comments]       profiling   \n",
       "283              False                       []            none   \n",
       "284              False                       []            none   \n",
       "285              False                       []            none   \n",
       "286              False                       []            none   \n",
       "287              False                       []            none   \n",
       "288              False                       []            none   \n",
       "289               True  [description, comments]     unspecified   \n",
       "290              False                       []            none   \n",
       "291              False                       []            none   \n",
       "292              False                       []            none   \n",
       "293              False                       []            none   \n",
       "294              False                       []            none   \n",
       "295              False                       []            none   \n",
       "296              False                       []            none   \n",
       "297               True            [description]     unspecified   \n",
       "298               True            [description]     unspecified   \n",
       "299              False                       []            none   \n",
       "\n",
       "                                                                                                                                                                                                                                    validation_description  \\\n",
       "280                                                                                                                                                                                                                                 No validation evidence   \n",
       "281                                                 The PR description and comments provide detailed before/after benchmarks and comparisons of different configurations, showing a significant speedup in CUDA graph capture time (e.g., from 35s to 2s).   \n",
       "282  The PR description claims performance improvements by caching function calls. However, a detailed analysis in the comments refutes the initial claims, showing the actual performance impact is minimal after profiling the underlying library calls.   \n",
       "283                                                                                                  The PR description mentions an optimization but provides no performance data or benchmark results to validate it. The pipeline is a generic test run.   \n",
       "284                                                                   No validation evidence. The description mentions compiler refinements which could impact performance, but no benchmarks or metrics are provided. The pipeline is a generic test run.   \n",
       "285                                                                                        No validation evidence found. The description mentions an optimization but provides no performance data, benchmarks, or profiling results to support the claim.   \n",
       "286                                                                                          The PR description mentions 'optimize' but provides no performance validation data like benchmarks or profiling results. The testing described is functional.   \n",
       "287                                                                                  The PR description mentions an 'optimize' goal, but no performance validation evidence like benchmarks or profiling is provided. The pipeline is a standard test run.   \n",
       "288                                                                                        No validation evidence. The PR description mentions optimizations but the testing section only shows unit test commands, not performance benchmarks or results.   \n",
       "289                                                                                                               The PR description and comments detail optimizations to reduce redundant API calls and improve data fetching strategies for performance.   \n",
       "290                                                                                                         No validation evidence. The pipeline is a generic 'Test' and the description only mentions running 'go test', which is for functional testing.   \n",
       "291                                                         No validation evidence. The description mentions running 'go test', which typically refers to unit or integration tests, not performance validation. The pipeline name 'Test' is also generic.   \n",
       "292                                                                                                           No validation evidence. The 'Test' pipeline and 'go test' command in the description suggest functional testing, not performance validation.   \n",
       "293                                                                                                                    No validation evidence. The PR description mentions running 'go test' with golden files, which is for correctness, not performance.   \n",
       "294                                                             No validation evidence found. The description mentions running 'go test', which typically refers to unit or integration tests, not performance tests. The pipeline name 'Test' is generic.   \n",
       "295                                                                                              No validation evidence found. The pipeline name 'Test' is generic, and the description only refers to standard 'go test' commands, not performance tests.   \n",
       "296                                                                                                      No validation evidence found. The PR description mentions a standard `go test` command, which indicates unit testing, not performance validation.   \n",
       "297                                                                     The PR description states the goal is to reduce filesystem lookups and mentions documenting a 'performance change' in the changelog, but provides no specific data or methodology.   \n",
       "298                                                                The PR description claims performance improvements by reducing O(n^2) scans and adding caching, but provides no metrics or benchmark results. The only testing mentioned is unit tests.   \n",
       "299                                                                                                                  The PR only mentions standard unit tests (`go test ./...`) and a generic 'Test' pipeline, with no evidence of performance validation.   \n",
       "\n",
       "                                                                                      pipeline_signal  \\\n",
       "280                                                                                                     \n",
       "281                                        Pipelines are for linting and deployment, not performance.   \n",
       "282                                                                        No perf-related pipelines.   \n",
       "283                                      The 'Test' pipeline does not suggest performance validation.   \n",
       "284                                      The 'Test' pipeline does not suggest performance validation.   \n",
       "285                                     The 'Test' pipeline does not indicate performance validation.   \n",
       "286                                      The 'Test' pipeline does not suggest performance validation.   \n",
       "287                                            Pipeline 'Test' does not imply performance validation.   \n",
       "288                          The 'Test' pipeline is generic and does not suggest performance testing.   \n",
       "289  Pipelines are for linting, E2E tests, and deployment, with no indication of performance testing.   \n",
       "290                                            Pipeline 'Test' does not imply performance validation.   \n",
       "291                       The 'Test' pipeline name is generic and does not imply performance testing.   \n",
       "292                                 The 'Test' pipeline name does not suggest performance validation.   \n",
       "293                                      The 'Test' pipeline name does not imply performance testing.   \n",
       "294                                               Pipeline 'Test' does not imply performance testing.   \n",
       "295                                            Pipeline 'Test' does not imply performance validation.   \n",
       "296                                      The 'Test' pipeline name does not imply performance testing.   \n",
       "297                                                                                     No pipelines.   \n",
       "298                                  The 'REUSE Compliance Check' pipeline is not a performance test.   \n",
       "299                        The 'Test' pipeline suggests unit/lint checks, not performance validation.   \n",
       "\n",
       "                                                                                                                                                                            description_signal  \\\n",
       "280                                                                                                                                                                                              \n",
       "281                                                                                Description provides before/after benchmark results showing a speedup from 35s to 2s for cudagraph capture.   \n",
       "282                                                                                                                  Claims performance improvement by eliminating 'expensive' function calls.   \n",
       "283                                                                                                                 Describes an optimization but provides no performance data to validate it.   \n",
       "284                                                                                Description mentions compiler refinements but lacks any performance metrics, benchmarks, or profiling data.   \n",
       "285                                                                                                                 Mentions 'optimize' but provides no performance data or benchmark results.   \n",
       "286                                                                      The description mentions 'optimize' but the testing section only shows a standard 'go test' command, not a benchmark.   \n",
       "287                                                                                                   Mentions 'optimize' but provides no performance data, only a standard 'go test' command.   \n",
       "288                                                                                  Mentions optimizations but only provides unit test commands, no benchmark results or performance metrics.   \n",
       "289                       The description explicitly states the goal is to optimize queries and remove duplicate API calls to improve performance by reducing the number of initial API calls.   \n",
       "290                                                                                          Description mentions 'go test', which is standard functional testing, not performance validation.   \n",
       "291                                                                                              The description mentions 'go test', which indicates unit testing, not performance validation.   \n",
       "292                                                                                     The description mentions a 'go test' command, which is insufficient to confirm performance validation.   \n",
       "293                                                                   The description details running 'go test' with golden files, indicating correctness testing, not performance validation.   \n",
       "294                                                                                                      Description mentions 'go test', which is for unit/integration tests, not performance.   \n",
       "295                                                                                           Description mentions 'go test', which is for unit/integration tests, not performance validation.   \n",
       "296                                                                                         The description provides a `go test` command, indicating unit testing, not performance validation.   \n",
       "297                                                                                        Mentions reducing filesystem lookups and documenting a performance change, but lacks specific data.   \n",
       "298  The summary describes performance optimizations (reducing O(n^2) scans, batching updates, caching), but the testing section only mentions unit tests and provides no performance metrics.   \n",
       "299                                                                                The description mentions running `go test ./...`, which indicates unit testing, not performance validation.   \n",
       "\n",
       "                                                                                                                                    comment_signal  \n",
       "280                                                                                                                                                 \n",
       "281  Comments contain extensive benchmark results comparing different approaches and configurations, showing significant performance improvements.  \n",
       "282                    Detailed analysis in comments refutes initial claims, showing minimal performance gain after profiling the underlying code.  \n",
       "283                                                                                                                                   No comments.  \n",
       "284                                                                                                                                   No comments.  \n",
       "285                                                                                                                                   No comments.  \n",
       "286                                                                                                                                   No comments.  \n",
       "287                                                                                                                                   No comments.  \n",
       "288                                                                                                                                   No comments.  \n",
       "289                                       An auto-generated comment summarizes the refactoring of data fetching logic for performance improvement.  \n",
       "290                                                                                                                          No comments provided.  \n",
       "291                                                                                                                          No comments provided.  \n",
       "292                                                                                                                                   No comments.  \n",
       "293                                                                                                                     No comments were provided.  \n",
       "294                                                                                                                                   No comments.  \n",
       "295                                                                                                                          No comments provided.  \n",
       "296                                                                                                                          No comments provided.  \n",
       "297                                                                                                                                   No comments.  \n",
       "298                                                                                                                                   No comments.  \n",
       "299                                                                                                                          No comments provided.  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.expand_frame_repr\", True)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "data_temp = pd.read_parquet(out_path)\n",
    "data_temp.tail(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
