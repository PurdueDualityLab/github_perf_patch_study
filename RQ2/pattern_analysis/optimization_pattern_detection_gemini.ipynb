{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0486a43",
   "metadata": {},
   "source": [
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd880dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Environment ready!\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install pandas numpy matplotlib seaborn scipy wordcloud pyarrow datasets --quiet\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import re\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Environment ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "588b1d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compatibility shim: some versions of fsspec don't expose url_to_fs at top-level.\n",
    "# This ensures code that expects fsspec.url_to_fs (used by some IO backends) continues to work.\n",
    "try:\n",
    "    import fsspec\n",
    "    if not hasattr(fsspec, \"url_to_fs\"):\n",
    "        try:\n",
    "            from fsspec.core import url_to_fs as _url_to_fs\n",
    "        except Exception:\n",
    "            try:\n",
    "                import fsspec.core as _core\n",
    "                _url_to_fs = _core.url_to_fs\n",
    "            except Exception:\n",
    "                # Fallback shim: create a minimal url_to_fs that returns a filesystem and the path.\n",
    "                def _url_to_fs(url, **kwargs):\n",
    "                    protocol = url.split(\"://\")[0] if \"://\" in url else \"file\"\n",
    "                    fs = fsspec.filesystem(protocol)\n",
    "                    return fs, url\n",
    "        fsspec.url_to_fs = _url_to_fs\n",
    "except Exception:\n",
    "    # If anything goes wrong, continue without failing here; subsequent IO calls will raise their own errors.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06bd5c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading AIDev datasets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Performance PR IDs to process: 428\n",
      "\n",
      "Processing commit details (filtering to performance PRs only)...\n",
      "  Total commit records in dataset: 719,797\n",
      "  Filtered to performance PRs: 15,284 commit records\n",
      "  Unique performance PRs with commits: 427\n",
      "  Filtered out null filenames: 46 records removed\n",
      "  Remaining after filename filter: 15,238 commit records\n",
      "  Filtered out config-only commits: 44 records removed\n",
      "  Remaining after config filter: 15,194 commit records\n",
      "  Filtered out merge commits: 10,166 records removed\n",
      "  Remaining after merge filter: 5,028 commit records\n",
      "  Removed deleted repo PR commits: 74 records removed\n",
      "  Remaining after deleted repo filter: 4,954 commit records\n",
      "  Unique performance PRs after all filters: 407\n",
      "  ✓ Aggregated to 407 unique performance PRs\n",
      "  Avg commits per PR: 12.2\n",
      "  AI Agent PRs with commit data: 324 / 340 (95.3%)\n",
      "  Human PRs with commit data: 83 / 88 (94.3%)\n",
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "Original Performance PRs:\n",
      "  AI Agent: 340\n",
      "  Human: 88\n",
      "  Total: 428\n",
      "\n",
      "After Commit Filtering:\n",
      "✓ AI Agent Performance PRs: 324\n",
      "✓ Human Performance PRs: 83\n",
      "✓ Total Performance PRs: 407\n",
      "\n",
      "AI Agent Distribution:\n",
      "  OpenAI_Codex           205 ( 63.3%)\n",
      "  Devin                   59 ( 18.2%)\n",
      "  Copilot                 37 ( 11.4%)\n",
      "  Cursor                  20 (  6.2%)\n",
      "  Claude_Code              3 (  0.9%)\n",
      "\n",
      "================================================================================\n",
      "COMMIT STATISTICS\n",
      "================================================================================\n",
      "\n",
      "AI Agent:\n",
      "  PRs with commit data: 324\n",
      "  Avg commits per PR: 13.3\n",
      "  Median commits per PR: 4.0\n",
      "  Avg additions: 368 lines\n",
      "  Median additions: 61 lines\n",
      "  Avg deletions: 282 lines\n",
      "  Median deletions: 25 lines\n",
      "\n",
      "Human:\n",
      "  PRs with commit data: 83\n",
      "  Avg commits per PR: 7.8\n",
      "  Median commits per PR: 2.0\n",
      "  Avg additions: 204 lines\n",
      "  Median additions: 29 lines\n",
      "  Avg deletions: 142 lines\n",
      "  Median deletions: 19 lines\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load datasets\n",
    "print(\"Loading AIDev datasets...\")\n",
    "\n",
    "# AI Agent PRs\n",
    "pr_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/pull_request.parquet\")\n",
    "pr_task_type_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/pr_task_type.parquet\")\n",
    "ai_perf_prs = (\n",
    "    pr_df\n",
    "    .merge(\n",
    "        pr_task_type_df[[\"id\", \"type\", \"reason\"]],\n",
    "        on=\"id\",\n",
    "        how=\"inner\"\n",
    "    )\n",
    "    .query(\"type == 'perf'\")\n",
    "    .copy()\n",
    ")\n",
    "ai_perf_prs['classification_reason'] = ai_perf_prs['reason']\n",
    "ai_perf_prs['author_type'] = 'AI Agent'\n",
    "\n",
    "# Human PRs\n",
    "human_pr_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/human_pull_request.parquet\")\n",
    "human_pr_task_type_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/human_pr_task_type.parquet\")\n",
    "human_perf_prs = (\n",
    "    human_pr_df\n",
    "    .merge(\n",
    "        human_pr_task_type_df[[\"id\", \"type\", \"reason\"]],\n",
    "        on=\"id\",\n",
    "        how=\"inner\"\n",
    "    )\n",
    "    .query(\"type == 'perf'\")\n",
    "    .copy()\n",
    ")\n",
    "human_perf_prs['classification_reason'] = human_perf_prs['reason']\n",
    "human_perf_prs['author_type'] = 'Human'\n",
    "human_perf_prs['agent'] = 'Human'\n",
    "\n",
    "# Store original counts\n",
    "original_ai_count = len(ai_perf_prs)\n",
    "original_human_count = len(human_perf_prs)\n",
    "\n",
    "# Repository data for language info\n",
    "all_repo_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/all_repository.parquet\")\n",
    "\n",
    "# Get list of performance PR IDs we care about\n",
    "perf_pr_ids = set(ai_perf_prs['id'].tolist() + human_perf_prs['id'].tolist())\n",
    "print(f\"\\n✓ Performance PR IDs to process: {len(perf_pr_ids):,}\")\n",
    "\n",
    "# PR commits details - FILTER FIRST, then aggregate\n",
    "print(\"\\nProcessing commit details (filtering to performance PRs only)...\")\n",
    "pr_commits_details = pd.read_parquet(\"hf://datasets/hao-li/AIDev/pr_commit_details.parquet\")\n",
    "\n",
    "# Pr commit details for human PRs\n",
    "human_pr_commit_details = pd.read_parquet(\"./../../datasets/human_pr/human_pr_commit_details_original.parquet\")\n",
    "human_pr_commits = pd.read_parquet(\"./../../datasets/human_pr/human_pr_commits_original.parquet\")\n",
    "\n",
    "# Extract only the columns you need from the second table\n",
    "msg_df = human_pr_commits[[\"sha\", \"commit_message\"]]\n",
    "\n",
    "human_pr_commit_details = (\n",
    "    human_pr_commit_details\n",
    "        .merge(msg_df, on=\"sha\", how=\"left\")\n",
    ")\n",
    "\n",
    "human_pr_commit_details.rename(columns={\"commit_message\": \"message\"}, inplace=True)\n",
    "\n",
    "pr_commits_details = pd.concat(\n",
    "    [pr_commits_details, human_pr_commit_details],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "if 'pr_id' in pr_commits_details.columns:\n",
    "    print(f\"  Total commit records in dataset: {len(pr_commits_details):,}\")\n",
    "    \n",
    "    # FILTER: Keep only commits for performance PRs\n",
    "    pr_commits_filtered = pr_commits_details[pr_commits_details['pr_id'].isin(perf_pr_ids)].copy()\n",
    "    print(f\"  Filtered to performance PRs: {len(pr_commits_filtered):,} commit records\")\n",
    "    print(f\"  Unique performance PRs with commits: {pr_commits_filtered['pr_id'].nunique():,}\")\n",
    "    \n",
    "    # ADDITIONAL FILTERING: Remove commits with null filename\n",
    "    if 'filename' in pr_commits_filtered.columns:\n",
    "        before_filename_filter = len(pr_commits_filtered)\n",
    "        pr_commits_filtered = pr_commits_filtered[pr_commits_filtered['filename'].notna()].copy()\n",
    "        print(f\"  Filtered out null filenames: {before_filename_filter - len(pr_commits_filtered):,} records removed\")\n",
    "        print(f\"  Remaining after filename filter: {len(pr_commits_filtered):,} commit records\")\n",
    "        \n",
    "    # ADDITIONAL FILTERING: Remove config/metadata-only files\n",
    "    if 'filename' in pr_commits_filtered.columns:\n",
    "        before_config_filter = len(pr_commits_filtered)\n",
    "        \n",
    "        # Define patterns for non-code files to exclude\n",
    "        config_patterns = [\n",
    "            r'^\\.mvn/',                          # Maven wrapper configs\n",
    "            r'^\\.gradle/',                       # Gradle configs\n",
    "            r'^\\.idea/',                         # IntelliJ configs\n",
    "            r'^\\.vscode/',                       # VSCode configs\n",
    "            r'^\\.github/workflows/',             # GitHub Actions (unless it's code)\n",
    "            r'\\.properties$',                    # Properties files\n",
    "            r'\\.xml$',                           # XML config files (pom.xml, etc.)\n",
    "            r'\\.yml$',                           # YAML configs\n",
    "            r'\\.yaml$',                          # YAML configs\n",
    "            r'\\.json$',                          # JSON configs (package.json, etc.)\n",
    "            r'\\.md$',                            # Markdown docs\n",
    "            r'\\.txt$',                           # Text files\n",
    "            r'\\.gitignore$',                     # Git configs\n",
    "            r'\\.dockerignore$',                  # Docker ignore files\n",
    "            r'/Dockerfile$',                     # Dockerfiles (anywhere in path)\n",
    "            r'^Dockerfile$',                     # Dockerfile at root\n",
    "            r'/docker-compose',                  # Docker compose (anywhere)\n",
    "            r'^docker-compose',                  # Docker compose at root\n",
    "            r'\\.lock$',                          # Lock files (package-lock, yarn.lock)\n",
    "            r'^LICENSE',                         # License files\n",
    "            r'^README',                          # README files\n",
    "        ]\n",
    "        \n",
    "        config_pattern = '|'.join(config_patterns)\n",
    "        \n",
    "        # Mark config files\n",
    "        pr_commits_filtered['is_config_file'] = pr_commits_filtered['filename'].str.contains(\n",
    "            config_pattern, case=False, na=False, regex=True\n",
    "        )\n",
    "        \n",
    "        # Keep track of which files are code files per PR\n",
    "        pr_commits_filtered['is_code_file'] = ~pr_commits_filtered['is_config_file']\n",
    "        \n",
    "        # For each PR, check if it has ANY code files\n",
    "        pr_has_code = pr_commits_filtered.groupby('pr_id')['is_code_file'].any().reset_index()\n",
    "        pr_has_code.columns = ['pr_id', 'has_code_files']\n",
    "        \n",
    "        # Filter to keep only PRs that have at least one code file\n",
    "        pr_commits_filtered = pr_commits_filtered.merge(pr_has_code, on='pr_id', how='left')\n",
    "        pr_commits_filtered = pr_commits_filtered[pr_commits_filtered['has_code_files']].copy()\n",
    "        \n",
    "        # Clean up temporary columns\n",
    "        pr_commits_filtered = pr_commits_filtered.drop(columns=['is_config_file', 'is_code_file', 'has_code_files'])\n",
    "        \n",
    "        print(f\"  Filtered out config-only commits: {before_config_filter - len(pr_commits_filtered):,} records removed\")\n",
    "        print(f\"  Remaining after config filter: {len(pr_commits_filtered):,} commit records\")\n",
    "    \n",
    "    # ADDITIONAL FILTERING: Remove merge commits\n",
    "    if 'message' in pr_commits_filtered.columns:\n",
    "        before_merge_filter = len(pr_commits_filtered)\n",
    "        # Common merge commit patterns\n",
    "        merge_patterns = [\n",
    "            r'^Merge\\s+branch',\n",
    "            r'^Merge\\s+pull\\s+request',\n",
    "            r'^Merge\\s+remote-tracking\\s+branch',\n",
    "            r'^Merge\\s+.*\\s+into\\s+',\n",
    "            r\"^Merged\\s+in\\s+\",\n",
    "        ]\n",
    "        merge_pattern = '|'.join(merge_patterns)\n",
    "        pr_commits_filtered = pr_commits_filtered[\n",
    "            ~pr_commits_filtered['message'].str.match(merge_pattern, case=False, na=False)\n",
    "        ].copy()\n",
    "        print(f\"  Filtered out merge commits: {before_merge_filter - len(pr_commits_filtered):,} records removed\")\n",
    "        print(f\"  Remaining after merge filter: {len(pr_commits_filtered):,} commit records\")\n",
    "\n",
    "        # FINAL FILTER: drop PRs whose repositories were deleted\n",
    "        deleted_repo_pr_ids = {3271610326, 3209206554}\n",
    "        before_deleted_repo_filter = len(pr_commits_filtered)\n",
    "        pr_commits_filtered = pr_commits_filtered[~pr_commits_filtered['pr_id'].isin(deleted_repo_pr_ids)].copy()\n",
    "        removed_deleted_repo_commits = before_deleted_repo_filter - len(pr_commits_filtered)\n",
    "        if removed_deleted_repo_commits > 0:\n",
    "            print(f\"  Removed deleted repo PR commits: {removed_deleted_repo_commits:,} records removed\")\n",
    "        print(f\"  Remaining after deleted repo filter: {len(pr_commits_filtered):,} commit records\")\n",
    "    \n",
    "    print(f\"  Unique performance PRs after all filters: {pr_commits_filtered['pr_id'].nunique():,}\")\n",
    "    \n",
    "    if len(pr_commits_filtered) > 0:\n",
    "        # AGGREGATE: Now aggregate only the filtered commits\n",
    "        commit_aggregated = pr_commits_filtered.groupby('pr_id').agg({\n",
    "            'additions': 'sum',      # Total lines added across all commits\n",
    "            'deletions': 'sum',      # Total lines deleted across all commits\n",
    "            'patch': lambda x: '\\n\\n'.join([str(p) for p in x if pd.notna(p)])  # Concatenate all patches\n",
    "        }).reset_index()\n",
    "        \n",
    "        # Add derived metrics\n",
    "        commit_aggregated['num_commits'] = pr_commits_filtered.groupby('pr_id').size().values\n",
    "        \n",
    "        # Calculate patch length (for analysis)\n",
    "        commit_aggregated['patch_length'] = commit_aggregated['patch'].str.len()\n",
    "        \n",
    "        print(f\"  ✓ Aggregated to {len(commit_aggregated):,} unique performance PRs\")\n",
    "        print(f\"  Avg commits per PR: {commit_aggregated['num_commits'].mean():.1f}\")\n",
    "        \n",
    "        # Merge commit stats into AI Agent PR table\n",
    "        ai_perf_prs = ai_perf_prs.merge(\n",
    "            commit_aggregated,\n",
    "            left_on='id',\n",
    "            right_on='pr_id',\n",
    "            how='left'\n",
    "        )\n",
    "        if 'pr_id' in ai_perf_prs.columns:\n",
    "            ai_perf_prs = ai_perf_prs.drop(columns=['pr_id'])\n",
    "        \n",
    "        # Filter to keep only PRs with commit data\n",
    "        ai_before_filter = len(ai_perf_prs)\n",
    "        ai_with_commits = ai_perf_prs[ai_perf_prs['additions'].notna()].copy()\n",
    "        print(f\"  AI Agent PRs with commit data: {len(ai_with_commits):,} / {ai_before_filter:,} ({len(ai_with_commits)/ai_before_filter*100:.1f}%)\")\n",
    "        \n",
    "        # Merge commit stats into Human PR table\n",
    "        human_perf_prs = human_perf_prs.merge(\n",
    "            commit_aggregated,\n",
    "            left_on='id',\n",
    "            right_on='pr_id',\n",
    "            how='left'\n",
    "        )\n",
    "        if 'pr_id' in human_perf_prs.columns:\n",
    "            human_perf_prs = human_perf_prs.drop(columns=['pr_id'])\n",
    "        \n",
    "        # Filter to keep only PRs with commit data\n",
    "        human_before_filter = len(human_perf_prs)\n",
    "        human_with_commits = human_perf_prs[human_perf_prs['additions'].notna()].copy()\n",
    "        print(f\"  Human PRs with commit data: {len(human_with_commits):,} / {human_before_filter:,} ({len(human_with_commits)/human_before_filter*100:.1f}%)\")\n",
    "    else:\n",
    "        print(\"  ⚠ No commits found for performance PRs after filtering\")\n",
    "        # Create empty dataframes with same structure\n",
    "        ai_with_commits = ai_perf_prs.iloc[0:0].copy()\n",
    "        human_with_commits = human_perf_prs.iloc[0:0].copy()\n",
    "    \n",
    "else:\n",
    "    print('⚠ pr_commit_details missing pr_id column; skipping commit merges.')\n",
    "    # Create empty dataframes\n",
    "    ai_with_commits = ai_perf_prs.iloc[0:0].copy()\n",
    "    human_with_commits = human_perf_prs.iloc[0:0].copy()\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"SUMMARY\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Original Performance PRs:\")\n",
    "print(f\"  AI Agent: {original_ai_count:,}\")\n",
    "print(f\"  Human: {original_human_count:,}\")\n",
    "print(f\"  Total: {original_ai_count + original_human_count:,}\")\n",
    "print(f\"\\nAfter Commit Filtering:\")\n",
    "print(f\"✓ AI Agent Performance PRs: {len(ai_with_commits):,}\")\n",
    "print(f\"✓ Human Performance PRs: {len(human_with_commits):,}\")\n",
    "print(f\"✓ Total Performance PRs: {len(ai_with_commits) + len(human_with_commits):,}\")\n",
    "\n",
    "# Distribution by AI agent\n",
    "if len(ai_with_commits) > 0:\n",
    "    print(f\"\\nAI Agent Distribution:\")\n",
    "    for agent, count in ai_with_commits['agent'].value_counts().items():\n",
    "        pct = count / len(ai_with_commits) * 100\n",
    "        print(f\"  {agent:20s} {count:5,d} ({pct:5.1f}%)\")\n",
    "\n",
    "# Commit statistics summary\n",
    "if len(ai_with_commits) > 0 or len(human_with_commits) > 0:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"COMMIT STATISTICS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    for author_type, df in [('AI Agent', ai_with_commits), ('Human', human_with_commits)]:\n",
    "        if len(df) > 0:\n",
    "            print(f\"\\n{author_type}:\")\n",
    "            print(f\"  PRs with commit data: {len(df):,}\")\n",
    "            print(f\"  Avg commits per PR: {df['num_commits'].mean():.1f}\")\n",
    "            print(f\"  Median commits per PR: {df['num_commits'].median():.1f}\")\n",
    "            print(f\"  Avg additions: {df['additions'].mean():.0f} lines\")\n",
    "            print(f\"  Median additions: {df['additions'].median():.0f} lines\")\n",
    "            print(f\"  Avg deletions: {df['deletions'].mean():.0f} lines\")\n",
    "            print(f\"  Median deletions: {df['deletions'].median():.0f} lines\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07b0ab2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset: 407 performance PRs\n",
      "  AI Agents: 324\n",
      "  Humans: 83\n"
     ]
    }
   ],
   "source": [
    "# Combine AI and Human PRs\n",
    "perf_prs = pd.concat([ai_with_commits, human_with_commits], ignore_index=True)\n",
    "\n",
    "print(f\"Combined dataset: {len(perf_prs):,} performance PRs\")\n",
    "print(f\"  AI Agents: {(perf_prs['author_type'] == 'AI Agent').sum():,}\")\n",
    "print(f\"  Humans: {(perf_prs['author_type'] == 'Human').sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52c76e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset: 182 performance PRs\n",
      "  AI Agents: 137\n",
      "  Humans: 45\n"
     ]
    }
   ],
   "source": [
    "ai_todo_ids = pd.read_csv('./llm_data/final_data/ai_round3_todo.csv')\n",
    "human_todo_ids = pd.read_csv('./llm_data/final_data/human_round3_todo.csv')\n",
    "\n",
    "ai_id_list = ai_todo_ids['id'].tolist()\n",
    "human_id_list = human_todo_ids['id'].tolist()\n",
    "\n",
    "# Filter ai_with_commits to keep only rows where pr_id is in the list\n",
    "ai_with_commits_filtered = ai_with_commits[ai_with_commits['id'].isin(ai_id_list)]\n",
    "\n",
    "# Filter human_with_commits to keep only rows where pr_id is in the list\n",
    "human_with_commits_filtered = human_with_commits[human_with_commits['id'].isin(human_id_list)]\n",
    "\n",
    "# Combine AI and Human PRs\n",
    "perf_prs = pd.concat([ai_with_commits_filtered, human_with_commits_filtered], ignore_index=True)\n",
    "\n",
    "print(f\"Combined dataset: {len(perf_prs):,} performance PRs\")\n",
    "print(f\"  AI Agents: {(perf_prs['author_type'] == 'AI Agent').sum():,}\")\n",
    "print(f\"  Humans: {(perf_prs['author_type'] == 'Human').sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa5d5acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Performance Optimization Pattern Detection with Gemini 3-Pro\n",
    "# ============================================================================\n",
    "!pip install google-genai python-dotenv pydantic --quiet\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from pydantic import BaseModel, Field\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Define the structured output schema\n",
    "class AnalysisResult(BaseModel):\n",
    "    explanation: str = Field(description=\"Brief description of what the code is doing\")\n",
    "    optimization_comparison: str = Field(description=\"Detailed comparison highlighting specific optimizations\")\n",
    "    high_level_pattern: str = Field(description=\"Single most representative high-level optimization pattern (or 'No Meaningful Change')\")\n",
    "    sub_pattern: str = Field(description=\"Most representative sub-pattern within the category (or null if No Meaningful Change)\")\n",
    "\n",
    "def analyze_optimization_with_gemini(title, body, patch):\n",
    "    \"\"\"\n",
    "    Call Gemini to analyze performance optimization patterns in a commit.\n",
    "    \n",
    "    Parameters:\n",
    "    - title: PR/commit title\n",
    "    - body: PR/commit description\n",
    "    - patch: Git diff/patch content\n",
    "    \n",
    "    Returns:\n",
    "    - dict with analysis results or error info\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare the context\n",
    "    context_parts = []\n",
    "    \n",
    "    if pd.notna(title) and str(title).strip():\n",
    "        context_parts.append(f\"**Title**: {title}\")\n",
    "    \n",
    "    if pd.notna(body) and str(body).strip():\n",
    "        context_parts.append(f\"**Description**: {body}\")\n",
    "    \n",
    "    if pd.notna(patch) and str(patch).strip():\n",
    "        # Truncate very long patches to avoid token limits\n",
    "        patch_str = str(patch)\n",
    "        if len(patch_str) > 15000:  # Rough character limit\n",
    "            patch_str = patch_str[:15000] + \"\\n\\n... [patch truncated for length] ...\"\n",
    "        context_parts.append(f\"**Code Changes (Patch)**:\\n```diff\\n{patch_str}\\n```\")\n",
    "    \n",
    "    if not context_parts:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": \"No content available\",\n",
    "            \"explanation\": None,\n",
    "            \"optimization_comparison\": None,\n",
    "            \"high_level_pattern\": None,\n",
    "            \"sub_pattern\": None,\n",
    "            \"tokens_used\": 0\n",
    "        }\n",
    "    \n",
    "    context = \"\\n\\n\".join(context_parts)\n",
    "    \n",
    "    try:\n",
    "        load_dotenv(override=True)\n",
    "    except Exception:\n",
    "        # dotenv not installed / .env not loaded; rely on environment variables\n",
    "        pass\n",
    "\n",
    "    api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise RuntimeError(\"GEMINI_API_KEY not found in environment. Add it to your .env or export it.\")\n",
    "\n",
    "    # Initialize the client\n",
    "    client = genai.Client(api_key=api_key)\n",
    "    \n",
    "    # Construct the prompt\n",
    "    # Load the optimization patterns taxonomy from CSV\n",
    "    def load_optimization_taxonomy(csv_path):\n",
    "        \"\"\"Load and format the optimization patterns taxonomy from CSV.\"\"\"\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Format the taxonomy as a structured string\n",
    "        taxonomy_text = \"### Optimization Patterns Taxonomy:\\n\\n\"\n",
    "        \n",
    "        # Group by high-level pattern\n",
    "        for high_level in df['High-level Pattern'].unique():\n",
    "            taxonomy_text += f\"- **{high_level}**\\n\"\n",
    "            \n",
    "            # Get all sub-patterns for this high-level pattern\n",
    "            sub_patterns = df[df['High-level Pattern'] == high_level]\n",
    "            \n",
    "            for _, row in sub_patterns.iterrows():\n",
    "                taxonomy_text += f\"    - {row['Sub pattern']}\\n\"\n",
    "                if pd.notna(row['Description']):\n",
    "                    taxonomy_text += f\"        - Description: {row['Description']}\\n\"\n",
    "                if pd.notna(row['Example']):\n",
    "                    taxonomy_text += f\"        - Example: {row['Example']}\\n\"\n",
    "                if pd.notna(row['Optimized Metrics']):\n",
    "                    taxonomy_text += f\"        - Metrics: {row['Optimized Metrics']}\\n\"\n",
    "                if pd.notna(row['Detection']):\n",
    "                    taxonomy_text += f\"        - Detection: {row['Detection']}\\n\"\n",
    "        \n",
    "        return taxonomy_text\n",
    "\n",
    "    # Load taxonomy (adjust path as needed)\n",
    "    taxonomy = load_optimization_taxonomy('./catalog/updated_optimization_catalog.csv')\n",
    "\n",
    "    # Construct the prompt\n",
    "    prompt = f\"\"\"I have a performance optimization commit with the following information. Please analyze with the following goals:\n",
    "\n",
    "    1. **Code Function Explanation**: Briefly explain what the code is doing—what problem it solves and how it works.\n",
    "\n",
    "    2. **Optimization Comparison**: Compare the original and optimized versions to identify:\n",
    "    - **Algorithmic changes**: Any differences in logic, algorithm design, or problem-solving approach.\n",
    "    - **Performance improvements**: Enhancements related to time complexity, space efficiency, or runtime behavior.\n",
    "    - **Redundant code removal**: Elimination of unnecessary logic, method calls, or control structures.\n",
    "    - **Other noteworthy changes**: Any structural or stylistic differences that could impact performance or readability.\n",
    "    \n",
    "    3. **Optimization Pattern Classification**:\n",
    "    Based on the overall nature of the optimized code, assign the following. Return \"No Meaningful Change\" if no meaningful change is made.\n",
    "    - **Exactly one high-level optimization pattern** from the list below  \n",
    "    - **One most representative sub-pattern** within that high-level category\n",
    "    \n",
    "    {taxonomy}\n",
    "            \n",
    "    Here are the info:\n",
    "                \n",
    "    {context}\n",
    "\n",
    "    **Output Structure**:  \n",
    "    Please respond in JSON format with the following structure:\n",
    "    {{\n",
    "    \"explanation\": \"Brief description of what the code is doing\",\n",
    "    \"optimization_comparison\": \"Detailed comparison highlighting specific optimizations\",\n",
    "    \"high_level_pattern\": \"Single most representative high-level optimization pattern (or 'No Meaningful Change')\",\n",
    "    \"sub_pattern\": \"Most representative sub-pattern within the category (or null if No Meaningful Change)\",\n",
    "    }}\n",
    "\n",
    "    Ensure your response is valid JSON that can be parsed.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Generate response with structured output\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-3-pro-preview\",\n",
    "            contents=prompt,\n",
    "            config={\n",
    "                \"temperature\": 0,\n",
    "                \"response_mime_type\": \"application/json\",\n",
    "                \"response_json_schema\": AnalysisResult.model_json_schema(),\n",
    "                \"system_instruction\": \"You are an expert software engineer specializing in performance optimization analysis. Analyze code changes and classify optimization patterns accurately.\"\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Parse the response using Pydantic\n",
    "        result = AnalysisResult.model_validate_json(response.text)\n",
    "        \n",
    "        # Get token usage (if available)\n",
    "        tokens_used = 0\n",
    "        if hasattr(response, 'usage_metadata') and response.usage_metadata:\n",
    "            tokens_used = getattr(response.usage_metadata, 'total_token_count', 0)\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"explanation\": result.explanation,\n",
    "            \"optimization_comparison\": result.optimization_comparison,\n",
    "            \"high_level_pattern\": result.high_level_pattern,\n",
    "            \"sub_pattern\": result.sub_pattern,\n",
    "            \"tokens_used\": tokens_used,\n",
    "            \"error\": None\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": str(e),\n",
    "            \"explanation\": None,\n",
    "            \"optimization_comparison\": None,\n",
    "            \"high_level_pattern\": None,\n",
    "            \"sub_pattern\": None,\n",
    "            \"tokens_used\": 0\n",
    "        }\n",
    "\n",
    "\n",
    "def batch_analyze_performance_prs(perf_prs, batch_size=10, delay=1.0, resume=False, checkpoint_prefix='perf_prs_checkpoint', output_file='perf_prs_with_gemini_analysis.csv'):\n",
    "    \"\"\"\n",
    "    Analyze all performance PRs in batches using Gemini.\n",
    "\n",
    "    Parameters:\n",
    "    - perf_prs: DataFrame with performance PRs\n",
    "    - batch_size: Number of PRs to process before saving checkpoint\n",
    "    - delay: Delay between API calls in seconds\n",
    "    - resume: Continue from the last available checkpoint if True\n",
    "    - checkpoint_prefix: Filename prefix used for checkpoint files\n",
    "    - output_file: Final CSV filename for the aggregated results\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with analysis results added\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Starting Gemini analysis of {len(perf_prs):,} performance PRs...\")\n",
    "\n",
    "    checkpoint_files = []\n",
    "    processed_count = 0\n",
    "\n",
    "    if resume:\n",
    "        checkpoint_files = sorted(Path('.').glob(f\"{checkpoint_prefix}_*.csv\"))\n",
    "        if checkpoint_files:\n",
    "            def _processed_from_path(path_obj):\n",
    "                suffix = path_obj.stem.rsplit('_', 1)[-1]\n",
    "                return int(suffix) if suffix.isdigit() else 0\n",
    "\n",
    "            latest_checkpoint = max(checkpoint_files, key=_processed_from_path)\n",
    "            checkpoint_progress = _processed_from_path(latest_checkpoint)\n",
    "            perf_prs = pd.read_csv(latest_checkpoint)\n",
    "            processed_count = min(checkpoint_progress, len(perf_prs))\n",
    "            print(f\"↻ Resuming from checkpoint {latest_checkpoint} ({processed_count} PRs processed)...\")\n",
    "        else:\n",
    "            print(\"↻ Resume requested but no checkpoint found. Starting from scratch.\")\n",
    "\n",
    "    result_defaults = {\n",
    "        'gemini_explanation': None,\n",
    "        'gemini_comparison': None,\n",
    "        'optimization_pattern': None,\n",
    "        'optimization_subpattern': None,\n",
    "        'gemini_success': False,\n",
    "        'gemini_error': None,\n",
    "        'gemini_tokens': 0\n",
    "    }\n",
    "\n",
    "    for column, default in result_defaults.items():\n",
    "        if resume and column in perf_prs.columns:\n",
    "            continue\n",
    "        perf_prs[column] = default\n",
    "\n",
    "    start_idx = processed_count if resume else 0\n",
    "    iterator = range(start_idx, len(perf_prs))\n",
    "    progress_bar = tqdm(iterator, total=len(perf_prs), desc=\"Analyzing PRs\", initial=start_idx)\n",
    "\n",
    "    for idx in progress_bar:\n",
    "        row = perf_prs.iloc[idx]\n",
    "        result = analyze_optimization_with_gemini(\n",
    "            title=row.get('title'),\n",
    "            body=row.get('body'),\n",
    "            patch=row.get('patch')\n",
    "        )\n",
    "\n",
    "        perf_prs.at[idx, 'gemini_success'] = result['success']\n",
    "        perf_prs.at[idx, 'gemini_tokens'] = result['tokens_used']\n",
    "\n",
    "        if result['success']:\n",
    "            perf_prs.at[idx, 'gemini_explanation'] = result['explanation']\n",
    "            perf_prs.at[idx, 'gemini_comparison'] = result['optimization_comparison']\n",
    "            perf_prs.at[idx, 'optimization_pattern'] = result['high_level_pattern']\n",
    "            perf_prs.at[idx, 'optimization_subpattern'] = result['sub_pattern']\n",
    "            perf_prs.at[idx, 'gemini_error'] = None\n",
    "        else:\n",
    "            perf_prs.at[idx, 'gemini_error'] = result['error']\n",
    "\n",
    "        time.sleep(delay)\n",
    "\n",
    "        if (idx + 1) % batch_size == 0:\n",
    "            checkpoint_file = f\"{checkpoint_prefix}_{idx+1}.csv\"\n",
    "            perf_prs.to_csv(checkpoint_file, index=False)\n",
    "            print(f\"✓ Checkpoint saved: {checkpoint_file}\")\n",
    "\n",
    "    perf_prs.to_csv(output_file, index=False)\n",
    "    print(f\"✓ Analysis complete! Saved to: {output_file}\")\n",
    "\n",
    "    success_series = perf_prs['gemini_success'].fillna(False)\n",
    "    success_count = success_series.sum()\n",
    "    success_rate = (success_count / len(perf_prs) * 100) if len(perf_prs) else 0\n",
    "    failure_count = success_series.eq(False).sum()\n",
    "    total_tokens = perf_prs['gemini_tokens'].sum()\n",
    "\n",
    "    print(f\"{'='*80}\")\n",
    "    print(\"ANALYSIS SUMMARY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Total PRs analyzed: {len(perf_prs):,}\")\n",
    "    print(f\"Successful: {success_count:,} ({success_rate:.1f}%)\")\n",
    "    print(f\"Failed: {failure_count:,}\")\n",
    "    print(f\"Total tokens used: {total_tokens:,}\")\n",
    "\n",
    "    if success_count > 0:\n",
    "        print(f\"{'='*80}\")\n",
    "        print(\"OPTIMIZATION PATTERN DISTRIBUTION\")\n",
    "        print(f\"{'='*80}\")\n",
    "        pattern_counts = perf_prs[perf_prs['gemini_success'] == True]['optimization_pattern'].value_counts()\n",
    "        for pattern, count in pattern_counts.items():\n",
    "            pct = count / success_count * 100\n",
    "            print(f\"  {pattern:50s} {count:4d} ({pct:5.1f}%)\")\n",
    "\n",
    "    return perf_prs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532b365f",
   "metadata": {},
   "source": [
    "## Usage scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "107368e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Gemini analysis on 137 AI PRs\n",
      "Starting Gemini analysis of 137 performance PRs...\n",
      "↻ Resuming from checkpoint gemini_ai_perf_prs_checkpoint_56.csv (56 PRs processed)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  41%|████      | 56/137 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  42%|████▏     | 58/137 [02:53<1:52:56, 85.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_58.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  44%|████▍     | 60/137 [05:26<1:43:39, 80.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_60.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  45%|████▌     | 62/137 [07:55<1:32:38, 74.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_62.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  47%|████▋     | 64/137 [09:39<1:16:25, 62.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_64.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  48%|████▊     | 66/137 [10:47<54:19, 45.90s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_66.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  50%|████▉     | 68/137 [12:38<59:50, 52.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_68.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  51%|█████     | 70/137 [15:04<1:10:08, 62.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_70.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  53%|█████▎    | 72/137 [17:37<1:15:31, 69.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_72.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  54%|█████▍    | 74/137 [19:26<1:06:07, 62.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_74.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  55%|█████▌    | 76/137 [21:24<1:03:02, 62.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_76.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  57%|█████▋    | 78/137 [22:42<48:53, 49.71s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_78.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  58%|█████▊    | 80/137 [24:50<54:20, 57.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_80.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  60%|█████▉    | 82/137 [26:10<43:13, 47.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_82.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  61%|██████▏   | 84/137 [28:03<44:36, 50.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_84.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  63%|██████▎   | 86/137 [29:18<36:22, 42.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_86.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  64%|██████▍   | 88/137 [30:33<33:08, 40.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_88.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  66%|██████▌   | 90/137 [31:45<30:41, 39.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_90.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  67%|██████▋   | 92/137 [34:15<40:51, 54.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_92.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  69%|██████▊   | 94/137 [36:08<39:39, 55.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_94.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  70%|███████   | 96/137 [37:58<38:12, 55.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_96.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  72%|███████▏  | 98/137 [40:18<41:53, 64.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_98.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  73%|███████▎  | 100/137 [41:44<33:37, 54.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_100.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  74%|███████▍  | 102/137 [42:58<26:44, 45.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_102.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  76%|███████▌  | 104/137 [44:43<27:44, 50.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_104.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  77%|███████▋  | 106/137 [46:12<23:43, 45.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_106.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  79%|███████▉  | 108/137 [48:19<26:35, 55.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_108.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  80%|████████  | 110/137 [49:43<20:55, 46.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_110.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  82%|████████▏ | 112/137 [52:08<24:56, 59.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_112.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  83%|████████▎ | 114/137 [55:06<27:22, 71.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_114.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  85%|████████▍ | 116/137 [55:58<16:42, 47.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_116.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  86%|████████▌ | 118/137 [57:07<12:45, 40.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_118.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  88%|████████▊ | 120/137 [58:12<10:03, 35.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_120.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  89%|████████▉ | 122/137 [59:52<10:51, 43.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_122.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  91%|█████████ | 124/137 [1:00:57<08:12, 37.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_124.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  92%|█████████▏| 126/137 [1:02:29<07:21, 40.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_126.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  93%|█████████▎| 128/137 [1:03:17<04:53, 32.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_128.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  95%|█████████▍| 130/137 [1:04:26<03:45, 32.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_130.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  96%|█████████▋| 132/137 [1:05:26<02:33, 30.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_132.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  98%|█████████▊| 134/137 [1:06:22<01:29, 29.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_134.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  99%|█████████▉| 136/137 [1:08:11<00:41, 41.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: gemini_ai_perf_prs_checkpoint_136.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs: 100%|██████████| 137/137 [1:08:46<00:00, 50.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Analysis complete! Saved to: ai_perf_prs_with_gemini_analysis_new_catalog.csv\n",
      "================================================================================\n",
      "ANALYSIS SUMMARY\n",
      "================================================================================\n",
      "Total PRs analyzed: 137\n",
      "Successful: 137 (100.0%)\n",
      "Failed: 0\n",
      "Total tokens used: 3,376,432\n",
      "================================================================================\n",
      "OPTIMIZATION PATTERN DISTRIBUTION\n",
      "================================================================================\n",
      "  Algorithm-Level Optimizations                        33 ( 24.1%)\n",
      "  Code Smells and Structural Simplification            29 ( 21.2%)\n",
      "  Memory and Data Locality Optimizations               25 ( 18.2%)\n",
      "  Build & Compilation & Infrastructure Optimization    15 ( 10.9%)\n",
      "  I/O and Synchronization                              10 (  7.3%)\n",
      "  Network, Database, and Data Access Optimization       8 (  5.8%)\n",
      "  No Meaningful Change                                  6 (  4.4%)\n",
      "  Data Structure Selection and Adaptation               6 (  4.4%)\n",
      "  Loop Transformations                                  3 (  2.2%)\n",
      "  Control-Flow and Branching Optimizations              2 (  1.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Usage\n",
    "# ============================================================================\n",
    "\n",
    "# run ai and human pr analysis separately\n",
    "\n",
    "# ai pr analysis\n",
    "ai_sample = perf_prs[perf_prs['author_type'] == 'AI Agent'].copy().reset_index(drop=True)\n",
    "print(f\"Testing Gemini analysis on {len(ai_sample)} AI PRs\")\n",
    "\n",
    "# Run the analysis\n",
    "perf_prs_analyzed = batch_analyze_performance_prs(\n",
    "    ai_sample,\n",
    "    batch_size=2,    # Save checkpoint every 10 PRs\n",
    "    delay=0.5,        # 0.5 second delay between API calls\n",
    "    resume=True,      # Continue from the last saved checkpoint if available\n",
    "    checkpoint_prefix='gemini_ai_perf_prs_checkpoint',\n",
    "    output_file='ai_perf_prs_with_gemini_analysis_new_catalog.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e170d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the AI analysis results\n",
    "import pandas as pd\n",
    "ai_analyzed = pd.read_csv('ai_perf_prs_with_gemini_analysis.csv')\n",
    "\n",
    "# Find failed analyses\n",
    "failed_analyses = ai_analyzed[ai_analyzed['gemini_success'] == False]\n",
    "print(f\"Found {len(failed_analyses)} failed analyses\")\n",
    "print(failed_analyses[['id', 'title', 'gemini_error']].head(10))\n",
    "\n",
    "# Re-analyze failed PRs\n",
    "if len(failed_analyses) > 0:\n",
    "    print(f\"\\nRe-analyzing {len(failed_analyses)} failed PRs...\")\n",
    "    \n",
    "    for idx in failed_analyses.index:\n",
    "        row = ai_analyzed.iloc[idx]\n",
    "        print(f\"Re-analyzing PR {idx}: {row['title'][:50]}...\")\n",
    "        \n",
    "        result = analyze_optimization_with_gemini(\n",
    "            title=row.get('title'),\n",
    "            body=row.get('body'),\n",
    "            patch=row.get('patch')\n",
    "        )\n",
    "        \n",
    "        ai_analyzed.at[idx, 'gemini_success'] = result['success']\n",
    "        ai_analyzed.at[idx, 'gemini_tokens'] = result['tokens_used']\n",
    "        \n",
    "        if result['success']:\n",
    "            ai_analyzed.at[idx, 'gemini_explanation'] = result['explanation']\n",
    "            ai_analyzed.at[idx, 'gemini_comparison'] = result['optimization_comparison']\n",
    "            ai_analyzed.at[idx, 'optimization_pattern'] = result['high_level_pattern']\n",
    "            ai_analyzed.at[idx, 'optimization_subpattern'] = result['sub_pattern']\n",
    "            ai_analyzed.at[idx, 'gemini_error'] = None\n",
    "        else:\n",
    "            ai_analyzed.at[idx, 'gemini_error'] = result['error']\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    # Save updated results\n",
    "    ai_analyzed.to_csv('ai_perf_prs_with_gemini_analysis_updated.csv', index=False)\n",
    "    print(\"✓ Updated results saved!\")\n",
    "    \n",
    "    # Show summary\n",
    "    success_count = (ai_analyzed['gemini_success'] == True).sum()\n",
    "    print(f\"\\nFinal success rate: {success_count}/{len(ai_analyzed)} ({success_count/len(ai_analyzed)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6ba3fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Gemini analysis of 45 performance PRs...\n",
      "↻ Resume requested but no checkpoint found. Starting from scratch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:   0%|          | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:   4%|▍         | 2/45 [01:04<22:49, 31.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: human_perf_prs_checkpoint_gemini_2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:   9%|▉         | 4/45 [02:31<27:15, 39.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: human_perf_prs_checkpoint_gemini_4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  13%|█▎        | 6/45 [03:46<23:59, 36.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: human_perf_prs_checkpoint_gemini_6.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  18%|█▊        | 8/45 [05:21<27:48, 45.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: human_perf_prs_checkpoint_gemini_8.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  22%|██▏       | 10/45 [07:03<28:53, 49.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: human_perf_prs_checkpoint_gemini_10.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  27%|██▋       | 12/45 [08:38<27:24, 49.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: human_perf_prs_checkpoint_gemini_12.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  31%|███       | 14/45 [10:41<28:58, 56.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: human_perf_prs_checkpoint_gemini_14.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  36%|███▌      | 16/45 [13:23<32:38, 67.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: human_perf_prs_checkpoint_gemini_16.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  40%|████      | 18/45 [14:42<23:37, 52.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: human_perf_prs_checkpoint_gemini_18.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  44%|████▍     | 20/45 [16:24<22:05, 53.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: human_perf_prs_checkpoint_gemini_20.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  49%|████▉     | 22/45 [18:04<19:37, 51.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: human_perf_prs_checkpoint_gemini_22.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  53%|█████▎    | 24/45 [19:05<14:10, 40.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: human_perf_prs_checkpoint_gemini_24.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  58%|█████▊    | 26/45 [20:52<14:00, 44.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: human_perf_prs_checkpoint_gemini_26.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  62%|██████▏   | 28/45 [22:40<14:48, 52.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: human_perf_prs_checkpoint_gemini_28.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  67%|██████▋   | 30/45 [23:32<09:51, 39.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: human_perf_prs_checkpoint_gemini_30.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  71%|███████   | 32/45 [25:28<10:28, 48.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: human_perf_prs_checkpoint_gemini_32.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  76%|███████▌  | 34/45 [27:12<08:51, 48.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: human_perf_prs_checkpoint_gemini_34.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  80%|████████  | 36/45 [28:47<07:16, 48.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: human_perf_prs_checkpoint_gemini_36.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  84%|████████▍ | 38/45 [30:51<05:58, 51.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: human_perf_prs_checkpoint_gemini_38.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  89%|████████▉ | 40/45 [32:19<03:55, 47.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: human_perf_prs_checkpoint_gemini_40.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  93%|█████████▎| 42/45 [34:48<03:06, 62.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: human_perf_prs_checkpoint_gemini_42.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:  98%|█████████▊| 44/45 [36:04<00:49, 49.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: human_perf_prs_checkpoint_gemini_44.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs: 100%|██████████| 45/45 [37:09<00:00, 49.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Analysis complete! Saved to: human_perf_prs_with_gemini_analysis_new_catalog.csv\n",
      "================================================================================\n",
      "ANALYSIS SUMMARY\n",
      "================================================================================\n",
      "Total PRs analyzed: 45\n",
      "Successful: 45 (100.0%)\n",
      "Failed: 0\n",
      "Total tokens used: 1,068,159\n",
      "================================================================================\n",
      "OPTIMIZATION PATTERN DISTRIBUTION\n",
      "================================================================================\n",
      "  Memory and Data Locality Optimizations               14 ( 31.1%)\n",
      "  Algorithm-Level Optimizations                         7 ( 15.6%)\n",
      "  I/O and Synchronization                               6 ( 13.3%)\n",
      "  Code Smells and Structural Simplification             5 ( 11.1%)\n",
      "  Build & Compilation & Infrastructure Optimization     5 ( 11.1%)\n",
      "  Network, Database, and Data Access Optimization       4 (  8.9%)\n",
      "  Data Structure Selection and Adaptation               2 (  4.4%)\n",
      "  Control-Flow and Branching Optimizations              2 (  4.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# human pr analysis\n",
    "human_sample = perf_prs[perf_prs['author_type'] == 'Human'].copy().reset_index(drop=True)\n",
    "\n",
    "# Run the analysis\n",
    "perf_prs_analyzed = batch_analyze_performance_prs(\n",
    "    human_sample,\n",
    "    batch_size=2,    # Save checkpoint every 10 PRs\n",
    "    delay=0.5,        # 0.5 second delay between API calls\n",
    "    resume=True,      # Continue from the last saved checkpoint if available\n",
    "    checkpoint_prefix='human_perf_prs_checkpoint_gemini',\n",
    "    output_file='human_perf_prs_with_gemini_analysis_new_catalog.csv'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc1b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and check the human PRs analysis file\n",
    "human_analyzed = pd.read_csv('human_perf_prs_with_gemini_analysis.csv')\n",
    "\n",
    "print(f\"Total entries in human_perf_prs_with_gemini_analysis.csv: {len(human_analyzed):,}\")\n",
    "print(f\"Successful analyses: {(human_analyzed['gemini_success'] == True).sum():,}\")\n",
    "print(f\"Failed analyses: {(human_analyzed['gemini_success'] == False).sum():,}\")\n",
    "print(f\"Success rate: {(human_analyzed['gemini_success'] == True).sum() / len(human_analyzed) * 100:.1f}%\")\n",
    "\n",
    "# Remove failed analyses and rewrite to the original file\n",
    "failed_analyses = human_analyzed[human_analyzed['gemini_success'] == False]\n",
    "print(f\"Removing {len(failed_analyses)} failed analyses...\")\n",
    "\n",
    "human_analyzed = human_analyzed[human_analyzed['gemini_success'] == True].copy()\n",
    "human_analyzed.to_csv('human_perf_prs_with_gemini_analysis.csv', index=False)\n",
    "\n",
    "print(f\"Updated file saved with {len(human_analyzed)} successful analyses\")\n",
    "print(f\"Success rate: {len(human_analyzed) / (len(failed_analyses) + len(human_analyzed)) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291d666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze results by author type\n",
    "print(\"=\"*80)\n",
    "print(\"PATTERN COMPARISON: AI AGENTS VS HUMANS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for author_type in ['AI Agent', 'Human']:\n",
    "    subset = perf_prs_analyzed[\n",
    "        (perf_prs_analyzed['author_type'] == author_type) & \n",
    "        (perf_prs_analyzed['gemini_success'] == True)\n",
    "    ]\n",
    "    \n",
    "    if len(subset) > 0:\n",
    "        print(f\"{author_type} (n={len(subset):,}):\")\n",
    "        pattern_dist = subset['optimization_pattern'].value_counts().head(5)\n",
    "        for pattern, count in pattern_dist.items():\n",
    "            pct = count / len(subset) * 100\n",
    "            print(f\"  {pattern:50s} {count:4d} ({pct:5.1f}%)\")\n",
    "\n",
    "# Compare sub-patterns\n",
    "print(\"=\"*80)\n",
    "print(\"TOP SUB-PATTERNS BY AUTHOR TYPE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for author_type in ['AI Agent', 'Human']:\n",
    "    subset = perf_prs_analyzed[\n",
    "        (perf_prs_analyzed['author_type'] == author_type) & \n",
    "        (perf_prs_analyzed['gemini_success'] == True)\n",
    "    ]\n",
    "    \n",
    "    if len(subset) > 0:\n",
    "        print(f\"{author_type}:\")\n",
    "        subpattern_dist = subset['optimization_subpattern'].value_counts().head(5)\n",
    "        for subpattern, count in subpattern_dist.items():\n",
    "            pct = count / len(subset) * 100\n",
    "            print(f\"  {subpattern:50s} {count:4d} ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef32eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
