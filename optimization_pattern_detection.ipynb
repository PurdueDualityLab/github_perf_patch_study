{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0486a43",
   "metadata": {},
   "source": [
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd880dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment ready!\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install pandas numpy matplotlib seaborn scipy wordcloud pyarrow datasets --quiet\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import re\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Environment ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "588b1d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compatibility shim: some versions of fsspec don't expose url_to_fs at top-level.\n",
    "# This ensures code that expects fsspec.url_to_fs (used by some IO backends) continues to work.\n",
    "try:\n",
    "    import fsspec\n",
    "    if not hasattr(fsspec, \"url_to_fs\"):\n",
    "        try:\n",
    "            from fsspec.core import url_to_fs as _url_to_fs\n",
    "        except Exception:\n",
    "            try:\n",
    "                import fsspec.core as _core\n",
    "                _url_to_fs = _core.url_to_fs\n",
    "            except Exception:\n",
    "                # Fallback shim: create a minimal url_to_fs that returns a filesystem and the path.\n",
    "                def _url_to_fs(url, **kwargs):\n",
    "                    protocol = url.split(\"://\")[0] if \"://\" in url else \"file\"\n",
    "                    fs = fsspec.filesystem(protocol)\n",
    "                    return fs, url\n",
    "        fsspec.url_to_fs = _url_to_fs\n",
    "except Exception:\n",
    "    # If anything goes wrong, continue without failing here; subsequent IO calls will raise their own errors.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bd5c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading AIDev datasets...\n",
      "\n",
      "✓ Performance PR IDs to process: 428\n",
      "\n",
      "Processing commit details (filtering to performance PRs only)...\n",
      "  Total commit records in dataset: 711,923\n",
      "  Filtered to performance PRs: 7,410 commit records\n",
      "  Unique performance PRs with commits: 340\n",
      "  ✓ Aggregated to 340 unique performance PRs\n",
      "  Avg commits per PR: 21.8\n",
      "  AI Agent PRs with commit data: 340 / 340 (100.0%)\n",
      "  Human PRs with commit data: 0 / 88 (0.0%)\n",
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "✓ AI Agent Performance PRs: 340\n",
      "✓ Human Performance PRs: 88\n",
      "✓ Total Performance PRs: 428\n",
      "\n",
      "AI Agent Distribution:\n",
      "  OpenAI_Codex           207 ( 60.9%)\n",
      "  Devin                   62 ( 18.2%)\n",
      "  Copilot                 44 ( 12.9%)\n",
      "  Cursor                  24 (  7.1%)\n",
      "  Claude_Code              3 (  0.9%)\n",
      "\n",
      "================================================================================\n",
      "COMMIT STATISTICS\n",
      "================================================================================\n",
      "\n",
      "AI Agent:\n",
      "  PRs with commit data: 340 (100.0%)\n",
      "  Avg commits per PR: 21.8\n",
      "  Median commits per PR: 4.0\n",
      "  Avg additions: 646 lines\n",
      "  Median additions: 72 lines\n",
      "  Avg deletions: 646 lines\n",
      "  Median deletions: 26 lines\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "print(\"Loading AIDev datasets...\")\n",
    "\n",
    "# AI Agent PRs\n",
    "pr_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/pull_request.parquet\")\n",
    "pr_task_type_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/pr_task_type.parquet\")\n",
    "\n",
    "ai_perf_prs = (\n",
    "    pr_df\n",
    "    .merge(\n",
    "        pr_task_type_df[[\"id\", \"type\", \"reason\"]],\n",
    "        on=\"id\",\n",
    "        how=\"inner\"\n",
    "    )\n",
    "    .query(\"type == 'perf'\")\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "ai_perf_prs['classification_reason'] = ai_perf_prs['reason']\n",
    "ai_perf_prs['author_type'] = 'AI Agent'\n",
    "\n",
    "\n",
    "# Human PRs\n",
    "human_pr_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/human_pull_request.parquet\")\n",
    "human_pr_task_type_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/human_pr_task_type.parquet\")\n",
    "human_perf_prs = (\n",
    "    human_pr_df\n",
    "    .merge(\n",
    "        human_pr_task_type_df[[\"id\", \"type\", \"reason\"]],\n",
    "        on=\"id\",\n",
    "        how=\"inner\"\n",
    "    )\n",
    "    .query(\"type == 'perf'\")\n",
    "    .copy()\n",
    ")\n",
    "human_perf_prs['classification_reason'] = human_perf_prs['reason']\n",
    "human_perf_prs['author_type'] = 'Human'\n",
    "human_perf_prs['agent'] = 'Human'\n",
    "\n",
    "# Repository data for language info\n",
    "all_repo_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/all_repository.parquet\")\n",
    "\n",
    "# Get list of performance PR IDs we care about\n",
    "perf_pr_ids = set(ai_perf_prs['id'].tolist() + human_perf_prs['id'].tolist())\n",
    "print(f\"\\n✓ Performance PR IDs to process: {len(perf_pr_ids):,}\")\n",
    "\n",
    "# PR commits details - FILTER FIRST, then aggregate\n",
    "print(\"\\nProcessing commit details (filtering to performance PRs only)...\")\n",
    "pr_commits_details = pd.read_parquet(\"hf://datasets/hao-li/AIDev/pr_commit_details.parquet\")\n",
    "\n",
    "if 'pr_id' in pr_commits_details.columns:\n",
    "    print(f\"  Total commit records in dataset: {len(pr_commits_details):,}\")\n",
    "    \n",
    "    # FILTER: Keep only commits for performance PRs\n",
    "    pr_commits_filtered = pr_commits_details[pr_commits_details['pr_id'].isin(perf_pr_ids)].copy()\n",
    "    print(f\"  Filtered to performance PRs: {len(pr_commits_filtered):,} commit records\")\n",
    "    print(f\"  Unique performance PRs with commits: {pr_commits_filtered['pr_id'].nunique():,}\")\n",
    "    \n",
    "    if len(pr_commits_filtered) > 0:\n",
    "        # AGGREGATE: Now aggregate only the filtered commits\n",
    "        commit_aggregated = pr_commits_filtered.groupby('pr_id').agg({\n",
    "            'additions': 'sum',      # Total lines added across all commits\n",
    "            'deletions': 'sum',      # Total lines deleted across all commits\n",
    "            'patch': lambda x: '\\n\\n'.join([str(p) for p in x if pd.notna(p)])  # Concatenate all patches\n",
    "        }).reset_index()\n",
    "        \n",
    "        # Add derived metrics\n",
    "        commit_aggregated['num_commits'] = pr_commits_filtered.groupby('pr_id').size().values\n",
    "        \n",
    "        # Calculate patch length (for analysis)\n",
    "        commit_aggregated['patch_length'] = commit_aggregated['patch'].str.len()\n",
    "        \n",
    "        print(f\"  ✓ Aggregated to {len(commit_aggregated):,} unique performance PRs\")\n",
    "        print(f\"  Avg commits per PR: {commit_aggregated['num_commits'].mean():.1f}\")\n",
    "        \n",
    "        # Merge commit stats into AI Agent PR table\n",
    "        ai_perf_prs = ai_perf_prs.merge(\n",
    "            commit_aggregated,\n",
    "            left_on='id',\n",
    "            right_on='pr_id',\n",
    "            how='left'\n",
    "        )\n",
    "        if 'pr_id' in ai_perf_prs.columns:\n",
    "            ai_perf_prs = ai_perf_prs.drop(columns=['pr_id'])\n",
    "        \n",
    "        ai_with_commits = ai_perf_prs['additions'].notna().sum()\n",
    "        print(f\"  AI Agent PRs with commit data: {ai_with_commits:,} / {len(ai_perf_prs):,} ({ai_with_commits/len(ai_perf_prs)*100:.1f}%)\")\n",
    "        \n",
    "        # Merge commit stats into Human PR table\n",
    "        human_perf_prs = human_perf_prs.merge(\n",
    "            commit_aggregated,\n",
    "            left_on='id',\n",
    "            right_on='pr_id',\n",
    "            how='left'\n",
    "        )\n",
    "        if 'pr_id' in human_perf_prs.columns:\n",
    "            human_perf_prs = human_perf_prs.drop(columns=['pr_id'])\n",
    "        \n",
    "        human_with_commits = human_perf_prs['additions'].notna().sum()\n",
    "        print(f\"  Human PRs with commit data: {human_with_commits:,} / {len(human_perf_prs):,} ({human_with_commits/len(human_perf_prs)*100:.1f}%)\")\n",
    "    else:\n",
    "        print(\"  ⚠ No commits found for performance PRs\")\n",
    "        # Add placeholder columns\n",
    "        for df in [ai_perf_prs, human_perf_prs]:\n",
    "            df['additions'] = None\n",
    "            df['deletions'] = None\n",
    "            df['num_commits'] = None\n",
    "            df['patch'] = None\n",
    "            df['patch_length'] = None\n",
    "    \n",
    "else:\n",
    "    print('⚠ pr_commit_details missing pr_id column; skipping commit merges.')\n",
    "    # Add placeholder columns\n",
    "    for df in [ai_perf_prs, human_perf_prs]:\n",
    "        df['additions'] = None\n",
    "        df['deletions'] = None\n",
    "        df['num_commits'] = None\n",
    "        df['patch'] = None\n",
    "        df['patch_length'] = None\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"SUMMARY\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"✓ AI Agent Performance PRs: {len(ai_perf_prs):,}\")\n",
    "print(f\"✓ Human Performance PRs: {len(human_perf_prs):,}\")\n",
    "print(f\"✓ Total Performance PRs: {len(ai_perf_prs) + len(human_perf_prs):,}\")\n",
    "\n",
    "# Distribution by AI agent\n",
    "print(f\"\\nAI Agent Distribution:\")\n",
    "for agent, count in ai_perf_prs['agent'].value_counts().items():\n",
    "    pct = count / len(ai_perf_prs) * 100\n",
    "    print(f\"  {agent:20s} {count:5,d} ({pct:5.1f}%)\")\n",
    "\n",
    "# Commit statistics summary\n",
    "if 'num_commits' in ai_perf_prs.columns and ai_perf_prs['num_commits'].notna().any():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"COMMIT STATISTICS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    for author_type, df in [('AI Agent', ai_perf_prs), ('Human', human_perf_prs)]:\n",
    "        with_commits = df['num_commits'].notna()\n",
    "        if with_commits.sum() > 0:\n",
    "            print(f\"\\n{author_type}:\")\n",
    "            print(f\"  PRs with commit data: {with_commits.sum():,} ({with_commits.mean()*100:.1f}%)\")\n",
    "            print(f\"  Avg commits per PR: {df.loc[with_commits, 'num_commits'].mean():.1f}\")\n",
    "            print(f\"  Median commits per PR: {df.loc[with_commits, 'num_commits'].median():.1f}\")\n",
    "            print(f\"  Avg additions: {df.loc[with_commits, 'additions'].mean():.0f} lines\")\n",
    "            print(f\"  Median additions: {df.loc[with_commits, 'additions'].median():.0f} lines\")\n",
    "            print(f\"  Avg deletions: {df.loc[with_commits, 'deletions'].mean():.0f} lines\")\n",
    "            print(f\"  Median deletions: {df.loc[with_commits, 'deletions'].median():.0f} lines\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa5d5acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset: 428 performance PRs\n",
      "  AI Agents: 340\n",
      "  Humans: 88\n"
     ]
    }
   ],
   "source": [
    "# Combine AI and Human PRs\n",
    "perf_prs = pd.concat([ai_perf_prs, human_perf_prs], ignore_index=True)\n",
    "\n",
    "print(f\"Combined dataset: {len(perf_prs):,} performance PRs\")\n",
    "print(f\"  AI Agents: {(perf_prs['author_type'] == 'AI Agent').sum():,}\")\n",
    "print(f\"  Humans: {(perf_prs['author_type'] == 'Human').sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a247c4a",
   "metadata": {},
   "source": [
    "# Optimization Pattern Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b725c6f4",
   "metadata": {},
   "source": [
    "## LLM inference script\n",
    "Script to map optimization to the performance optimization pattern catalog using LLM, based on PR title, body, and patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ed2759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Performance Optimization Pattern Detection with GPT\n",
    "# ============================================================================\n",
    "!pip install openai --quiet\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from pydantic import BaseModel \n",
    "from pathlib import Path\n",
    "\n",
    "def analyze_optimization_with_gpt(title, body, patch):\n",
    "    \"\"\"\n",
    "    Call GPT to analyze performance optimization patterns in a commit.\n",
    "    \n",
    "    Parameters:\n",
    "    - title: PR/commit title\n",
    "    - body: PR/commit description\n",
    "    - patch: Git diff/patch content\n",
    "    \n",
    "    Returns:\n",
    "    - dict with analysis results or error info\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare the context\n",
    "    context_parts = []\n",
    "    \n",
    "    if pd.notna(title) and str(title).strip():\n",
    "        context_parts.append(f\"**Title**: {title}\")\n",
    "    \n",
    "    if pd.notna(body) and str(body).strip():\n",
    "        context_parts.append(f\"**Description**: {body}\")\n",
    "    \n",
    "    if pd.notna(patch) and str(patch).strip():\n",
    "        # Truncate very long patches to avoid token limits\n",
    "        patch_str = str(patch)\n",
    "        if len(patch_str) > 15000:  # Rough character limit\n",
    "            patch_str = patch_str[:15000] + \"\\n\\n... [patch truncated for length] ...\"\n",
    "        context_parts.append(f\"**Code Changes (Patch)**:\\n```diff\\n{patch_str}\\n```\")\n",
    "    \n",
    "    if not context_parts:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": \"No content available\",\n",
    "            \"explanation\": None,\n",
    "            \"optimization_comparison\": None,\n",
    "            \"high_level_pattern\": None,\n",
    "            \"sub_pattern\": None,\n",
    "            \"confidence\": None,\n",
    "            \"tokens_used\": 0\n",
    "        }\n",
    "    \n",
    "    context = \"\\n\\n\".join(context_parts)\n",
    "    \n",
    "    client=OpenAI(api_key=\"YOUR_OPENAI_API_KEY_HERE\")\n",
    "    \n",
    "    # Construct the prompt\n",
    "    prompt = f\"\"\"I have a performance optimization commit with the following information. Please analyze with the following goals:\n",
    "\n",
    "1. **Code Function Explanation**: Briefly explain what the code is doing—what problem it solves and how it works.\n",
    "\n",
    "2. **Optimization Comparison**: Compare the original and optimized versions to identify:\n",
    "   - **Algorithmic changes**: Any differences in logic, algorithm design, or problem-solving approach.\n",
    "   - **Performance improvements**: Enhancements related to time complexity, space efficiency, or runtime behavior.\n",
    "   - **Redundant code removal**: Elimination of unnecessary logic, method calls, or control structures.\n",
    "   - **Other noteworthy changes**: Any structural or stylistic differences that could impact performance or readability.\n",
    "   \n",
    "3. **Optimization Pattern Classification**:\n",
    "   Based on the overall nature of the optimized code, assign the following. Return \"No Meaningful Change\" if no meaningful change is made.\n",
    "   - **Exactly one high-level optimization pattern** from the list below  \n",
    "   - **One most representative sub-pattern** within that high-level category\n",
    "   \n",
    "   ### High-Level Optimization Patterns Taxonomy:\n",
    "   - **Algorithm-Level Optimizations**\n",
    "        - Select Computationally Efficient Algorithms\n",
    "        - Select Algorithm Based on Instruction Speed\n",
    "        - Structure Algorithm to Support ILP\n",
    "        - Select Space Efficient Algorithm\n",
    "        - Inheritance over Delegation for Energy Efficiency\n",
    "   - **Control-Flow and Branching Optimizations**\n",
    "        - Make Conditional Branches More Predictable\n",
    "        - Remove Branches with min/max Instructions\n",
    "        - Remove Branches by Doing Extra Work\n",
    "        - Remove Branching with Masking\n",
    "        - Rearranging Branches\n",
    "        - Combining Branches\n",
    "   - **Memory and Data Locality Optimizations**\n",
    "        - Access Data with Appropriate Type\n",
    "        - Increase Cache Efficiency via Locality\n",
    "        - Arrange Data for Optimal Prefetching\n",
    "        - Avoid Cache Capacity Issues\n",
    "        - Increase Workload to Hide Latency\n",
    "        - Use Smaller Data Types\n",
    "        - Caching, Buffering\n",
    "        - Improve Data Structure Locality\n",
    "        - Optimize Object Use\n",
    "        - Reduce RTSJ Immortal Memory Bloat\n",
    "   - **Loop Transformations**\n",
    "        - Remove Conditional by Loop Unrolling\n",
    "        - Loop Distribution (Fission)\n",
    "        - Loop Fusion, Peeling, Interchanging\n",
    "        - Loop Invariant Branches\n",
    "        - Loop Strip-mining\n",
    "   - **I/O and Synchronization**\n",
    "        - Selection of I/O Size\n",
    "        - Polling\n",
    "        - Non-Blocking I/O\n",
    "   - **Data Structure Selection and Adaptation**\n",
    "        - Choose Structure for Energy Efficiency\n",
    "        - Darwinian Selection\n",
    "        - Select via Method Calls\n",
    "        - Cross-Library Comparison\n",
    "   - **Code Smells and Structural Simplification**\n",
    "        - Remove Optional Features\n",
    "        - Remove Redundant Method Calls\n",
    "        - Extract Long Methods\n",
    "        - Remove Duplicates\n",
    "        - Move Methods to Reduce Feature Envy\n",
    "        - Minimize God Classes\n",
    "        - Type Checking\n",
    "         \n",
    "Here are the info:\n",
    "            \n",
    "{context}\n",
    "\n",
    "**Output Structure**:  \n",
    "Please respond in JSON format with the following structure:\n",
    "{{\n",
    "  \"explanation\": \"Brief description of what the code is doing\",\n",
    "  \"optimization_comparison\": \"Detailed comparison highlighting specific optimizations\",\n",
    "  \"high_level_pattern\": \"Single most representative high-level optimization pattern (or 'No Meaningful Change')\",\n",
    "  \"sub_pattern\": \"Most representative sub-pattern within the category (or null if No Meaningful Change)\",\n",
    "  \"confidence\": \"high/medium/low - your confidence in this classification\"\n",
    "}}\n",
    "\n",
    "Ensure your response is valid JSON that can be parsed.\n",
    "\"\"\"\n",
    "\n",
    "    class AnalysisResult(BaseModel):  \n",
    "        explanation: str\n",
    "        optimization_comparison: str\n",
    "        high_level_pattern: str\n",
    "        sub_pattern: str\n",
    "        confidence: str\n",
    "    \n",
    "    try:        \n",
    "        response = client.beta.chat.completions.parse(\n",
    "                    model = \"gpt-5-mini\",\n",
    "                    messages = [\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": \"You are an expert software engineer specializing in performance optimization analysis. Analyze code changes and classify optimization patterns accurately.\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": prompt\n",
    "                        }\n",
    "                    ],\n",
    "                    response_format=AnalysisResult,\n",
    "                )\n",
    "\n",
    "        # Parse the response\n",
    "        content = response.choices[0].message.content\n",
    "        result = json.loads(content)\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"explanation\": result.get(\"explanation\", \"\"),\n",
    "            \"optimization_comparison\": result.get(\"optimization_comparison\", \"\"),\n",
    "            \"high_level_pattern\": result.get(\"high_level_pattern\", \"\"),\n",
    "            \"sub_pattern\": result.get(\"sub_pattern\", \"\"),\n",
    "            \"confidence\": result.get(\"confidence\", \"unknown\"),\n",
    "            \"tokens_used\": response.usage.total_tokens,\n",
    "            \"error\": None\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": str(e),\n",
    "            \"explanation\": None,\n",
    "            \"optimization_comparison\": None,\n",
    "            \"high_level_pattern\": None,\n",
    "            \"sub_pattern\": None,\n",
    "            \"confidence\": None,\n",
    "            \"tokens_used\": 0\n",
    "        }\n",
    "\n",
    "\n",
    "def batch_analyze_performance_prs(perf_prs, batch_size=10, delay=1.0,resume=False, checkpoint_prefix='perf_prs_checkpoint', output_file='perf_prs_with_gpt_analysis.csv'):\n",
    "    \"\"\"\n",
    "    Analyze all performance PRs in batches.\n",
    "\n",
    "    Parameters:\n",
    "    - perf_prs: DataFrame with performance PRs\n",
    "    - batch_size: Number of PRs to process before saving checkpoint\n",
    "    - delay: Delay between API calls in seconds\n",
    "    - resume: Continue from the last available checkpoint if True\n",
    "    - checkpoint_prefix: Filename prefix used for checkpoint files\n",
    "    - output_file: Final CSV filename for the aggregated results\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with analysis results added\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Starting GPT analysis of {len(perf_prs):,} performance PRs...\")\n",
    "\n",
    "    checkpoint_files = []\n",
    "    processed_count = 0\n",
    "\n",
    "    if resume:\n",
    "        checkpoint_files = sorted(Path('.').glob(f\"{checkpoint_prefix}_*.csv\"))\n",
    "        if checkpoint_files:\n",
    "            def _processed_from_path(path_obj):\n",
    "                suffix = path_obj.stem.rsplit('_', 1)[-1]\n",
    "                return int(suffix) if suffix.isdigit() else 0\n",
    "\n",
    "            latest_checkpoint = max(checkpoint_files, key=_processed_from_path)\n",
    "            checkpoint_progress = _processed_from_path(latest_checkpoint)\n",
    "            perf_prs = pd.read_csv(latest_checkpoint)\n",
    "            processed_count = min(checkpoint_progress, len(perf_prs))\n",
    "            print(f\"↻ Resuming from checkpoint {latest_checkpoint} ({processed_count} PRs processed)...\")\n",
    "        else:\n",
    "            print(\"↻ Resume requested but no checkpoint found. Starting from scratch.\")\n",
    "\n",
    "    result_defaults = {\n",
    "        'gpt_explanation': None,\n",
    "        'gpt_comparison': None,\n",
    "        'optimization_pattern': None,\n",
    "        'optimization_subpattern': None,\n",
    "        'pattern_confidence': None,\n",
    "        'gpt_success': False,\n",
    "        'gpt_error': None,\n",
    "        'gpt_tokens': 0\n",
    "    }\n",
    "\n",
    "    for column, default in result_defaults.items():\n",
    "        if resume and column in perf_prs.columns:\n",
    "            continue\n",
    "        perf_prs[column] = default\n",
    "\n",
    "    start_idx = processed_count if resume else 0\n",
    "    iterator = range(start_idx, len(perf_prs))\n",
    "    progress_bar = tqdm(iterator, total=len(perf_prs), desc=\"Analyzing PRs\", initial=start_idx)\n",
    "\n",
    "    for idx in progress_bar:\n",
    "        row = perf_prs.iloc[idx]\n",
    "        result = analyze_optimization_with_gpt(\n",
    "            title=row.get('title'),\n",
    "            body=row.get('body'),\n",
    "            patch=row.get('patch')\n",
    "        )\n",
    "\n",
    "        perf_prs.at[idx, 'gpt_success'] = result['success']\n",
    "        perf_prs.at[idx, 'gpt_tokens'] = result['tokens_used']\n",
    "\n",
    "        if result['success']:\n",
    "            perf_prs.at[idx, 'gpt_explanation'] = result['explanation']\n",
    "            perf_prs.at[idx, 'gpt_comparison'] = result['optimization_comparison']\n",
    "            perf_prs.at[idx, 'optimization_pattern'] = result['high_level_pattern']\n",
    "            perf_prs.at[idx, 'optimization_subpattern'] = result['sub_pattern']\n",
    "            perf_prs.at[idx, 'pattern_confidence'] = result['confidence']\n",
    "            perf_prs.at[idx, 'gpt_error'] = None\n",
    "        else:\n",
    "            perf_prs.at[idx, 'gpt_error'] = result['error']\n",
    "\n",
    "        time.sleep(delay)\n",
    "\n",
    "        if (idx + 1) % batch_size == 0:\n",
    "            checkpoint_file = f\"{checkpoint_prefix}_{idx+1}.csv\"\n",
    "            perf_prs.to_csv(checkpoint_file, index=False)\n",
    "            print(f\"✓ Checkpoint saved: {checkpoint_file}\")\n",
    "\n",
    "    perf_prs.to_csv(output_file, index=False)\n",
    "    print(f\"✓ Analysis complete! Saved to: {output_file}\")\n",
    "\n",
    "    success_series = perf_prs['gpt_success'].fillna(False)\n",
    "    success_count = success_series.sum()\n",
    "    success_rate = (success_count / len(perf_prs) * 100) if len(perf_prs) else 0\n",
    "    failure_count = success_series.eq(False).sum()\n",
    "    total_tokens = perf_prs['gpt_tokens'].sum()\n",
    "\n",
    "    print(f\"{'='*80}\")\n",
    "    print(\"ANALYSIS SUMMARY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Total PRs analyzed: {len(perf_prs):,}\")\n",
    "    print(f\"Successful: {success_count:,} ({success_rate:.1f}%)\")\n",
    "    print(f\"Failed: {failure_count:,}\")\n",
    "    print(f\"Total tokens used: {total_tokens:,}\")\n",
    "\n",
    "    if success_count > 0:\n",
    "        print(f\"{'='*80}\")\n",
    "        print(\"OPTIMIZATION PATTERN DISTRIBUTION\")\n",
    "        print(f\"{'='*80}\")\n",
    "        pattern_counts = perf_prs[perf_prs['gpt_success'] == True]['optimization_pattern'].value_counts()\n",
    "        for pattern, count in pattern_counts.items():\n",
    "            pct = count / success_count * 100\n",
    "            print(f\"  {pattern:50s} {count:4d} ({pct:5.1f}%)\")\n",
    "\n",
    "    return perf_prs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532b365f",
   "metadata": {},
   "source": [
    "## Usage scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "107368e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/l0_qr8g54f3b60v0fzt7bf200000gs/T/ipykernel_98135/296692622.py:241: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  perf_prs[column] = default\n",
      "/var/folders/lj/l0_qr8g54f3b60v0fzt7bf200000gs/T/ipykernel_98135/296692622.py:241: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  perf_prs[column] = default\n",
      "/var/folders/lj/l0_qr8g54f3b60v0fzt7bf200000gs/T/ipykernel_98135/296692622.py:241: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  perf_prs[column] = default\n",
      "/var/folders/lj/l0_qr8g54f3b60v0fzt7bf200000gs/T/ipykernel_98135/296692622.py:241: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  perf_prs[column] = default\n",
      "/var/folders/lj/l0_qr8g54f3b60v0fzt7bf200000gs/T/ipykernel_98135/296692622.py:241: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  perf_prs[column] = default\n",
      "/var/folders/lj/l0_qr8g54f3b60v0fzt7bf200000gs/T/ipykernel_98135/296692622.py:241: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  perf_prs[column] = default\n",
      "/var/folders/lj/l0_qr8g54f3b60v0fzt7bf200000gs/T/ipykernel_98135/296692622.py:241: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  perf_prs[column] = default\n",
      "/var/folders/lj/l0_qr8g54f3b60v0fzt7bf200000gs/T/ipykernel_98135/296692622.py:241: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  perf_prs[column] = default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing GPT analysis on 340 AI PRs\n",
      "Starting GPT analysis of 340 performance PRs...\n",
      "↻ Resume requested but no checkpoint found. Starting from scratch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:   3%|▎         | 10/340 [03:32<2:09:34, 23.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint saved: ai_perf_prs_checkpoint_10.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing PRs:   3%|▎         | 10/340 [03:42<2:02:25, 22.26s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting GPT analysis on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ai_sample)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m AI PRs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Run the analysis\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m perf_prs_analyzed \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_analyze_performance_prs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mai_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Save checkpoint every 10 PRs\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 0.5 second delay between API calls\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# Continue from the last saved checkpoint if available\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mai_perf_prs_checkpoint\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mai_perf_prs_with_gpt_analysis.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 249\u001b[0m, in \u001b[0;36mbatch_analyze_performance_prs\u001b[0;34m(perf_prs, batch_size, delay, resume, checkpoint_prefix, output_file)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m progress_bar:\n\u001b[1;32m    248\u001b[0m     row \u001b[38;5;241m=\u001b[39m perf_prs\u001b[38;5;241m.\u001b[39miloc[idx]\n\u001b[0;32m--> 249\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_optimization_with_gpt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtitle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbody\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpatch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m     perf_prs\u001b[38;5;241m.\u001b[39mat[idx, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt_success\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuccess\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    256\u001b[0m     perf_prs\u001b[38;5;241m.\u001b[39mat[idx, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt_tokens\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens_used\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[4], line 148\u001b[0m, in \u001b[0;36manalyze_optimization_with_gpt\u001b[0;34m(title, body, patch)\u001b[0m\n\u001b[1;32m    145\u001b[0m     confidence: \u001b[38;5;28mstr\u001b[39m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:        \n\u001b[0;32m--> 148\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-5-mini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are an expert software engineer specializing in performance optimization analysis. Analyze code changes and classify optimization patterns accurately.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    154\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m                \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m                \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAnalysisResult\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Parse the response\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     content \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py:183\u001b[0m, in \u001b[0;36mCompletions.parse\u001b[0;34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, safety_identifier, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparser\u001b[39m(raw_completion: ChatCompletion) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ParsedChatCompletion[ResponseFormatT]:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[1;32m    178\u001b[0m         response_format\u001b[38;5;241m=\u001b[39mresponse_format,\n\u001b[1;32m    179\u001b[0m         chat_completion\u001b[38;5;241m=\u001b[39mraw_completion,\n\u001b[1;32m    180\u001b[0m         input_tools\u001b[38;5;241m=\u001b[39mchat_completion_tools,\n\u001b[1;32m    181\u001b[0m     )\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_cache_key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_type_to_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msafety_identifier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mverbosity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;49;00m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedChatCompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/openai/_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1258\u001b[0m     )\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/openai/_base_client.py:982\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    980\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 982\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    988\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/ssl.py:1258\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1255\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1256\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1257\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/ssl.py:1131\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1131\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Usage\n",
    "# ============================================================================\n",
    "\n",
    "# run ai and human pr analysis separately\n",
    "\n",
    "# ai pr analysis\n",
    "ai_sample = perf_prs[perf_prs['author_type'] == 'AI Agent']\n",
    "print(f\"Testing GPT analysis on {len(ai_sample)} AI PRs\")\n",
    "\n",
    "# Run the analysis\n",
    "perf_prs_analyzed = batch_analyze_performance_prs(\n",
    "    ai_sample,\n",
    "    batch_size=10,    # Save checkpoint every 10 PRs\n",
    "    delay=0.5,        # 0.5 second delay between API calls\n",
    "    resume=True,      # Continue from the last saved checkpoint if available\n",
    "    checkpoint_prefix='ai_perf_prs_checkpoint',\n",
    "    output_file='ai_perf_prs_with_gpt_analysis.csv'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ba3fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# human pr analysis\n",
    "human_sample = perf_prs[perf_prs['author_type'] == 'Human']\n",
    "print(f\"Testing GPT analysis on {len(human_sample)} Human PRs\")\n",
    "\n",
    "# Run the analysis\n",
    "perf_prs_analyzed = batch_analyze_performance_prs(\n",
    "    human_sample,\n",
    "    batch_size=10,    # Save checkpoint every 10 PRs\n",
    "    delay=0.5,        # 0.5 second delay between API calls\n",
    "    resume=True,      # Continue from the last saved checkpoint if available\n",
    "    checkpoint_prefix='human_perf_prs_checkpoint',\n",
    "    output_file='human_perf_prs_with_gpt_analysis.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291d666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze results by author type\n",
    "print(\"=\"*80)\n",
    "print(\"PATTERN COMPARISON: AI AGENTS VS HUMANS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for author_type in ['AI Agent', 'Human']:\n",
    "    subset = perf_prs_analyzed[\n",
    "        (perf_prs_analyzed['author_type'] == author_type) & \n",
    "        (perf_prs_analyzed['gpt_success'] == True)\n",
    "    ]\n",
    "    \n",
    "    if len(subset) > 0:\n",
    "        print(f\"{author_type} (n={len(subset):,}):\")\n",
    "        pattern_dist = subset['optimization_pattern'].value_counts().head(5)\n",
    "        for pattern, count in pattern_dist.items():\n",
    "            pct = count / len(subset) * 100\n",
    "            print(f\"  {pattern:50s} {count:4d} ({pct:5.1f}%)\")\n",
    "\n",
    "# Compare sub-patterns\n",
    "print(\"=\"*80)\n",
    "print(\"TOP SUB-PATTERNS BY AUTHOR TYPE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for author_type in ['AI Agent', 'Human']:\n",
    "    subset = perf_prs_analyzed[\n",
    "        (perf_prs_analyzed['author_type'] == author_type) & \n",
    "        (perf_prs_analyzed['gpt_success'] == True)\n",
    "    ]\n",
    "    \n",
    "    if len(subset) > 0:\n",
    "        print(f\"{author_type}:\")\n",
    "        subpattern_dist = subset['optimization_subpattern'].value_counts().head(5)\n",
    "        for subpattern, count in subpattern_dist.items():\n",
    "            pct = count / len(subset) * 100\n",
    "            print(f\"  {subpattern:50s} {count:4d} ({pct:5.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
