{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "975a3c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment ready!\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install pandas numpy matplotlib seaborn scipy wordcloud pyarrow datasets PyGithub python-dotenv --quiet\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import re\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from urllib.parse import urlparse\n",
    "import time\n",
    "from github import Github\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Environment ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f4e3e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compatibility shim: some versions of fsspec don't expose url_to_fs at top-level.\n",
    "# This ensures code that expects fsspec.url_to_fs (used by some IO backends) continues to work.\n",
    "try:\n",
    "    import fsspec\n",
    "    if not hasattr(fsspec, \"url_to_fs\"):\n",
    "        try:\n",
    "            from fsspec.core import url_to_fs as _url_to_fs\n",
    "        except Exception:\n",
    "            try:\n",
    "                import fsspec.core as _core\n",
    "                _url_to_fs = _core.url_to_fs\n",
    "            except Exception:\n",
    "                # Fallback shim: create a minimal url_to_fs that returns a filesystem and the path.\n",
    "                def _url_to_fs(url, **kwargs):\n",
    "                    protocol = url.split(\"://\")[0] if \"://\" in url else \"file\"\n",
    "                    fs = fsspec.filesystem(protocol)\n",
    "                    return fs, url\n",
    "        fsspec.url_to_fs = _url_to_fs\n",
    "except Exception:\n",
    "    # If anything goes wrong, continue without failing here; subsequent IO calls will raise their own errors.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f91e93a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/dq9r8b6n1bx49mhvn82gzl180000gn/T/ipykernel_20001/4070930473.py:6: DeprecationWarning: Argument login_or_token is deprecated, please use auth=github.Auth.Token(...) instead\n",
      "  gh = Github(GITHUB_API_TOKEN)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() \n",
    "GITHUB_API_TOKEN = os.environ.get(\"GITHUB_TOKEN\")\n",
    "gh = Github(GITHUB_API_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ce11e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_owner_repo(repo_url: str, html_url: str):\n",
    "    for url in (repo_url, html_url):\n",
    "        if not isinstance(url, str):\n",
    "            continue\n",
    "        try:\n",
    "            path = urlparse(url).path.strip(\"/\")\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        parts = path.split(\"/\")\n",
    "\n",
    "        # API: /repos/OWNER/REPO\n",
    "        if \"repos\" in parts:\n",
    "            idx = parts.index(\"repos\")\n",
    "            if len(parts) >= idx + 3:\n",
    "                owner = parts[idx + 1]\n",
    "                repo = parts[idx + 2]\n",
    "                return owner, repo\n",
    "\n",
    "        # Web: /OWNER/REPO/pull/123\n",
    "        if len(parts) >= 2:\n",
    "            owner = parts[0]\n",
    "            repo = parts[1]\n",
    "            return owner, repo\n",
    "\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab3bb2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading AIDev datasets...\n",
      "len = 340\n",
      "Missing repos: 0\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "print(\"Loading AIDev datasets...\")\n",
    "\n",
    "\n",
    "# ai PRs\n",
    "ai_pr_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/pull_request.parquet\")\n",
    "ai_pr_task_type_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/pr_task_type.parquet\")\n",
    "\n",
    "perf_ai = (\n",
    "ai_pr_df\n",
    "    .merge(\n",
    "        ai_pr_task_type_df[[\"id\", \"type\"]], on=\"id\", \n",
    "    )\n",
    "    .query(\"type == 'perf'\")\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "perf_ai[[\"repo_owner\", \"repo_name\"]] = perf_ai.apply(\n",
    "    lambda row: pd.Series(extract_owner_repo(row['repo_url'], row['html_url'])), axis=1\n",
    ")\n",
    "\n",
    "print(f\"len = {len(perf_ai)}\")\n",
    "missing_repos = perf_ai[perf_ai['repo_owner'].isna() | perf_ai['repo_name'].isna()]\n",
    "print(f\"Missing repos: {len(missing_repos)}\")\n",
    "\n",
    "#Reconstruct pr_commit_df from human_pr_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "527183b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>number</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>agent</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user</th>\n",
       "      <th>state</th>\n",
       "      <th>created_at</th>\n",
       "      <th>closed_at</th>\n",
       "      <th>merged_at</th>\n",
       "      <th>repo_id</th>\n",
       "      <th>repo_url</th>\n",
       "      <th>html_url</th>\n",
       "      <th>type</th>\n",
       "      <th>repo_owner</th>\n",
       "      <th>repo_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>3200679276</td>\n",
       "      <td>4304</td>\n",
       "      <td>Implement lazy loading for RegistryInstance to improve latency in operations where the registry ...</td>\n",
       "      <td>ðŸ‘¨ \\r\\n\\r\\nBefore:\\r\\n\\r\\n```\\r\\njulia&gt; @time Pkg.instantiate()\\r\\n  0.390297 seconds (1.95 M all...</td>\n",
       "      <td>Claude_Code</td>\n",
       "      <td>1282691</td>\n",
       "      <td>KristofferC</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-07-03T21:18:03Z</td>\n",
       "      <td>2025-07-04T08:34:04Z</td>\n",
       "      <td>2025-07-04T08:34:04Z</td>\n",
       "      <td>82341193</td>\n",
       "      <td>https://api.github.com/repos/JuliaLang/Pkg.jl</td>\n",
       "      <td>https://github.com/JuliaLang/Pkg.jl/pull/4304</td>\n",
       "      <td>perf</td>\n",
       "      <td>JuliaLang</td>\n",
       "      <td>Pkg.jl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>3250477735</td>\n",
       "      <td>397</td>\n",
       "      <td>Optimize nancorrmatrix and nancovmatrix for cache locality</td>\n",
       "      <td>Refactor `nancorrmatrix` and `nancovmatrix` to process observations sequentially. This improves ...</td>\n",
       "      <td>Claude_Code</td>\n",
       "      <td>5635139</td>\n",
       "      <td>max-sixty</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-07-22T00:19:55Z</td>\n",
       "      <td>2025-07-22T00:28:17Z</td>\n",
       "      <td>2025-07-22T00:28:17Z</td>\n",
       "      <td>25501620</td>\n",
       "      <td>https://api.github.com/repos/numbagg/numbagg</td>\n",
       "      <td>https://github.com/numbagg/numbagg/pull/397</td>\n",
       "      <td>perf</td>\n",
       "      <td>numbagg</td>\n",
       "      <td>numbagg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>3254647682</td>\n",
       "      <td>59071</td>\n",
       "      <td>skip unnecessary alias-check in collect(::AbstractArray) from copyto\\!</td>\n",
       "      <td>As discussed on Slack with @MasonProtter &amp; @jakobnissen, `collect` currently does a usually chea...</td>\n",
       "      <td>Claude_Code</td>\n",
       "      <td>1814174</td>\n",
       "      <td>ChrisRackauckas</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-07-23T02:52:46Z</td>\n",
       "      <td>2025-07-23T23:55:54Z</td>\n",
       "      <td>None</td>\n",
       "      <td>1644196</td>\n",
       "      <td>https://api.github.com/repos/JuliaLang/julia</td>\n",
       "      <td>https://github.com/JuliaLang/julia/pull/59071</td>\n",
       "      <td>perf</td>\n",
       "      <td>JuliaLang</td>\n",
       "      <td>julia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>3151002300</td>\n",
       "      <td>6671</td>\n",
       "      <td>Use async file system APIs instead of sync APIs in install.ts</td>\n",
       "      <td>Replaces synchronous file system API calls with asynchronous equivalents in `vscode/npm-package/...</td>\n",
       "      <td>Copilot</td>\n",
       "      <td>198982749</td>\n",
       "      <td>Copilot</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-06-16T19:04:49Z</td>\n",
       "      <td>2025-06-17T20:07:53Z</td>\n",
       "      <td>2025-06-17T20:07:52Z</td>\n",
       "      <td>323665366</td>\n",
       "      <td>https://api.github.com/repos/microsoft/kiota</td>\n",
       "      <td>https://github.com/microsoft/kiota/pull/6671</td>\n",
       "      <td>perf</td>\n",
       "      <td>microsoft</td>\n",
       "      <td>kiota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>3151370964</td>\n",
       "      <td>12025</td>\n",
       "      <td>Add fast-paths for ToolLocationHelper property functions</td>\n",
       "      <td>This PR adds fast-path implementations for two commonly used ToolLocationHelper property functio...</td>\n",
       "      <td>Copilot</td>\n",
       "      <td>198982749</td>\n",
       "      <td>Copilot</td>\n",
       "      <td>open</td>\n",
       "      <td>2025-06-16T21:24:28Z</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>32051890</td>\n",
       "      <td>https://api.github.com/repos/dotnet/msbuild</td>\n",
       "      <td>https://github.com/dotnet/msbuild/pull/12025</td>\n",
       "      <td>perf</td>\n",
       "      <td>dotnet</td>\n",
       "      <td>msbuild</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  number  \\\n",
       "102  3200679276    4304   \n",
       "114  3250477735     397   \n",
       "249  3254647682   59071   \n",
       "526  3151002300    6671   \n",
       "534  3151370964   12025   \n",
       "\n",
       "                                                                                                   title  \\\n",
       "102  Implement lazy loading for RegistryInstance to improve latency in operations where the registry ...   \n",
       "114                                           Optimize nancorrmatrix and nancovmatrix for cache locality   \n",
       "249                               skip unnecessary alias-check in collect(::AbstractArray) from copyto\\!   \n",
       "526                                        Use async file system APIs instead of sync APIs in install.ts   \n",
       "534                                             Add fast-paths for ToolLocationHelper property functions   \n",
       "\n",
       "                                                                                                    body  \\\n",
       "102  ðŸ‘¨ \\r\\n\\r\\nBefore:\\r\\n\\r\\n```\\r\\njulia> @time Pkg.instantiate()\\r\\n  0.390297 seconds (1.95 M all...   \n",
       "114  Refactor `nancorrmatrix` and `nancovmatrix` to process observations sequentially. This improves ...   \n",
       "249  As discussed on Slack with @MasonProtter & @jakobnissen, `collect` currently does a usually chea...   \n",
       "526  Replaces synchronous file system API calls with asynchronous equivalents in `vscode/npm-package/...   \n",
       "534  This PR adds fast-path implementations for two commonly used ToolLocationHelper property functio...   \n",
       "\n",
       "           agent    user_id             user   state            created_at  \\\n",
       "102  Claude_Code    1282691      KristofferC  closed  2025-07-03T21:18:03Z   \n",
       "114  Claude_Code    5635139        max-sixty  closed  2025-07-22T00:19:55Z   \n",
       "249  Claude_Code    1814174  ChrisRackauckas  closed  2025-07-23T02:52:46Z   \n",
       "526      Copilot  198982749          Copilot  closed  2025-06-16T19:04:49Z   \n",
       "534      Copilot  198982749          Copilot    open  2025-06-16T21:24:28Z   \n",
       "\n",
       "                closed_at             merged_at    repo_id  \\\n",
       "102  2025-07-04T08:34:04Z  2025-07-04T08:34:04Z   82341193   \n",
       "114  2025-07-22T00:28:17Z  2025-07-22T00:28:17Z   25501620   \n",
       "249  2025-07-23T23:55:54Z                  None    1644196   \n",
       "526  2025-06-17T20:07:53Z  2025-06-17T20:07:52Z  323665366   \n",
       "534                  None                  None   32051890   \n",
       "\n",
       "                                          repo_url  \\\n",
       "102  https://api.github.com/repos/JuliaLang/Pkg.jl   \n",
       "114   https://api.github.com/repos/numbagg/numbagg   \n",
       "249   https://api.github.com/repos/JuliaLang/julia   \n",
       "526   https://api.github.com/repos/microsoft/kiota   \n",
       "534    https://api.github.com/repos/dotnet/msbuild   \n",
       "\n",
       "                                          html_url  type repo_owner repo_name  \n",
       "102  https://github.com/JuliaLang/Pkg.jl/pull/4304  perf  JuliaLang    Pkg.jl  \n",
       "114    https://github.com/numbagg/numbagg/pull/397  perf    numbagg   numbagg  \n",
       "249  https://github.com/JuliaLang/julia/pull/59071  perf  JuliaLang     julia  \n",
       "526   https://github.com/microsoft/kiota/pull/6671  perf  microsoft     kiota  \n",
       "534   https://github.com/dotnet/msbuild/pull/12025  perf     dotnet   msbuild  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_ai.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fda7408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âž¡ Fetching commits, pipelines & comments for JuliaLang/Pkg.jl PR #4304 (dataset id=3200679276)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for numbagg/numbagg PR #397 (dataset id=3250477735)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for JuliaLang/julia PR #59071 (dataset id=3254647682)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for microsoft/kiota PR #6671 (dataset id=3151002300)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for dotnet/msbuild PR #12025 (dataset id=3151370964)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for dotnet/aspnetcore PR #62056 (dataset id=3081695764)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for ant-design/ant-design PR #54325 (dataset id=3210885983)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for nearai/nearai PR #1179 (dataset id=3122455352)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for microsoft/testfx PR #6060 (dataset id=3235179464)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for robertpenner/as3-signals PR #74 (dataset id=3074606452)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for trinodb/trino PR #26149 (dataset id=3212230718)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for microsoft/onnxruntime PR #25061 (dataset id=3146327522)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for microsoft/onnxruntime PR #25066 (dataset id=3146329050)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for OWASP-BLT/BLT PR #4290 (dataset id=3077200502)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for microsoft/genaiscript PR #1633 (dataset id=3167979829)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for remotion-dev/remotion PR #5403 (dataset id=3153634298)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for halo-dev/halo PR #7645 (dataset id=3275676664)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for CarGuo/gsy_github_app_flutter PR #913 (dataset id=3258539679)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for tokens-studio/figma-plugin PR #3412 (dataset id=3119099358)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for demergent-labs/azle PR #3058 (dataset id=3076655992)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for microsoft/magentic-ui PR #54 (dataset id=3075266937)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Following Github server redirection from /repos/unibeck/solstatus to /repositories/969089225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âž¡ Fetching commits, pipelines & comments for unibeck/solstatus PR #55 (dataset id=3075349977)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for microsoft/testfx PR #6162 (dataset id=3262412016)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for cschleiden/go-workflows PR #388 (dataset id=3220396620)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for primer/react PR #6197 (dataset id=3137892942)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mlflow/mlflow PR #16039 (dataset id=3113006799)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for celestiaorg/rsmt2d PR #361 (dataset id=3113051088)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for tomhrr/cosh PR #181 (dataset id=3158727370)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for microsoft/HydraLab PR #694 (dataset id=3096236895)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for microsoft/HydraLab PR #695 (dataset id=3096249565)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for Krande/adapy PR #146 (dataset id=3189634328)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for microsoft/react-native-windows PR #14756 (dataset id=3134374490)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for onnx/onnx PR #7057 (dataset id=3160620876)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for dotnet/sdk PR #49459 (dataset id=3154652967)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for dotnet/msbuild PR #11953 (dataset id=3120627194)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for microsoft/testfx PR #5654 (dataset id=3093949496)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for microsoft/testfx PR #5655 (dataset id=3093995006)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for faros-ai/airbyte-connectors PR #2114 (dataset id=3173779555)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for dotnet/aspnetcore PR #62661 (dataset id=3219696751)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for doodlum/skyrim-community-shaders PR #1281 (dataset id=3241523087)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for ltwlf/json-diff-ts PR #300 (dataset id=3206743230)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for hyperlight-dev/hyperlight PR #510 (dataset id=3075207290)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for quarylabs/sqruff PR #1749 (dataset id=3204565892)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for rustfs/rustfs PR #74 (dataset id=3207425781)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for rustfs/rustfs PR #76 (dataset id=3207429355)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for dotnet/runtime PR #117160 (dataset id=3189195714)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for Z3Prover/z3 PR #7710 (dataset id=3193183157)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #10824 (dataset id=3246365675)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #10854 (dataset id=3246418740)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #10855 (dataset id=3246432388)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #1268 (dataset id=3152227912)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for phellipeandrade/rbac PR #42 (dataset id=3128593850)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for jdereg/java-util PR #146 (dataset id=3146870376)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for MontrealAI/AGI-Alpha-Agent-v0 PR #1332 (dataset id=3107237879)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #4150 (dataset id=3187736538)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #2003 (dataset id=3158684496)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for zpm-zsh/zpm PR #65 (dataset id=3120514991)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #5564 (dataset id=3206323613)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for eplatonoff/pilorama PR #89 (dataset id=3186657928)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #3931 (dataset id=3185733825)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for jscarle/LightResults PR #60 (dataset id=3213723251)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #10497 (dataset id=3245892725)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #10505 (dataset id=3245899488)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #10515 (dataset id=3245927515)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #10525 (dataset id=3245957050)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #10557 (dataset id=3245970844)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for moonbitlang/core PR #2255 (dataset id=3138341820)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for addok/addok PR #893 (dataset id=3089613637)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #207 (dataset id=3128738345)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for elixr-games/elics PR #17 (dataset id=3078172167)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for hmislk/hmis PR #13695 (dataset id=3204638990)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for jscarle/LightResults PR #61 (dataset id=3213724164)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #3924 (dataset id=3185679015)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #3943 (dataset id=3185988908)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #3947 (dataset id=3186033939)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #3969 (dataset id=3186235764)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #3980 (dataset id=3186305413)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #3988 (dataset id=3186318107)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #3992 (dataset id=3186329921)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #3994 (dataset id=3186332246)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #4001 (dataset id=3186370979)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #4004 (dataset id=3186409173)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #4011 (dataset id=3186433660)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #7196 (dataset id=3218234090)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #7207 (dataset id=3218343296)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #9435 (dataset id=3241690700)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #9436 (dataset id=3241691177)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #9440 (dataset id=3241695471)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #9484 (dataset id=3241758610)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #3948 (dataset id=3186037018)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #7751 (dataset id=3222683231)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #2463 (dataset id=3164738704)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for OEvortex/Webscout PR #70 (dataset id=3108570703)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for MihaiCristianCondrea/Smart-Cleaner-for-Android PR #132 (dataset id=3214766453)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #7115 (dataset id=3217761016)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #7119 (dataset id=3217766297)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #4798 (dataset id=3198134004)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #9410 (dataset id=3240460340)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for gensx-inc/gensx PR #806 (dataset id=3164430964)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for eplatonoff/pilorama PR #76 (dataset id=3111251601)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for eplatonoff/pilorama PR #78 (dataset id=3111298393)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #60 (dataset id=3118392412)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for MontrealAI/AGI-Alpha-Agent-v0 PR #615 (dataset id=3087062778)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #2457 (dataset id=3164722645)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for jscarle/LightResults PR #70 (dataset id=3213747226)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for jscarle/LightResults PR #76 (dataset id=3213876116)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for OpenHFT/Chronicle-Bytes PR #686 (dataset id=3116534114)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #2739 (dataset id=3168842951)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #2736 (dataset id=3168819278)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #39 (dataset id=3117777345)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #13059 (dataset id=3262865664)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for MontrealAI/AGI-Alpha-Agent-v0 PR #367 (dataset id=3073998720)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #13145 (dataset id=3263278811)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for ryokun6/ryos PR #118 (dataset id=3104463145)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #10318 (dataset id=3245509530)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for jniebuhr/gaggimate PR #299 (dataset id=3220760486)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for Rello/analytics PR #469 (dataset id=3087231593)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #5003 (dataset id=3202402474)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #5004 (dataset id=3202406874)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #5040 (dataset id=3202673408)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #5046 (dataset id=3202700175)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #5067 (dataset id=3202763859)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #11614 (dataset id=3250286583)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #1134 (dataset id=3150133933)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for jaseci-labs/jaseci PR #2146 (dataset id=3148090723)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mangiucugna/json_repair PR #120 (dataset id=3071827885)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #214 (dataset id=3128867544)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #215 (dataset id=3128873567)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #217 (dataset id=3128898273)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for carverauto/serviceradar PR #951 (dataset id=3154548302)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #2721 (dataset id=3168509434)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Following Github server redirection from /repos/stanford-crfm/levanter to /repositories/496005961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âž¡ Fetching commits, pipelines & comments for stanford-crfm/levanter PR #1066 (dataset id=3234031765)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for Doriandarko/make-it-heavy PR #9 (dataset id=3240593081)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for moonbitlang/core PR #2253 (dataset id=3137138306)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for MihaiCristianCondrea/Smart-Cleaner-for-Android PR #125 (dataset id=3213528854)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for ryokun6/ryos PR #50 (dataset id=3073532077)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for ryokun6/ryos PR #57 (dataset id=3074924091)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for prebid/Prebid.js PR #13460 (dataset id=3189294728)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for moonbitlang/core PR #2267 (dataset id=3142771614)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #7897 (dataset id=3224827777)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for gacela-project/gacela PR #326 (dataset id=3104378127)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for phel-lang/phel-lang PR #823 (dataset id=3104406142)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for dlt-hub/dlt PR #2691 (dataset id=3096300821)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for MontrealAI/AGI-Alpha-Agent-v0 PR #29 (dataset id=3070310257)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for MontrealAI/AGI-Alpha-Agent-v0 PR #1245 (dataset id=3104683212)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #4190 (dataset id=3188612213)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #4193 (dataset id=3188613267)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #4195 (dataset id=3188613776)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #4196 (dataset id=3188614083)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #4197 (dataset id=3188614216)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #4202 (dataset id=3188714494)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #4206 (dataset id=3188718282)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #4228 (dataset id=3188781479)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #4253 (dataset id=3188892969)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #13905 (dataset id=3267289370)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for vllm-project/vllm PR #21146 (dataset id=3241057566)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for Stirling-Tools/Stirling-PDF PR #3992 (dataset id=3246122368)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for hikettei/Caten PR #430 (dataset id=3150434121)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #4055 (dataset id=3187015246)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for TypedDevs/bashunit PR #411 (dataset id=3106031006)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for FarmBot/Farmbot-Web-App PR #2493 (dataset id=3164813640)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #9492 (dataset id=3242128024)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #9550 (dataset id=3242396116)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #3611 (dataset id=3181363640)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for bruin-data/bruin PR #932 (dataset id=3253809004)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #4340 (dataset id=3190320694)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #18 (dataset id=3116414631)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #59 (dataset id=3118377413)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #9329 (dataset id=3239403987)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #41 (dataset id=3117839444)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #7854 (dataset id=3223908947)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for stanford-crfm/levanter PR #1056 (dataset id=3226180108)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Following Github server redirection from /repos/stanford-crfm/levanter to /repositories/496005961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #484 (dataset id=3142986664)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for jscarle/LightResults PR #74 (dataset id=3213850102)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for jscarle/LightResults PR #75 (dataset id=3213857892)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #12900 (dataset id=3261822593)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for phellipeandrade/rbac PR #43 (dataset id=3128644658)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #7004 (dataset id=3216964251)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for wieslawsoltes/Xaml.Behaviors PR #82 (dataset id=3071083444)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for prebid/Prebid.js PR #13334 (dataset id=3130957636)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for marin-community/marin PR #1429 (dataset id=3200979351)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #11961 (dataset id=3252596861)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #4084 (dataset id=3187229759)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for MihaiCristianCondrea/Smart-Cleaner-for-Android PR #212 (dataset id=3246158661)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for moonbitlang/core PR #2262 (dataset id=3141942061)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for MihaiCristianCondrea/Smart-Cleaner-for-Android PR #219 (dataset id=3257571628)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for MihaiCristianCondrea/Smart-Cleaner-for-Android PR #220 (dataset id=3257665431)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for econ-ark/HARK PR #1562 (dataset id=3077187183)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for elixr-games/elics PR #39 (dataset id=3084684604)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for elixr-games/elics PR #42 (dataset id=3084770989)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #7246 (dataset id=3218429525)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #6520 (dataset id=3214278956)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #6522 (dataset id=3214281732)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for jdereg/java-util PR #143 (dataset id=3146857680)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #10448 (dataset id=3245861239)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for moonbitlang/core PR #2265 (dataset id=3142207549)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for jscarle/LightResults PR #65 (dataset id=3213730809)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #6256 (dataset id=3210728631)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for temporalio/temporal PR #7896 (dataset id=3134947414)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for writer/writer-framework PR #902 (dataset id=3101459806)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #6882 (dataset id=3216548273)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #6900 (dataset id=3216588034)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for Rello/audioplayer PR #634 (dataset id=3246099511)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for Rello/analytics PR #522 (dataset id=3246105987)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #10727 (dataset id=3246117305)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #3946 (dataset id=3186031697)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for elixr-games/elics PR #24 (dataset id=3078500498)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #8629 (dataset id=3227169343)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #8664 (dataset id=3227405736)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for intelligencedev/manifold PR #91 (dataset id=3210894862)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for jscarle/LightResults PR #71 (dataset id=3213750237)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for jdereg/java-util PR #347 (dataset id=3166859797)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for jscarle/LightResults PR #77 (dataset id=3213895675)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for jscarle/LightResults PR #63 (dataset id=3213728031)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #7113 (dataset id=3217758395)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for onlook-dev/onlook PR #2132 (dataset id=3131512724)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for prebid/Prebid.js PR #13469 (dataset id=3190098735)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for prebid/Prebid.js PR #13468 (dataset id=3190011828)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #3168 (dataset id=3175127708)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #3949 (dataset id=3186037439)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for phel-lang/phel-lang PR #809 (dataset id=3099945080)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #7367 (dataset id=3219158589)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for hmislk/hmis PR #14205 (dataset id=3265736885)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for gluesql/glues PR #146 (dataset id=3135397128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Following Github server redirection from /repos/stanford-crfm/levanter to /repositories/496005961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âž¡ Fetching commits, pipelines & comments for stanford-crfm/levanter PR #1102 (dataset id=3264767865)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for Wtrwx/DYYY PR #250 (dataset id=3196281528)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for moonbitlang/core PR #2266 (dataset id=3142406085)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for parse-community/parse-dashboard PR #2920 (dataset id=3239561220)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #3893 (dataset id=3184544966)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for OpenHFT/Chronicle-Core PR #813 (dataset id=3106780046)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for OpenHFT/Chronicle-Core PR #814 (dataset id=3106804055)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for MontrealAI/AGI-Alpha-Agent-v0 PR #1377 (dataset id=3107735616)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for static-frame/static-frame PR #1069 (dataset id=3115186500)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for MontrealAI/AGI-Alpha-Agent-v0 PR #3666 (dataset id=3253657829)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #3698 (dataset id=3181712853)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for elixr-games/elics PR #35 (dataset id=3081150843)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Following Github server redirection from /repos/stanford-crfm/levanter to /repositories/496005961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âž¡ Fetching commits, pipelines & comments for stanford-crfm/levanter PR #1065 (dataset id=3233988388)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for jdereg/java-util PR #194 (dataset id=3147149820)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for Rello/audioplayer PR #611 (dataset id=3225788754)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #3266 (dataset id=3176300978)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for swhan0329/vehicle_speed_estimation PR #7 (dataset id=3117019425)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for ltwlf/json-diff-ts PR #301 (dataset id=3206861578)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #9165 (dataset id=3238396793)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #9213 (dataset id=3238582253)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #9244 (dataset id=3238674493)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #9252 (dataset id=3238720815)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #9253 (dataset id=3238723742)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #9260 (dataset id=3238737226)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #9262 (dataset id=3238739331)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #13057 (dataset id=3262845265)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #13066 (dataset id=3262887238)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for wieslawsoltes/Xaml.Behaviors PR #78 (dataset id=3071077630)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #3993 (dataset id=3186331079)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mochilang/mochi PR #3998 (dataset id=3186346363)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for lunasaw/gb28181-proxy PR #38 (dataset id=3198941408)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for langfuse/langfuse PR #7895 (dataset id=3233537204)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for liuyanghejerry/painttyWidget PR #91 (dataset id=3271610326)\n",
      "   Error fetching PR #91 from liuyanghejerry/painttyWidget: 404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/repos/repos#get-a-repository\", \"status\": \"404\"}\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for zws-im/zws PR #856 (dataset id=3219981823)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for different-ai/zero-finance PR #216 (dataset id=3190247421)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for langchain-ai/langchain PR #31987 (dataset id=3224713270)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for jxxghp/MoviePilot-Frontend PR #359 (dataset id=3206379276)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for gmathi/NovelLibrary PR #244 (dataset id=3217652543)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for getsentry/sentry PR #95050 (dataset id=3213281518)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for epicweb-dev/epicshop PR #268 (dataset id=3226144762)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for buster-so/buster PR #416 (dataset id=3209206554)\n",
      "   Error fetching PR #416 from buster-so/buster: 404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/repos/repos#get-a-repository\", \"status\": \"404\"}\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for kleosr/cursorkleosr PR #5 (dataset id=3261917784)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for vercel/turborepo PR #10623 (dataset id=3194284966)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for mediar-ai/terminator PR #201 (dataset id=3226639011)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for ryokun6/ryos PR #94 (dataset id=3087728875)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for jxxghp/MoviePilot PR #4579 (dataset id=3215138589)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for nnstreamer/nntrainer PR #3312 (dataset id=3215330137)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for epicweb-dev/restore-scroll PR #13 (dataset id=3197078069)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for gmathi/NovelLibrary PR #246 (dataset id=3217675934)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for gmathi/NovelLibrary PR #247 (dataset id=3217742863)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for tldraw/tldraw PR #6472 (dataset id=3239263606)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for elie222/inbox-zero PR #505 (dataset id=3138324206)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for ethyca/fides PR #6310 (dataset id=3209964949)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for ohcnetwork/care_fe PR #12979 (dataset id=3242666013)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for calcom/cal.com PR #21166 (dataset id=3046771940)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for airbytehq/airbyte PR #60253 (dataset id=3061069405)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for calcom/cal.com PR #21192 (dataset id=3049300237)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for calcom/cal.com PR #21193 (dataset id=3049320746)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for magiclabs/magic-js PR #874 (dataset id=2973653748)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for calcom/cal.com PR #21048 (dataset id=3033566586)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for calcom/cal.com PR #21052 (dataset id=3033886992)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for amplication/amplication PR #9794 (dataset id=3168164252)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for gear-tech/gear PR #4725 (dataset id=3155697260)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for calcom/cal.com PR #21479 (dataset id=3084608702)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for jnsahaj/tweakcn PR #97 (dataset id=3084701052)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for saturday06/VRM-Addon-for-Blender PR #795 (dataset id=3006445782)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for saturday06/VRM-Addon-for-Blender PR #796 (dataset id=3006507938)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for saturday06/VRM-Addon-for-Blender PR #797 (dataset id=3006534682)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for saturday06/VRM-Addon-for-Blender PR #798 (dataset id=3006544045)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for saturday06/VRM-Addon-for-Blender PR #800 (dataset id=3006562482)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Following Github server redirection from /repos/buger/probe to /repositories/943383028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âž¡ Fetching commits, pipelines & comments for buger/probe PR #56 (dataset id=3235100943)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for buffdb/buffdb PR #26 (dataset id=3250089415)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for Yamashou/gqlgenc PR #289 (dataset id=3148602658)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for calcom/cal.com PR #21220 (dataset id=3053649404)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for calcom/cal.com PR #20676 (dataset id=2991070962)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for web-infra-dev/rspack PR #10677 (dataset id=3147340923)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for sikanhe/gqtx PR #79 (dataset id=3148127134)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for liam-hq/liam PR #1985 (dataset id=3136694740)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for jodendaal/OpenAI.Net PR #89 (dataset id=3137786825)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Following Github server redirection from /repos/appdotbuild/agent to /repositories/913914262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âž¡ Fetching commits, pipelines & comments for appdotbuild/agent PR #185 (dataset id=3052357500)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for calcom/cal.com PR #21217 (dataset id=3053325093)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for liam-hq/liam PR #2102 (dataset id=3161908700)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for ateliee/jquery.schedule PR #58 (dataset id=3161909204)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for sourcebot-dev/sourcebot PR #357 (dataset id=3155001680)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for vercel/vercel PR #13284 (dataset id=3034997303)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for calcom/cal.com PR #21162 (dataset id=3046430027)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for calcom/cal.com PR #21418 (dataset id=3077061912)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for calcom/cal.com PR #21370 (dataset id=3070150168)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for calcom/cal.com PR #21371 (dataset id=3070165463)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for calcom/cal.com PR #21372 (dataset id=3070227634)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for calcom/cal.com PR #21373 (dataset id=3070233885)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for different-ai/zero-finance PR #146 (dataset id=3127179519)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for calcom/cal.com PR #21067 (dataset id=3034903835)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for ReactiveCircus/android-emulator-runner PR #436 (dataset id=3146354845)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for stack-auth/stack-auth PR #495 (dataset id=2887787232)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for calcom/cal.com PR #21113 (dataset id=3039380315)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for calcom/cal.com PR #21949 (dataset id=3164482877)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for assistant-ui/assistant-ui PR #2113 (dataset id=3151604419)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for wolfSSL/wolfssh PR #779 (dataset id=2859989652)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for calcom/cal.com PR #21137 (dataset id=3042979666)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for bolna-ai/bolna PR #226 (dataset id=3220735806)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for Cap-go/capgo PR #1108 (dataset id=2965102818)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for onlook-dev/onlook PR #982 (dataset id=2766896431)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for onlook-dev/onlook PR #1634 (dataset id=2927184629)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for promptfoo/promptfoo PR #3046 (dataset id=2843312341)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for promptfoo/promptfoo PR #3047 (dataset id=2843334531)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for calcom/cal.com PR #21552 (dataset id=3095454351)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for calcom/cal.com PR #21374 (dataset id=3070322024)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for pdfme/pdfme PR #711 (dataset id=2855302194)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for test-zeus-ai/testzeus-hercules PR #61 (dataset id=3133585449)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for saturday06/VRM-Addon-for-Blender PR #964 (dataset id=3206422165)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for onlook-dev/onlook PR #1630 (dataset id=2926188053)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for onflow/flow-go PR #7598 (dataset id=3240006620)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for calcom/cal.com PR #21497 (dataset id=3087295315)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for liam-hq/liam PR #2037 (dataset id=3152003781)\n",
      "\n",
      "âž¡ Fetching commits, pipelines & comments for Cap-go/capgo PR #1066 (dataset id=2920983723)\n",
      "\n",
      "Total commit rows (ai_pr_commits): 864\n",
      "Total detail rows (ai_pr_commit_details): 11379\n",
      "Total run rows (ai_pr_workflow_runs): 483\n",
      "Total issue comment rows (ai_pr_issue_comments): 459\n",
      "Total review comment rows (ai_pr_review_comments): 265\n",
      "\n",
      "Applying filters to commit data...\n",
      "  Starting detail rows: 11,379\n",
      "  Removed null filenames: 0\n",
      "  Removed config/metadata files: 2,246\n",
      "  Removed merge commits: 77 commit(s)\n",
      "  PRs remaining after filters: 327\n",
      "\n",
      "Totals after filtering:\n",
      "  Commit rows (ai_pr_commits): 764\n",
      "  Detail rows (ai_pr_commit_details): 4161\n",
      "  Run rows (ai_pr_workflow_runs): 464\n",
      "  Issue comment rows (ai_pr_issue_comments): 430\n",
      "  Review comment rows (ai_pr_review_comments): 265\n",
      "  Unique PRs retained: 327\n"
     ]
    }
   ],
   "source": [
    "rows_commits = []\n",
    "rows_details = []\n",
    "rows_runs = []\n",
    "rows_issue_comments = []\n",
    "rows_review_comments = []\n",
    "skipped_count = 0\n",
    "\n",
    "for idx, row in perf_ai.iterrows():\n",
    "    pr_id = int(row[\"id\"])\n",
    "    owner = row[\"repo_owner\"]\n",
    "    repo_name = row[\"repo_name\"]\n",
    "    number = int(row[\"number\"])\n",
    "\n",
    "    full_repo = f\"{owner}/{repo_name}\"\n",
    "    print(f\"\\nâž¡ Fetching commits, pipelines & comments for {full_repo} PR #{number} (dataset id={pr_id})\")\n",
    "\n",
    "    if pd.isna(owner) or pd.isna(repo_name):\n",
    "        print(\"   Skipping due to missing owner/repo\")\n",
    "        skipped_count += 1\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        repo = gh.get_repo(full_repo)\n",
    "        pr = repo.get_pull(number)\n",
    "\n",
    "        pr_title = pr.title\n",
    "        pr_description = pr.body\n",
    "        pr_comments_count = pr.comments  \n",
    "\n",
    "        # ===================== ISSUE COMMENTS  =====================\n",
    "        try:\n",
    "            issue_comments = pr.get_issue_comments()\n",
    "            for c in issue_comments:\n",
    "                rows_issue_comments.append({\n",
    "                    \"pr_id\": pr_id,\n",
    "                    \"pr_number\": number,\n",
    "                    \"comment_id\": c.id,\n",
    "                    \"user_login\": c.user.login if c.user else None,\n",
    "                    \"user_type\": c.user.type if c.user else None,\n",
    "                    \"body\": c.body,\n",
    "                    \"created_at\": c.created_at,\n",
    "                    \"updated_at\": c.updated_at,\n",
    "                    \"url\": c.html_url,\n",
    "                })\n",
    "        except Exception as e_ic:\n",
    "            print(f\"   Error fetching issue comments for PR #{number}: {e_ic}\")\n",
    "\n",
    "        # ===================== REVIEW COMMENTS =====================\n",
    "        try:\n",
    "            review_comments = pr.get_review_comments()\n",
    "            for rc in review_comments:\n",
    "                rows_review_comments.append({\n",
    "                    \"pr_id\": pr_id,\n",
    "                    \"pr_number\": number,\n",
    "                    \"comment_id\": rc.id,\n",
    "                    \"user_login\": rc.user.login if rc.user else None,\n",
    "                    \"user_type\": rc.user.type if rc.user else None,\n",
    "                    \"body\": rc.body,\n",
    "                    \"created_at\": rc.created_at,\n",
    "                    \"updated_at\": rc.updated_at,\n",
    "                    \"path\": rc.path,\n",
    "                    \"position\": rc.position,\n",
    "                    \"original_position\": rc.original_position,\n",
    "                    \"commit_id\": rc.commit_id,\n",
    "                    \"original_commit_id\": rc.original_commit_id,\n",
    "                    \"in_reply_to_id\": getattr(rc, \"in_reply_to_id\", None),\n",
    "                    \"diff_hunk\": rc.diff_hunk,\n",
    "                    \"url\": rc.html_url,\n",
    "                })\n",
    "        except Exception as e_rc:\n",
    "            print(f\"   Error fetching review comments for PR #{number}: {e_rc}\")\n",
    "\n",
    "        # ===================== COMMITS =====================\n",
    "        commit_list = pr.get_commits()\n",
    "        for c in commit_list:\n",
    "            sha = c.sha\n",
    "            commit_obj = c.commit\n",
    "\n",
    "            author_name = None\n",
    "            committer_name = None\n",
    "            commit_message = None\n",
    "\n",
    "            if commit_obj is not None:\n",
    "                if commit_obj.author is not None:\n",
    "                    author_name = commit_obj.author.name\n",
    "                if commit_obj.committer is not None:\n",
    "                    committer_name = commit_obj.committer.name\n",
    "                commit_message = commit_obj.message\n",
    "\n",
    "            stats = c.stats\n",
    "            commit_stats_additions = getattr(stats, \"additions\", None)\n",
    "            commit_stats_deletions = getattr(stats, \"deletions\", None)\n",
    "            commit_stats_total = getattr(stats, \"total\", None)\n",
    "\n",
    "            # ---- table commits ----\n",
    "            rows_commits.append({\n",
    "                \"sha\": sha,\n",
    "                \"pr_id\": pr_id,\n",
    "                \"pr_number\": number,\n",
    "                \"repo_owner\": owner,\n",
    "                \"repo_name\": repo_name,\n",
    "                \"author\": author_name,\n",
    "                \"committer\": committer_name,\n",
    "                \"commit_message\": commit_message,\n",
    "                \"pr_title\": pr_title,\n",
    "                \"pr_description\": pr_description,\n",
    "                \"pr_comments_count\": pr_comments_count,\n",
    "            })\n",
    "\n",
    "            # ---- table pr_commit_details ----\n",
    "            for f in c.files:\n",
    "                rows_details.append({\n",
    "                    \"sha\": sha,\n",
    "                    \"pr_id\": pr_id,\n",
    "                    \"pr_number\": number,\n",
    "                    \"commit_stats_total\": commit_stats_total,\n",
    "                    \"commit_stats_additions\": commit_stats_additions,\n",
    "                    \"commit_stats_deletions\": commit_stats_deletions,\n",
    "                    \"filename\": f.filename,\n",
    "                    \"status\": f.status,\n",
    "                    \"additions\": f.additions,\n",
    "                    \"deletions\": f.deletions,\n",
    "                    \"changes\": f.changes,\n",
    "                    \"patch\": f.patch,\n",
    "                })\n",
    "\n",
    "        # ===================== PIPELINES / WORKFLOW RUNS =====================\n",
    "        head_sha = pr.head.sha\n",
    "        head_branch = pr.head.ref\n",
    "\n",
    "        for run in repo.get_workflow_runs(branch=head_branch, event=\"pull_request\"):\n",
    "            if run.head_sha != head_sha:\n",
    "                continue\n",
    "\n",
    "            rows_runs.append({\n",
    "                \"run_id\": run.id,\n",
    "                \"pr_id\": pr_id,\n",
    "                \"pr_number\": number,\n",
    "                \"workflow_id\": run.workflow_id,\n",
    "                \"workflow_name\": getattr(run, \"name\", None),\n",
    "                \"head_branch\": run.head_branch,\n",
    "                \"head_sha\": run.head_sha,\n",
    "                \"event\": run.event,\n",
    "                \"status\": run.status,\n",
    "                \"conclusion\": run.conclusion,\n",
    "                \"created_at\": run.created_at,\n",
    "                \"updated_at\": run.updated_at,\n",
    "                \"run_attempt\": getattr(run, \"run_attempt\", None),\n",
    "                \"url\": run.html_url,\n",
    "            })\n",
    "\n",
    "        time.sleep(0.7)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   Error fetching PR #{number} from {full_repo}: {e}\")\n",
    "        skipped_count += 1\n",
    "\n",
    "# ===================== DATAFRAMES =====================\n",
    "df_commits = pd.DataFrame(rows_commits)\n",
    "df_details = pd.DataFrame(rows_details)\n",
    "df_runs = pd.DataFrame(rows_runs)\n",
    "df_issue_comments = pd.DataFrame(rows_issue_comments)\n",
    "df_review_comments = pd.DataFrame(rows_review_comments)\n",
    "\n",
    "print(\"\\nTotal commit rows (ai_pr_commits):\", len(df_commits))\n",
    "print(\"Total detail rows (ai_pr_commit_details):\", len(df_details))\n",
    "print(\"Total run rows (ai_pr_workflow_runs):\", len(df_runs))\n",
    "print(\"Total issue comment rows (ai_pr_issue_comments):\", len(df_issue_comments))\n",
    "print(\"Total review comment rows (ai_pr_review_comments):\", len(df_review_comments))\n",
    "\n",
    "# ===================== FILTERS =====================\n",
    "print(\"\\nApplying filters to commit data...\")\n",
    "\n",
    "if len(df_details) == 0:\n",
    "    print(\"  No commit detail rows; skipping filters.\")\n",
    "    filtered_pr_ids = set(df_commits.get('pr_id', pd.Series(dtype=int)).unique())\n",
    "else:\n",
    "    print(f\"  Starting detail rows: {len(df_details):,}\")\n",
    "    \n",
    "    # 1) Remove null filenames\n",
    "    before_filename = len(df_details)\n",
    "    df_details = df_details[df_details['filename'].notna()].copy()\n",
    "    print(f\"  Removed null filenames: {before_filename - len(df_details):,}\")\n",
    "\n",
    "\n",
    "    config_patterns = [\n",
    "        r'^\\.mvn/',\n",
    "        r'^\\.gradle/',\n",
    "        r'^\\.idea/',\n",
    "        r'^\\.vscode/',\n",
    "        r'^\\.github/workflows/',\n",
    "        r'\\.properties$',\n",
    "        r'\\.xml$',\n",
    "        r'\\.yml$',\n",
    "        r'\\.yaml$',\n",
    "        r'\\.json$',\n",
    "        r'\\.txt$',\n",
    "        r'\\.gitignore$',\n",
    "        r'\\.dockerignore$',\n",
    "        r'/Dockerfile$',\n",
    "        r'^Dockerfile$',\n",
    "        r'/docker-compose',\n",
    "        r'^docker-compose',\n",
    "        r'\\.lock$',\n",
    "        r'^LICENSE',\n",
    "        r'^README',\n",
    "    ]\n",
    "    config_pattern = '|'.join(config_patterns)\n",
    "    before_config = len(df_details)\n",
    "    df_details['is_config_file'] = df_details['filename'].str.contains(\n",
    "        config_pattern, case=False, na=False, regex=True\n",
    "    )\n",
    "    df_details = df_details[~df_details['is_config_file']].copy()\n",
    "    df_details = df_details.drop(columns=['is_config_file'])\n",
    "    print(f\"  Removed config/metadata files: {before_config - len(df_details):,}\")\n",
    "\n",
    "\n",
    "    merge_patterns = [\n",
    "        r'^Merge\\s+branch',\n",
    "        r'^Merge\\s+pull\\s+request',\n",
    "        r'^Merge\\s+remote-tracking\\s+branch',\n",
    "        r'^Merge\\s+.*\\s+into\\s+',\n",
    "        r\"^Merged\\s+in\\s+\",\n",
    "    ]\n",
    "    merge_pattern = '|'.join(merge_patterns)\n",
    "    merge_shas = set(\n",
    "        df_commits[\n",
    "            df_commits['commit_message'].str.match(merge_pattern, case=False, na=False)\n",
    "        ]['sha'].tolist()\n",
    "    )\n",
    "    if merge_shas:\n",
    "        df_commits = df_commits[~df_commits['sha'].isin(merge_shas)].copy()\n",
    "        df_details = df_details[~df_details['sha'].isin(merge_shas)].copy()\n",
    "    print(f\"  Removed merge commits: {len(merge_shas)} commit(s)\")\n",
    "\n",
    "\n",
    "    filtered_pr_ids = set(df_details['pr_id'].unique())\n",
    "    print(f\"  PRs remaining after filters: {len(filtered_pr_ids):,}\")\n",
    "\n",
    "# Keep only PRs that still have code files after filtering\n",
    "df_commits = df_commits[df_commits['pr_id'].isin(filtered_pr_ids)].copy()\n",
    "df_runs = df_runs[df_runs['pr_id'].isin(filtered_pr_ids)].copy()\n",
    "df_issue_comments = df_issue_comments[df_issue_comments['pr_id'].isin(filtered_pr_ids)].copy()\n",
    "df_review_comments = df_review_comments[df_review_comments['pr_id'].isin(filtered_pr_ids)].copy()\n",
    "\n",
    "print(\"\\nTotals after filtering:\")\n",
    "print(\"  Commit rows (ai_pr_commits):\", len(df_commits))\n",
    "print(\"  Detail rows (ai_pr_commit_details):\", len(df_details))\n",
    "print(\"  Run rows (ai_pr_workflow_runs):\", len(df_runs))\n",
    "print(\"  Issue comment rows (ai_pr_issue_comments):\", len(df_issue_comments))\n",
    "print(\"  Review comment rows (ai_pr_review_comments):\", len(df_review_comments))\n",
    "print(f\"  Unique PRs retained: {len(filtered_pr_ids):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5885b04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for PRs with markdown-only changes...\n",
      "  PRs with only markdown files: 3\n",
      "  Unique PRs retained after markdown-only filter: 324\n",
      "\n",
      "Totals after markdown-only filter:\n",
      "  Commit rows (ai_pr_commits): 758\n",
      "  Detail rows (ai_pr_commit_details): 4155\n",
      "  Run rows (ai_pr_workflow_runs): 457\n",
      "  Issue comment rows (ai_pr_issue_comments): 427\n",
      "  Review comment rows (ai_pr_review_comments): 265\n"
     ]
    }
   ],
   "source": [
    "# Remove PRs where commits only touch markdown files (no code changes)\n",
    "print(\"\\nChecking for PRs with markdown-only changes...\")\n",
    "\n",
    "if len(df_details) == 0:\n",
    "    print(\"  No commit detail rows; skipping markdown-only filter.\")\n",
    "    print(f\"  Unique PRs retained (unchanged): {len(filtered_pr_ids):,}\")\n",
    "else:\n",
    "    df_details[\"__is_markdown\"] = df_details[\"filename\"].str.lower().str.endswith((\".md\", \".markdown\"))\n",
    "\n",
    "    md_only_pr_ids = set(\n",
    "        df_details.groupby(\"pr_id\")[\"__is_markdown\"]\n",
    "        .agg(lambda s: bool(len(s)) and s.all())\n",
    "        .pipe(lambda s: s[s].index)\n",
    "    )\n",
    "\n",
    "    print(f\"  PRs with only markdown files: {len(md_only_pr_ids):,}\")\n",
    "    if md_only_pr_ids:\n",
    "        df_details = df_details[~df_details[\"pr_id\"].isin(md_only_pr_ids)].copy()\n",
    "        df_commits = df_commits[~df_commits[\"pr_id\"].isin(md_only_pr_ids)].copy()\n",
    "        df_runs = df_runs[~df_runs[\"pr_id\"].isin(md_only_pr_ids)].copy()\n",
    "        df_issue_comments = df_issue_comments[~df_issue_comments[\"pr_id\"].isin(md_only_pr_ids)].copy()\n",
    "        df_review_comments = df_review_comments[~df_review_comments[\"pr_id\"].isin(md_only_pr_ids)].copy()\n",
    "\n",
    "    filtered_pr_ids = set(df_details[\"pr_id\"].unique())\n",
    "    df_details = df_details.drop(columns=[\"__is_markdown\"])\n",
    "\n",
    "    print(f\"  Unique PRs retained after markdown-only filter: {len(filtered_pr_ids):,}\")\n",
    "    print(\"\\nTotals after markdown-only filter:\")\n",
    "    print(\"  Commit rows (ai_pr_commits):\", len(df_commits))\n",
    "    print(\"  Detail rows (ai_pr_commit_details):\", len(df_details))\n",
    "    print(\"  Run rows (ai_pr_workflow_runs):\", len(df_runs))\n",
    "    print(\"  Issue comment rows (ai_pr_issue_comments):\", len(df_issue_comments))\n",
    "    print(\"  Review comment rows (ai_pr_review_comments):\", len(df_review_comments))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "233f2708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: ai_pr_commits.parquet\n",
      "Saved: ai_pr_commit_details.parquet\n",
      "Saved: ai_pr_workflow_runs.parquet\n",
      "Saved: ai_pr_issue_comments.parquet\n",
      "Saved: ai_pr_review_comments.parquet\n",
      "\n",
      "Skipped 2 PRs due to errors or missing data.\n"
     ]
    }
   ],
   "source": [
    "# ===================== SAVE TO PARQUET =====================\n",
    "df_commits.to_parquet(\"./ai_pr_commits.parquet\", index=False)\n",
    "df_details.to_parquet(\"./ai_pr_commit_details.parquet\", index=False)\n",
    "df_runs.to_parquet(\"./ai_pr_workflow_runs.parquet\", index=False)\n",
    "df_issue_comments.to_parquet(\"./ai_pr_issue_comments.parquet\", index=False)\n",
    "df_review_comments.to_parquet(\"./ai_pr_review_comments.parquet\", index=False)\n",
    "print(\"\\nSaved: ai_pr_commits.parquet\")\n",
    "print(\"Saved: ai_pr_commit_details.parquet\")\n",
    "print(\"Saved: ai_pr_workflow_runs.parquet\")\n",
    "print(\"Saved: ai_pr_issue_comments.parquet\")\n",
    "print(\"Saved: ai_pr_review_comments.parquet\")\n",
    "print(f\"\\nSkipped {skipped_count} PRs due to errors or missing data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
