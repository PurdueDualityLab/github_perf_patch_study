{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0e094d3",
   "metadata": {},
   "source": [
    "\n",
    "# Combine OpenAI and Gemini validation labels\n",
    "\n",
    "Align OpenAI and Gemini RQ3 validation outputs, flag disagreements, and fill those rows with manual labels from the human/agent spreadsheets. The notebook saves a single resolved parquet file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a9290bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using BASE_DIR: /Users/antoniozhong/Documents/dev/purdue/MSR2026/github_perf_patch_study/RQ4_test_and_validation\n",
      "OpenAI file: /Users/antoniozhong/Documents/dev/purdue/MSR2026/github_perf_patch_study/RQ4_test_and_validation/llm_data/rq4_validation_evidence_openai.parquet\n",
      "Gemini file: /Users/antoniozhong/Documents/dev/purdue/MSR2026/github_perf_patch_study/RQ4_test_and_validation/llm_data/rq4_validation_evidence_gemini.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Use absolute paths to avoid notebook CWD issues\n",
    "BASE_DIR = Path('/Users/antoniozhong/Documents/dev/purdue/MSR2026/github_perf_patch_study/RQ4_test_and_validation')\n",
    "LLM_DIR = BASE_DIR / 'llm_data'\n",
    "MANUAL_DIR = BASE_DIR / 'manual_label'\n",
    "OUTPUT_DIR = BASE_DIR / 'final_data'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "openai_path = LLM_DIR / 'rq4_validation_evidence_openai.parquet'\n",
    "gemini_path = LLM_DIR / 'rq4_validation_evidence_gemini.parquet'\n",
    "manual_human_path = MANUAL_DIR / 'Final - Human PRs.csv'\n",
    "manual_agent_path = MANUAL_DIR / 'Final-Agent PRs.csv'\n",
    "print('Using BASE_DIR:', BASE_DIR)\n",
    "print('OpenAI file:', openai_path)\n",
    "print('Gemini file:', gemini_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e5834b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI rows: 407\n",
      "Gemini rows: 407\n",
      "Columns: ['pr_id', 'author_type', 'repo', 'pr_number', 'pr_title', 'pipeline_names', 'validation_present', 'evidence_sources', 'validation_type', 'validation_description', 'pipeline_signal', 'description_signal', 'comment_signal']\n"
     ]
    }
   ],
   "source": [
    "openai_df = pd.read_parquet(openai_path)\n",
    "gemini_df = pd.read_parquet(gemini_path)\n",
    "\n",
    "print(f'OpenAI rows: {len(openai_df)}')\n",
    "print(f'Gemini rows: {len(gemini_df)}')\n",
    "print(f'Columns: {list(openai_df.columns)}')\n",
    "\n",
    "assert openai_df['pr_id'].is_unique and gemini_df['pr_id'].is_unique, 'pr_id must be unique'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d70070e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows compared: 407\n",
      "Agreements: 344 | Mismatches: 63\n",
      "Mismatches by author_type (OpenAI side):\n",
      "author_type_openai\n",
      "ai_agent    53\n",
      "human       10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "comparison_columns = {\n",
    "    'validation_present': lambda s: s.fillna(False).astype(bool),\n",
    "    'validation_type': lambda s: s.fillna('none').astype(str).str.strip().str.lower(),\n",
    "}\n",
    "\n",
    "merged = openai_df.merge(\n",
    "    gemini_df,\n",
    "    on=['pr_id', 'repo', 'pr_number'],\n",
    "    suffixes=('_openai', '_gemini'),\n",
    "    how='inner',\n",
    ")\n",
    "assert len(merged) == len(openai_df) == len(gemini_df)\n",
    "\n",
    "mismatch_mask = pd.Series(False, index=merged.index)\n",
    "for col, normalizer in comparison_columns.items():\n",
    "    left = normalizer(merged[f\"{col}_openai\"])\n",
    "    right = normalizer(merged[f\"{col}_gemini\"])\n",
    "    merged[f\"{col}_mismatch\"] = left != right\n",
    "    mismatch_mask = mismatch_mask | merged[f\"{col}_mismatch\"]\n",
    "\n",
    "merged['has_mismatch'] = mismatch_mask\n",
    "agreement_ids = set(merged.loc[~mismatch_mask, 'pr_id'])\n",
    "mismatch_ids = set(merged.loc[mismatch_mask, 'pr_id'])\n",
    "\n",
    "print(f'Rows compared: {len(merged)}')\n",
    "print(f'Agreements: {len(agreement_ids)} | Mismatches: {len(mismatch_ids)}')\n",
    "print('Mismatches by author_type (OpenAI side):')\n",
    "print(merged.loc[mismatch_mask, 'author_type_openai'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9d5b0215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual labels loaded: 63 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "manual_human_df = pd.read_csv(manual_human_path)\n",
    "manual_agent_df = pd.read_csv(manual_agent_path)\n",
    "manual_df = pd.concat([manual_human_df, manual_agent_df], ignore_index=True)\n",
    "\n",
    "manual_df = manual_df.rename(columns={'ID': 'pr_id', 'URL': 'html_url'})\n",
    "manual_df['pr_id'] = manual_df['pr_id'].astype(int)\n",
    "manual_df['validation_type'] = manual_df['validation_type'].fillna('none')\n",
    "manual_df['evidence_sources'] = manual_df['evidence_sources'].fillna('')\n",
    "manual_df['validation_present'] = manual_df['validation_present'].astype(bool)\n",
    "\n",
    "manual_lookup = manual_df.set_index('pr_id')\n",
    "assert manual_lookup.index.is_unique\n",
    "missing_manual = mismatch_ids - set(manual_lookup.index)\n",
    "if missing_manual:\n",
    "    raise ValueError(f'Missing manual labels for mismatch ids: {sorted(missing_manual)}')\n",
    "\n",
    "print(f'Manual labels loaded: {len(manual_lookup)} rows')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a580ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_source\n",
      "openai_gemini_agree    344\n",
      "manual_override         63\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_df = openai_df.copy()\n",
    "final_df['label_source'] = 'openai_gemini_agree'\n",
    "\n",
    "for pr_id in mismatch_ids:\n",
    "    manual_row = manual_lookup.loc[pr_id]\n",
    "    mask = final_df['pr_id'] == pr_id\n",
    "    final_df.loc[mask, 'validation_present'] = bool(manual_row['validation_present'])\n",
    "    final_df.loc[mask, 'validation_type'] = manual_row['validation_type']\n",
    "    final_df.loc[mask, 'evidence_sources'] = manual_row['evidence_sources']\n",
    "    final_df.loc[mask, 'label_source'] = 'manual_override'\n",
    "\n",
    "final_df = final_df.merge(manual_df[['pr_id', 'html_url']], on='pr_id', how='left')\n",
    "final_df = final_df.drop(columns=['html_url'], errors='ignore')\n",
    "\n",
    "def _normalize_evidence_sources(val):\n",
    "    if val is None:\n",
    "        return ''\n",
    "    if isinstance(val, float) and pd.isna(val):\n",
    "        return ''\n",
    "    if isinstance(val, str):\n",
    "        return val\n",
    "    if isinstance(val, (list, tuple, set)):\n",
    "        return '; '.join(map(str, val))\n",
    "    if isinstance(val, dict):\n",
    "        try:\n",
    "            return json.dumps(val, ensure_ascii=True)\n",
    "        except Exception:\n",
    "            return str(val)\n",
    "    return str(val)\n",
    "\n",
    "final_df['evidence_sources'] = final_df['evidence_sources'].apply(_normalize_evidence_sources)\n",
    "\n",
    "print(final_df['label_source'].value_counts())\n",
    "\n",
    "final_df = final_df.drop(columns=['html_url', 'label_source'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "113d1ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved resolved data to: /Users/antoniozhong/Documents/dev/purdue/MSR2026/github_perf_patch_study/RQ4_test_and_validation/final_data/rq4_validation_evidence_final.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "resolved_parquet = OUTPUT_DIR / 'rq4_validation_evidence_final.parquet'\n",
    "final_df_to_save = final_df.drop(columns=['html_url', 'label_source'], errors='ignore')\n",
    "final_df_to_save.to_parquet(resolved_parquet, index=False)\n",
    "print(f'Saved resolved data to: {resolved_parquet}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "48ea4e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "407"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6d8c8d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pr_id</th>\n",
       "      <th>author_type</th>\n",
       "      <th>repo</th>\n",
       "      <th>pr_number</th>\n",
       "      <th>pr_title</th>\n",
       "      <th>pipeline_names</th>\n",
       "      <th>validation_present</th>\n",
       "      <th>evidence_sources</th>\n",
       "      <th>validation_type</th>\n",
       "      <th>validation_description</th>\n",
       "      <th>pipeline_signal</th>\n",
       "      <th>description_signal</th>\n",
       "      <th>comment_signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2766896431</td>\n",
       "      <td>ai_agent</td>\n",
       "      <td>onlook-dev/onlook</td>\n",
       "      <td>982</td>\n",
       "      <td>Replace motion library with Tailwind transitio...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>['description']</td>\n",
       "      <td>static-analysis</td>\n",
       "      <td>The PR explicitly states that performance is i...</td>\n",
       "      <td>No performance benchmarks, profiling, or metri...</td>\n",
       "      <td>Description claims improved performance specif...</td>\n",
       "      <td>Comments do not discuss or provide any perform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2843312341</td>\n",
       "      <td>ai_agent</td>\n",
       "      <td>promptfoo/promptfoo</td>\n",
       "      <td>3046</td>\n",
       "      <td>perf: optimize cache and token handling</td>\n",
       "      <td>[CI, Validate PR Title]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>none</td>\n",
       "      <td>The PR description claims performance optimiza...</td>\n",
       "      <td>Pipeline only validates PR title; no performan...</td>\n",
       "      <td>Description mentions performance-oriented chan...</td>\n",
       "      <td>Comments discuss automation (Devin, TestGru) a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2843334531</td>\n",
       "      <td>ai_agent</td>\n",
       "      <td>promptfoo/promptfoo</td>\n",
       "      <td>3047</td>\n",
       "      <td>perf: optimize cache and token handling</td>\n",
       "      <td>[CI, Validate PR Title]</td>\n",
       "      <td>True</td>\n",
       "      <td>['description']</td>\n",
       "      <td>static-analysis</td>\n",
       "      <td>The PR description explicitly describes perfor...</td>\n",
       "      <td>CI only validates the PR title and does not pr...</td>\n",
       "      <td>The description claims performance optimizatio...</td>\n",
       "      <td>Comments are from automation (Devin, TestGru) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2855302194</td>\n",
       "      <td>ai_agent</td>\n",
       "      <td>pdfme/pdfme</td>\n",
       "      <td>711</td>\n",
       "      <td>Optimize Font Loading Performance in Tests</td>\n",
       "      <td>[Unit Testing]</td>\n",
       "      <td>True</td>\n",
       "      <td>['description']</td>\n",
       "      <td>benchmark</td>\n",
       "      <td>Performance is validated by reporting before-a...</td>\n",
       "      <td>CI pipeline lists unit testing but does not re...</td>\n",
       "      <td>PR description includes explicit before-and-af...</td>\n",
       "      <td>PR comments contain only bot/automation inform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2859989652</td>\n",
       "      <td>ai_agent</td>\n",
       "      <td>wolfSSL/wolfssh</td>\n",
       "      <td>779</td>\n",
       "      <td>Update SFTP status callback to output once per...</td>\n",
       "      <td>[Cppcheck Test, Kyber Tests, OS Check Test, Si...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>none</td>\n",
       "      <td>The PR mentions only functional static analysi...</td>\n",
       "      <td>CI pipelines listed (Cppcheck, OS Check, Zephy...</td>\n",
       "      <td>The description explains that status updates a...</td>\n",
       "      <td>Comments mention that there was a performance ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pr_id author_type                 repo  pr_number  \\\n",
       "0  2766896431    ai_agent    onlook-dev/onlook        982   \n",
       "1  2843312341    ai_agent  promptfoo/promptfoo       3046   \n",
       "2  2843334531    ai_agent  promptfoo/promptfoo       3047   \n",
       "3  2855302194    ai_agent          pdfme/pdfme        711   \n",
       "4  2859989652    ai_agent      wolfSSL/wolfssh        779   \n",
       "\n",
       "                                            pr_title  \\\n",
       "0  Replace motion library with Tailwind transitio...   \n",
       "1            perf: optimize cache and token handling   \n",
       "2            perf: optimize cache and token handling   \n",
       "3         Optimize Font Loading Performance in Tests   \n",
       "4  Update SFTP status callback to output once per...   \n",
       "\n",
       "                                      pipeline_names  validation_present  \\\n",
       "0                                                 []                True   \n",
       "1                            [CI, Validate PR Title]               False   \n",
       "2                            [CI, Validate PR Title]                True   \n",
       "3                                     [Unit Testing]                True   \n",
       "4  [Cppcheck Test, Kyber Tests, OS Check Test, Si...               False   \n",
       "\n",
       "  evidence_sources  validation_type  \\\n",
       "0  ['description']  static-analysis   \n",
       "1               []             none   \n",
       "2  ['description']  static-analysis   \n",
       "3  ['description']        benchmark   \n",
       "4               []             none   \n",
       "\n",
       "                              validation_description  \\\n",
       "0  The PR explicitly states that performance is i...   \n",
       "1  The PR description claims performance optimiza...   \n",
       "2  The PR description explicitly describes perfor...   \n",
       "3  Performance is validated by reporting before-a...   \n",
       "4  The PR mentions only functional static analysi...   \n",
       "\n",
       "                                     pipeline_signal  \\\n",
       "0  No performance benchmarks, profiling, or metri...   \n",
       "1  Pipeline only validates PR title; no performan...   \n",
       "2  CI only validates the PR title and does not pr...   \n",
       "3  CI pipeline lists unit testing but does not re...   \n",
       "4  CI pipelines listed (Cppcheck, OS Check, Zephy...   \n",
       "\n",
       "                                  description_signal  \\\n",
       "0  Description claims improved performance specif...   \n",
       "1  Description mentions performance-oriented chan...   \n",
       "2  The description claims performance optimizatio...   \n",
       "3  PR description includes explicit before-and-af...   \n",
       "4  The description explains that status updates a...   \n",
       "\n",
       "                                      comment_signal  \n",
       "0  Comments do not discuss or provide any perform...  \n",
       "1  Comments discuss automation (Devin, TestGru) a...  \n",
       "2  Comments are from automation (Devin, TestGru) ...  \n",
       "3  PR comments contain only bot/automation inform...  \n",
       "4  Comments mention that there was a performance ...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
